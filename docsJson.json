[
    {
        "name_of_file": "admin.py",
        "functions": [
            {
                "function_name": "get_profile_by_full_name",
                "parameters": [
                    "full_name"
                ],
                "content": "        first_name, last_name = full_name.split()\n        try:\n            profile = Profile.objects.get(first_name=first_name, last_name=last_name)\n        except Profile.DoesNotExist:\n            return None\n        return profile"
            },
            {
                "function_name": "save",
                "parameters": [
                    "self",
                    "commit"
                ],
                "content": "            user = super().save(commit=False)\n            password = self.cleaned_data[\"password\"]\n            if password:\n                user.set_password(password)\n            if commit:\n                user.save()\n            return user"
            },
            {
                "function_name": "lookups",
                "parameters": [
                    "self",
                    "request",
                    "model_admin"
                ],
                "content": "            qs = model_admin.get_queryset(request)\n            lookups = []\n            for letter in self.letters:\n                count = qs.filter(title__istartswith=letter).count()\n                if count:\n                    lookups.append((letter, '{} ({})'.format(letter, count)))\n            return lookups"
            },
            {
                "function_name": "queryset",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            \n            filter_val = self.value()\n            if filter_val in self.letters:\n                return queryset.filter(title__istartswith=self.value())"
            },
            {
                "function_name": "lookups",
                "parameters": [
                    "self",
                    "request",
                    "model_admin"
                ],
                "content": "            return (\n                ('filled', _('Has content')),\n                ('empty', _('Empty content')),\n            )"
            },
            {
                "function_name": "queryset",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            if self.value() == 'filled':\n                return queryset.exclude(content__isnull=True).exclude(content__exact='')\n            if self.value() == 'empty':\n                return queryset.filter(content__isnull=True) | queryset.filter(content__exact='')"
            },
            {
                "function_name": "lookups",
                "parameters": [
                    "self",
                    "request",
                    "model_admin"
                ],
                "content": "            qs = model_admin.get_queryset(request)\n            lookups = []\n            for letter in self.letters:\n                count = qs.filter(company__name__istartswith=letter).count()\n                if count:\n                    lookups.append((letter, '{} ({})'.format(letter, count)))\n            return lookups"
            },
            {
                "function_name": "queryset",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            \n            filter_val = self.value()\n            if filter_val in self.letters:\n                return queryset.filter(company__name__istartswith=self.value())"
            },
            {
                "function_name": "lookups",
                "parameters": [
                    "self",
                    "request",
                    "model_admin"
                ],
                "content": "            qs = model_admin.get_queryset(request)\n            lookups = []\n            for letter in self.letters:\n                count = qs.filter(profile__last_name__istartswith=letter).count()\n                if count:\n                    lookups.append((letter, '{} ({})'.format(letter, count)))\n            return lookups"
            },
            {
                "function_name": "queryset",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            \n            filter_val = self.value()\n            if filter_val in self.letters:\n                return queryset.filter(profile__last_name__istartswith=self.value())"
            },
            {
                "function_name": "lookups",
                "parameters": [
                    "self",
                    "request",
                    "model_admin"
                ],
                "content": "            qs = model_admin.get_queryset(request)\n            lookups = []\n            for letter in self.letters:\n                count = qs.filter(name__istartswith=letter).count()\n                if count:\n                    lookups.append((letter, '{} ({})'.format(letter, count)))\n            return lookups"
            },
            {
                "function_name": "queryset",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            \n            filter_val = self.value()\n            if filter_val in self.letters:\n                return queryset.filter(name__istartswith=self.value())"
            },
            {
                "function_name": "lookups",
                "parameters": [
                    "self",
                    "request",
                    "model_admin"
                ],
                "content": "            qs = model_admin.get_queryset(request)\n            lookups = []\n            for letter in self.letters:\n                count = qs.filter(name__istartswith=letter).count()\n                if count:\n                    lookups.append((letter, '{} ({})'.format(letter, count)))\n            return lookups"
            },
            {
                "function_name": "queryset",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            \n            filter_val = self.value()\n            if filter_val in self.letters:\n                return queryset.filter(ticker__istartswith=self.value())"
            },
            {
                "function_name": "lookups",
                "parameters": [
                    "self",
                    "request",
                    "model_admin"
                ],
                "content": "            return [('today', 'Today')]"
            },
            {
                "function_name": "queryset",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            if self.value() == 'today':\n                return queryset.filter(last_login__gte = datetime.date.today())\n            if self.value():\n                return queryset.all()"
            },
            {
                "function_name": "before_import_row",
                "parameters": [
                    "self",
                    "row"
                ],
                "content": "            # Assuming that email field is used as the username\n            value = row.get('email')\n            print(value)\n            if value:\n                row['username'] = value\n                hashed_password = make_password(value)  # Set password same as username\n                row['password'] = hashed_password"
            },
            {
                "function_name": "get_urls",
                "parameters": [
                    "self"
                ],
                "content": "            urls = super().get_urls()\n            custom_urls = [\n                path('<int:user_id>/change_password/', self.admin_site.admin_view(self.change_password), name='change-password'),\n            ]\n            return custom_urls + urls"
            },
            {
                "function_name": "give_analyst_permission",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            \n            for user in queryset:\n                user.groups.clear()\n                user.groups.add(Group.objects.get(name=\"Analyst Group\"))"
            },
            {
                "function_name": "give_editor_permission",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            \n            for user in queryset:\n                user.groups.clear()\n                user.groups.add(Group.objects.get(name=\"Editor Group\"))"
            },
            {
                "function_name": "give_compliance_permission",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            \n            for user in queryset:\n                user.groups.clear()\n                user.groups.add(Group.objects.get(name=\"Compliance Group\"))"
            },
            {
                "function_name": "give_head_permission",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            \n            for user in queryset:\n                user.groups.clear()\n                user.groups.add(Group.objects.get(name=\"Head Group\"))"
            },
            {
                "function_name": "change_password",
                "parameters": [
                    "self",
                    "request",
                    "user_id"
                ],
                "content": "            user = User.objects.get(pk=user_id)\n    \n            if request.method == 'POST':\n                form = ChangeUserPasswordForm(request.POST)\n                if form.is_valid():\n                    user.password = make_password(form.cleaned_data['new_password'])\n                    user.save()\n                    self.message_user(request, \"Password changed successfully.\")\n                    return redirect('admin:auth_user_change', user_id)\n    \n            else:\n                form = ChangeUserPasswordForm()\n    \n            return render(request, 'change_password.html', {'form': form})"
            },
            {
                "function_name": "make_analyst",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            group = Group.objects.get(name=\"Analyst Group\")\n            for profile in queryset:\n                user = profile.user\n                # Clear the groups of the user\n                user.groups.clear()\n                # Add the user to the new group\n                user.groups.add(group)\n                # Update or create the Analyst\n                Analyst.objects.update_or_create(profile=profile, defaults={'sector': \"None\"})\n            updated = queryset.count()\n            self.message_user(\n                request,\n                ngettext(\n                    \"%d Profile was successfully made an analyst.\",\n                    \"%d Profiles were successfully made into analyst.\",\n                    updated,\n                )\n                % updated,\n                messages.SUCCESS,\n            )"
            },
            {
                "function_name": "hyper_phone",
                "parameters": [
                    "self",
                    "instance"
                ],
                "content": "            return format_html(\"<a href='tel:{0}'>{0}</a>\", instance.phone)"
            },
            {
                "function_name": "formfield_for_foreignkey",
                "parameters": [
                    "self",
                    "db_field",
                    "request"
                ],
                "content": "            if db_field.name == 'sales' or db_field.name == 'trading':\n                kwargs['queryset'] = Profile.objects.filter(is_sales_trader=True).exclude(id=request.resolver_match.kwargs.get('object_id'))\n            return super().formfield_for_foreignkey(db_field, request, **kwargs)"
            },
            {
                "function_name": "approve",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            queryset.update(approved=True, approved_by=request.user.profile)\n            for signup in queryset:\n                new_user = User.objects.create(username=signup.email, password=make_password(signup.email))\n                new_profile = Profile.objects.create(\n                    user=new_user,\n                    first_name=signup.first_name,\n                    last_name=signup.last_name,\n                    email=signup.email,\n                    phone=signup.phone,\n                    firm=signup.firm,\n                    title=signup.title,\n                    city=signup.city,\n                    country=signup.country,\n                    sales_contact=signup.sales,\n                    trading_contact=signup.trading\n                )\n    \n                send_html_email(\"Welcome to Paradigm Capital Research!\", signup.email)\n    \n                self.message_user(request, f\"{new_profile.email} user was approved.\", messages.SUCCESS)"
            },
            {
                "function_name": "reject",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            updated = queryset.update(approved=False, approved_by=None)  # Clear the approved_by field\n    \n            for signup in queryset:\n                try:\n                    user = User.objects.get(username=signup.email)\n                    profile = user.profile\n                    profile.approved = False\n                    profile.approved_by = None\n                    profile.save()\n                except (User.DoesNotExist, ObjectDoesNotExist):\n                    # Handle the case if the user or profile does not exist\n                    pass\n    \n            self.message_user(\n                request,\n                ngettext(\"%d user was rejected.\", \"%d users were rejected.\", updated) % updated,\n                messages.SUCCESS,\n            )"
            },
            {
                "function_name": "get_queryset",
                "parameters": [
                    "self",
                    "value",
                    "row"
                ],
                "content": "            queryset = super().get_queryset(value, row, *args, **kwargs)\n            if queryset.model.objects.filter(**{self.field: value}).exists():\n                return queryset\n            else:\n                obj = queryset.model.objects.create(**{self.field: value})\n                return queryset.model.objects.filter(pk=obj.pk)"
            },
            {
                "function_name": "before_import_row",
                "parameters": [
                    "self",
                    "row"
                ],
                "content": "           \n            report_type = row.get('Report type', '').lower() \n            if 'research note' in report_type:\n                row['Report type'] = 'Note' ##RESERACH NOTE NOW\n            elif any(term in report_type for term in ['flash', 'flashnote', 'intraday']): #cool way to check ;)\n                row['Report type'] = 'Flash Note'\n            elif any(term in report_type for term in ['initiating coverage', 'initiating report', 'initiating coverage', 'initiation report']):\n                row['Report type'] = 'Initiating Coverage'\n            company_name = row.get('Company name')\n            analyst_name = row.get('Main Analyst')\n            # first_name, last_name = analyst_name.strip().split(' ', 1)\n            # analyst = Analyst.objects.filter(profile__first_name__icontains=first_name, profile__last_name__icontains=last_name).first()\n            analyst = self.get_or_create_analyst(analyst_name)\n            if company_name and not Company.objects.filter(name=company_name).exists(): ##ticker=f\"TEMP{randint(1000, 9999)}\",  \n                Company.objects.create(\n                    name=company_name,\n                    ticker=row.get('Company Ticker'),  \n                    company_description=row.get('Company description'),\n                    analyst=analyst,\n                    investment_thesis=row.get('Investment thesis'),\n                    industry = row.get('Sector') or \"TEMPORARYVALUE\"\n                )\n            row['Main Analyst'] = analyst.id\n            print(\"DEBUGUG:\", row['Main Analyst'], 'id:',analyst.id)"
            },
            {
                "function_name": "get_or_create_analyst",
                "parameters": [
                    "self",
                    "analyst_name"
                ],
                "content": "            first_name, last_name = analyst_name.strip().split(' ', 1)\n            print(\"DEBUG: first, last name:\", first_name, \",\", last_name)\n            profile = None\n            analyst = None\n            try:\n                profile = Profile.objects.get(first_name__icontains=first_name, last_name__icontains=last_name)\n                print(\"no error:\", profile)\n            except ObjectDoesNotExist:\n                if Profile.objects.filter(first_name__icontains=first_name, last_name__icontains=last_name).exists():\n                    profile = Profile.objects.filter(first_name__icontains=first_name, last_name__icontains=last_name).first()\n                else:\n                    last_name_last_part = last_name.split()[-1]\n                    email = f\"{first_name[0]}{last_name_last_part}@paradigmcap.com\"\n                    new_user = User.objects.create(username=email, password=make_password(email))\n                    profile = Profile.objects.create(\n                                    user=new_user,\n                                    first_name=first_name,\n                                    last_name=last_name,\n                                    email=email,\n                                    phone=9999999999,\n                                    firm=\"TEMPORARY\",\n                                    title=\"TEMPORARY\",\n                                    city=\"TEMPORARY\",\n                                    country=\"TEMPORARY\"\n                                    )\n            if Analyst.objects.filter(profile=profile).exists():\n                analyst = Analyst.objects.filter(profile=profile).first()\n            else:\n                analyst = Analyst.objects.create(profile=profile, sector='TEMPORARYPROFILE')\n            print(\"The analyst?:\", analyst)\n            return analyst"
            },
            {
                "function_name": "save_model",
                "parameters": [
                    "self",
                    "request",
                    "obj",
                    "form",
                    "change"
                ],
                "content": "            obj.slug = slugify(f\"{obj.title} {obj.company.name}\")\n            super().save_model(request, obj, form, change)"
            },
            {
                "function_name": "display_pdf_link",
                "parameters": [
                    "self",
                    "obj"
                ],
                "content": "            if obj.pdf:\n                return format_html('<a href=\"{0}\" target=\"_blank\">View PDF</a>', obj.pdf.url)\n            return ''"
            },
            {
                "function_name": "move_to_draft",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            updated = queryset.update(is_reviewing=False, is_compliance=False, is_published=False, is_draft=True)\n            self.message_user(\n                request,\n                ngettext(\n                    \"%d Report was succesfully changed to draft.\",\n                    \"%d Report were succesfully changed to draft\",\n                    updated,\n                )\n                % updated,\n                messages.SUCCESS,\n            )"
            },
            {
                "function_name": "move_to_review",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            updated = queryset.update(is_reviewing=True, is_compliance=False, is_published=False, is_draft=False)\n            self.message_user(\n                request,\n                ngettext(\n                    \"%d Report was succesfully changed to review.\",\n                    \"%d Report were succesfully changed to review\",\n                    updated,\n                )\n                % updated,\n                messages.SUCCESS,\n            )"
            },
            {
                "function_name": "move_to_complaince",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            updated = queryset.update(is_reviewing=False, is_compliance=True, is_published=False, is_draft=False)\n            self.message_user(\n                request,\n                ngettext(\n                    \"%d Report was succesfully changed to compliance.\",\n                    \"%d Report were succesfully changed to compliance\",\n                    updated,\n                )\n                % updated,\n                messages.SUCCESS,\n            )"
            },
            {
                "function_name": "move_to_publishing",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            updated = queryset.update(is_reviewing=False, is_compliance=False, is_published=True, is_draft=False)\n            self.message_user(\n                request,\n                ngettext(\n                    \"%d Report was succesfully changed to publishing.\",\n                    \"%d Report were succesfully changed to publishing\",\n                    updated,\n                )\n                % updated,\n                messages.SUCCESS,\n            )"
            },
            {
                "function_name": "lookups",
                "parameters": [
                    "self",
                    "request",
                    "model_admin"
                ],
                "content": "            letters = set()\n            for log in model_admin.model.objects.all():\n                letters.add(log.title[0].upper())\n            return sorted((l, l) for l in letters)"
            },
            {
                "function_name": "queryset",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            if self.value():\n                return queryset.filter(title__istartswith=self.value())"
            },
            {
                "function_name": "lookups",
                "parameters": [
                    "self",
                    "request",
                    "model_admin"
                ],
                "content": "            letters = set()\n            for log in model_admin.model.objects.all():\n                if log.report and log.report.name:\n                    letters.add(log.report.name[0].upper())\n            return sorted((l, l) for l in letters)"
            },
            {
                "function_name": "queryset",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            if self.value():\n                return queryset.filter(report__name__istartswith=self.value())"
            },
            {
                "function_name": "lookups",
                "parameters": [
                    "self",
                    "request",
                    "model_admin"
                ],
                "content": "            letters = set()\n            for log in model_admin.model.objects.all():\n                if log.report and log.report.company.name:\n                    letters.add(log.report.company.name[0].upper())\n            return sorted((l, l) for l in letters)"
            },
            {
                "function_name": "queryset",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            if self.value():\n                return queryset.filter(report__company__name__istartswith=self.value())"
            },
            {
                "function_name": "lookups",
                "parameters": [
                    "self",
                    "request",
                    "model_admin"
                ],
                "content": "            letters = set()\n            for log in model_admin.model.objects.all():\n                if log.by_whom and log.by_whom.first_name:\n                    letters.add(log.by_whom.first_name[0].upper())\n            return sorted((l, l) for l in letters)"
            },
            {
                "function_name": "queryset",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            if self.value():\n                return queryset.filter(by_whom__first_name__istartswith=self.value())"
            },
            {
                "function_name": "before_import_row",
                "parameters": [
                    "self",
                    "row"
                ],
                "content": "            # Process pdf_path\n            pdf_path = row['pdf_path'].replace(\"C:_Users_aleja_OneDrive_Escritorio_WORK_FIRST_OF_EACH_company_tables_AWS_EXCEL_company_tables_AWS_EXCEL_\", \"\").replace(\".csv\", \"\").replace(\"_\", \" \").strip()\n            \n            company = None\n            try:\n                report = Report.objects.get(temp_pdf_path__icontains=pdf_path)\n                company = report.company\n            except Report.DoesNotExist:\n                ticker = pdf_path.split()[0]\n                try:\n                    company = Company.objects.filter(ticker=ticker).first()\n                except Company.DoesNotExist:\n                    print(f\"No company found for ticker: {ticker}\")\n    \n            if company:\n                row['company'] = company.id\n                row['is_estimate'] = False\n            else:\n                print(f\"Skipping row due to missing company: {row}\")\n                raise ObjectDoesNotExist(\"Missing company for row\")\n    \n            name = row['name']\n            metrics = [\"price\", \"FYE\", \"potential ror\", \"avg 3month daily vol\", \"shares basic\", \"shares fd\", \"marketcap basic\", \"marketcap fd\", \"revenue\", \"gross profit\"]\n            for metric in metrics:\n                \n                if name.lower() == 'fye':\n                    print('INNNN')\n                    company.FYE = row['amount']\n                    print('out')\n                    company.save()\n                    print(f\"Matched FYE: {metric}, updated company: {company}\")\n                    return\n                elif fuzz.ratio(name.lower(), metric.lower()) > 70:\n                    setattr(company, metric, row['amount'])\n                    company.save()\n                    print(f\"Matched metric: {metric}, updated company: {company}\")\n                    return"
            },
            {
                "function_name": "make_all_metrics",
                "parameters": [
                    "self",
                    "request",
                    "queryset"
                ],
                "content": "            \n            for metric in queryset:\n                metric.is_estimate = False\n                metric.save()"
            }
        ],
        "imports": [
            "django.core.files.base.ContentFile",
            "django.utils.timezone.now",
            "models.ExcelStatistic",
            "models.GeneralLog",
            "models.Profile",
            "import_export.widgets",
            "models.NewsObject",
            "models.Signup",
            "models.ReportMetric",
            "models.MagicLinkToken",
            "models.SectorMetric",
            "django.contrib.admin",
            "django.contrib.auth.models.User",
            "django.shortcuts.get_object_or_404",
            "django.contrib.messages",
            "models.Disclaimer",
            "random.randint",
            "models.Section",
            "import_export.resources",
            "django.utils.text.slugify",
            "typing.Any",
            "models.ReportGroup",
            "fuzzywuzzy.fuzz",
            "django.shortcuts.redirect",
            "django.urls.path",
            "models.CompanyDisclaimer",
            "models.Company",
            "django.shortcuts.render",
            "forms.ChangeUserPasswordForm",
            "string",
            "django.core.exceptions.ObjectDoesNotExist",
            "import_export.fields",
            "django.forms",
            "import_export.fields.Field",
            "django.utils.translation.gettext_lazy",
            "models.CompanyMetric",
            "import_export.widgets.ManyToManyWidget",
            "django.contrib.admin.SimpleListFilter",
            "models.Analyst",
            "django.utils.html.format_html",
            "django.utils.translation.ngettext",
            "utils.send_html_email",
            "datetime",
            "django.contrib.auth.hashers.make_password",
            "import_export.admin.ImportExportModelAdmin",
            "import_export.widgets.ForeignKeyWidget",
            "models.ReportDisclaimer",
            "django.contrib.auth.models.Group",
            "models.Report",
            "django.http.HttpResponseRedirect"
        ]
    },
    {
        "name_of_file": "forms.py",
        "functions": [
            {
                "function_name": "__init__",
                "parameters": [
                    "self"
                ],
                "content": "            super(SignupForm, self).__init__(*args, **kwargs)\n            self.fields['country'].widget.attrs.update({\n                'class': 'shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline'\n            })"
            },
            {
                "function_name": "clean",
                "parameters": [
                    "self"
                ],
                "content": "            cleaned_data = super().clean()\n            password = cleaned_data.get('new_password')\n            confirm_password = cleaned_data.get('new_password_confirm')\n    \n            if password != confirm_password:\n                raise forms.ValidationError(\"Passwords must match.\")\n    \n            return cleaned_data"
            }
        ],
        "imports": [
            "models.Signup",
            "tinymce.widgets.TinyMCE",
            "django_countries.fields.CountryField",
            "django.forms",
            "models.Report"
        ]
    },
    {
        "name_of_file": "middleware.py",
        "functions": [
            {
                "function_name": "__init__",
                "parameters": [
                    "self",
                    "get_response"
                ],
                "content": "            self.get_response = get_response"
            },
            {
                "function_name": "__call__",
                "parameters": [
                    "self",
                    "request"
                ],
                "content": "            response = self.get_response(request)\n            if request.user.is_authenticated:\n                logger.info(f'User {request.user.username} did a {request.method} request at {request.path}')\n            return response"
            },
            {
                "function_name": "process_response",
                "parameters": [
                    "self",
                    "req",
                    "resp"
                ],
                "content": "            origin = req.META.get('HTTP_ORIGIN')\n            if origin and 'officescripts.microsoftusercontent.com' in origin:\n                resp['Access-Control-Allow-Origin'] = origin\n                resp['Access-Control-Allow-Methods'] = 'POST, GET, OPTIONS, PUT, DELETE'\n                resp['Access-Control-Allow-Headers'] = 'Content-Type, Authorization'\n                resp['Access-Control-Allow-Credentials'] = 'true'\n                \n            return resp"
            }
        ],
        "imports": [
            "logging",
            "django.utils.deprecation.MiddlewareMixin"
        ]
    },
    {
        "name_of_file": "models.py",
        "functions": [
            {
                "function_name": "full_name",
                "parameters": [
                    "self"
                ],
                "content": "            return f\"{self.first_name} {self.last_name}\""
            },
            {
                "function_name": "__str__",
                "parameters": [
                    "self"
                ],
                "content": "            return f\"{self.first_name} {self.last_name}\""
            },
            {
                "function_name": "full_name",
                "parameters": [
                    "self"
                ],
                "content": "            return f\"{self.first_name} {self.last_name}\""
            },
            {
                "function_name": "__str__",
                "parameters": [
                    "self"
                ],
                "content": "            return f\"{self.firm}| {self.first_name} {self.last_name}\""
            },
            {
                "function_name": "__str__",
                "parameters": [
                    "self"
                ],
                "content": "            return self.profile.full_name"
            },
            {
                "function_name": "__str__",
                "parameters": [
                    "self"
                ],
                "content": "            if self.is_estimate == True:\n                return f\"{self.name} {self.year_estimated}\" \n            return self.name"
            },
            {
                "function_name": "save",
                "parameters": [
                    "self"
                ],
                "content": "            super().save(*args, **kwargs)  \n            if self.metrics:\n                new_metric_names = []\n                for line in self.metrics.split('\\n'):\n                    metric_name, metric_value = line.split(\":\")\n                    metric_name = metric_name.strip()\n                    metric_value = metric_value.strip()\n                    new_metric_names.append(metric_name)\n    \n                   \n                    company_metric, created = CompanyMetric.objects.get_or_create(\n                        company=self,\n                        name=metric_name,\n                        defaults={\"amount\": metric_value}\n                    )\n    \n                    if not created:\n                       \n                        company_metric.amount = metric_value\n                        company_metric.save()\n    \n               \n                CompanyMetric.objects.filter(company=self).exclude(name__in=new_metric_names).delete()"
            },
            {
                "function_name": "__str__",
                "parameters": [
                    "self"
                ],
                "content": "            return f\"{self.name}\""
            },
            {
                "function_name": "get_absolute_url",
                "parameters": [
                    "self"
                ],
                "content": "            return reverse(\"company\", kwargs={\"slug\": self.slug})"
            },
            {
                "function_name": "__str__",
                "parameters": [
                    "self"
                ],
                "content": "            return self.name if self.name else self.industry"
            },
            {
                "function_name": "__str__",
                "parameters": [
                    "self"
                ],
                "content": "            return f\"{self.name}: {self.amount} (Year: {self.year_estimated})\""
            },
            {
                "function_name": "upload_path",
                "parameters": [
                    "instance",
                    "filename"
                ],
                "content": "            return \"{0}/{1}\".format(instance.company.ticker, filename)"
            },
            {
                "function_name": "save",
                "parameters": [
                    "self"
                ],
                "content": "            if not self.slug:\n                # print(\"BIGG DEBUG: title:\", self.title, \", Company TICKER:\", self.company.ticker)\n                print(self.company)\n                self.slug = slugify(self.title + \"-\" + self.company.ticker) ##THERE IS A SPACE BEHIND THE -, CHECK HERE IF ERRORS!!!!!!!!############# I CHANGED IT BE CAREFUL\n    \n    \n            if self.event:\n                sentences = re.split(r'[-;,.\\s]\\s*', self.event)\n                # print(sentences)\n                truncated_event = ' '.join(sentences[:COUNT_OF_TRUNCATED_SENTENCES])\n                self.truncated_event = truncated_event\n    \n            if self.content:\n                from .utils import get_headings_and_texts ## LEAVE IT HERE, this lazy import fixes a circular import with .utils, else we cant use models in utils\n                \n                sections = get_headings_and_texts(self.content)\n                \n                i = 0\n                self.save_base() ##not fully sure why this worked but this saves the report as an instance once and then lets us play with the sections\n                # print(Section.objects.filter(report=self))\n                queryset = Section.objects.filter(report=self).delete()\n                for sectionT in sections:\n    \n                    \n    \n                    section = Section()\n                    section.report = self\n                    section.title = sectionT[0]\n                    section.content = sectionT[1]\n                    section.order = i\n                    i += 1\n                    section.save()\n                \n            \n            # print(self.other_analysts.all())\n            # if len(self.other_analysts.all()) == 0 and self.report_group: ##Not working GIVES ERRORS WITH EXPORT IMPORT\n                \n            #     query = Analyst.objects.filter(sector=self.report_group.name).all()\n            #     print(\"in\")\n            #     print(query)\n                \n            #     self.other_analysts.set(query)\n                # self.other_analysts.clear()\n                # for an in query:\n                #     self.other_analysts.add(Analyst.objects.get(profile__first_name=an.profile.first_name))\n                \n                \n            \n            \n            # print(self.other_analysts.all())\n            \n            super().save(*args, **kwargs)"
            },
            {
                "function_name": "get_absolute_url",
                "parameters": [
                    "self"
                ],
                "content": "            return reverse(\"report\", kwargs={\"slug\": self.slug})"
            },
            {
                "function_name": "__str__",
                "parameters": [
                    "self"
                ],
                "content": "            return f\"{self.title}\""
            },
            {
                "function_name": "embed_string",
                "parameters": [
                    "self"
                ],
                "content": "    \n            soup = BeautifulSoup(self.content, 'html.parser')\n            \n            # kill all script and style elements\n            for script in soup([\"script\", \"style\"]):\n                script.extract()  # rip it out\n            \n            # get text\n            text = soup.get_text()\n            \n            # break into lines and remove leading and trailing space on each\n            lines = (line.strip() for line in text.splitlines())\n            \n            # break multi-headlines into a line each\n            chunks = (phrase.strip() for line in lines for phrase in line.split(\" \"))\n            \n            # drop blank lines\n            text = '\\n'.join(chunk for chunk in chunks if chunk)\n            \n            return f\"{self.title}, {self.takeout}, {self.event}, {self.valuation}, {text}\""
            },
            {
                "function_name": "__str__",
                "parameters": [
                    "self"
                ],
                "content": "            return f\"{self.title}\""
            },
            {
                "function_name": "create_log",
                "parameters": [
                    "self",
                    "event",
                    "title",
                    "event_description"
                ],
                "content": "            self.title = title or f\"Report {event}\"\n            self.event_description = event_description or f\"The report was \\\"{event}\\\" by {self.by_whom}\"\n            self.save()"
            },
            {
                "function_name": "created_draft",
                "parameters": [
                    "self",
                    "title",
                    "event_description"
                ],
                "content": "            self.create_log( \"created as draft\", title, event_description)"
            },
            {
                "function_name": "moved_to_edit",
                "parameters": [
                    "self",
                    "title",
                    "event_description"
                ],
                "content": "            self.create_log(\"moved to edit\", title, event_description)"
            },
            {
                "function_name": "sent_back_to_analyst",
                "parameters": [
                    "self",
                    "title",
                    "event_description"
                ],
                "content": "            self.create_log(\"sent back to analyst\", title, event_description)"
            },
            {
                "function_name": "sent_back_to_editor",
                "parameters": [
                    "self",
                    "title",
                    "event_description"
                ],
                "content": "            self.create_log(\"sent back to editor\", title, event_description)"
            },
            {
                "function_name": "moved_to_compliance",
                "parameters": [
                    "self",
                    "title",
                    "event_description"
                ],
                "content": "            self.create_log(\"moved to compliance\", title, event_description)"
            },
            {
                "function_name": "approved_to_publish",
                "parameters": [
                    "self",
                    "title",
                    "event_description"
                ],
                "content": "            self.create_log(\"approved to publish\", title, event_description)"
            },
            {
                "function_name": "deleted_draft",
                "parameters": [
                    "self",
                    "title",
                    "event_description"
                ],
                "content": "            self.create_log(\"deleted draft\", title, event_description)"
            },
            {
                "function_name": "validate_legacy",
                "parameters": [
                    "self",
                    "title",
                    "event_description"
                ],
                "content": "            self.create_log(\"validated legacy report\", title, event_description)"
            }
        ],
        "imports": [
            "django.urls.reverse",
            "django.utils.text.slugify",
            "re",
            "bs4.BeautifulSoup",
            "django.db.models",
            "utils.get_headings_and_texts",
            "django.contrib.auth.models.User",
            "tinymce.models.HTMLField"
        ]
    },
    {
        "name_of_file": "tests.py",
        "functions": [
            {
                "function_name": "setUp",
                "parameters": [
                    "self"
                ],
                "content": "            # first report data\n            title1 = 'Test title 1'\n            publish_date1 = datetime.datetime.now()\n            event1 = \"The biggest event\"\n            slug1 = \"test-title-1\"\n            type1 = 'Research Note'\n            truncatedEvent1 = \"The biggest event\"\n            target1 = 99.99\n            rating1 = 'Buy'\n            \n    \n            # other models\n            testUser1 = User.objects.create(username='test@gmail.com', password=make_password('test@gmail.com'))\n           \n            new_profile = Profile.objects.create(\n                    user=testUser1,\n                    first_name= 'First Name test',\n                    last_name= 'Last N test',\n                    email= 'test@gmail.com',\n                    phone= '2893761844',\n                    firm= 'Paradigm',\n                    title= 'Analyst',\n                    city= 'Toronto',\n                    country= 'Canada'\n                )\n            \n            analyst1 = Analyst.objects.create(profile=new_profile, sector='Testing Sector')\n    \n            compName = 'The comp'\n            compTicker = 'TCT'\n            compIndustry = 'Technology'\n            compCurrentTarget = 4.32\n            compAnalyst = analyst1\n            compSlug = 'the-comp'\n            compCoverage = True\n            \n            company1 = Company.objects.create(name=compName,\n                                              ticker=compTicker,\n                                              industry=compIndustry,\n                                              current_target=compCurrentTarget,\n                                              analyst=compAnalyst,\n                                              slug=compSlug,\n                                              coverage=compCoverage\n                                              )\n            \n            reportGroup1 = ReportGroup.objects.create(name='The testing group', industry=compIndustry)\n    \n            firstReport = Report.objects.create(title=title1,\n                                                company=company1,\n                                                publish_date=publish_date1,\n                                                event=event1,\n                                                analyst=analyst1,\n                                                slug=slug1,\n                                                type=type1,\n                                                report_group=reportGroup1,\n                                                target=target1,\n                                                rating=rating1,\n                                                truncated_event=truncatedEvent1\n                                                )\n            \n            self.client = Client()"
            },
            {
                "function_name": "test_login",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************Testing_login_page************************')\n            print()\n    \n            response = self.client.get(\"http://127.0.0.1:8000/login\")\n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n            self.assertTemplateUsed(response, 'login.html')"
            },
            {
                "function_name": "test_login_with_a_empty_user",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************Testing_login_page_with_a_empty_user************************')\n            print()\n            empty_loggin_data = {'username':'', 'password':''}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=empty_loggin_data)\n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            \n            self.assertIn(b'Invalid username or password.', response.content)\n    \n            self.assertTemplateUsed(response, 'login.html')"
            },
            {
                "function_name": "test_login_with_an_invalid_user",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_login_with_an_invalid_user************************')\n            print()\n            loggin_data = {'username':'NOTVALIDUSER@gmail.com', 'password':'NOTAVALIDPASSWORD'}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            \n            self.assertIn(b'Invalid username or password.', response.content)\n    \n            self.assertTemplateUsed(response, 'login.html')"
            },
            {
                "function_name": "test_login_with_a_valid_user",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_login_with_a_valid_user************************')\n            print()\n    \n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            loggin_data = {'username':testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 302) ##redirect, need to start using rest_f moving forward\n    \n            \n            self.assertNotIn(b'Invalid username or password.', response.content)\n    \n            #self.assertTemplateUsed(response, 'login.html')\n            self.assertRedirects(response, '/home')"
            },
            {
                "function_name": "test_empty_search_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_empty_search_works************************')\n            print()\n    \n            # testUser1 = User.objects.filter(username='test@gmail.com').first()\n            # loggin_data = {'username':testUser1.username, 'password': testUser1.username}\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            loggin_data = {'username':testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n            response = self.client.get(\"http://127.0.0.1:8000/search/?q=\")\n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n            self.assertTemplateUsed(response, 'search_results.html')"
            },
            {
                "function_name": "test_search_buttons_in_filter_search_work",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_search_buttons_in_filter_search_work************************')\n            print()\n            #testReport = Report.objects.filter(title='Test title 1').first()\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            loggin_data = {'username':testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n    \n            response = self.client.get(\"?publishDateStart=2023-09-01&publishDateEnd=2023-09-30&analyst=aa%40gmail.com&company_ticker=TTT\")\n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)"
            },
            {
                "function_name": "test_search_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_search_works************************')\n            print()\n            #testReport = Report.objects.filter(title='Test title 1').first()\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            loggin_data = {'username':testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n    \n            response = self.client.get(\"http://127.0.0.1:8000/search/?q=Test+Title+1\")\n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            self.assertIn(b'The biggest event', response.content) ## check that it shows  up by looking for the event description\n            self.assertNotIn(b'INCORRECT EVENT', response.content)\n            self.assertTemplateUsed(response, 'search_results.html')"
            },
            {
                "function_name": "test_empty_search_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_empty_search_works************************')\n            print()\n            #testReport = Report.objects.filter(title='Test title 1').first()\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            loggin_data = {'username':testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n    \n            response = self.client.get(\"http://127.0.0.1:8000/search/?q=\")\n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            self.assertIn(b'The biggest event', response.content) ## check that it shows  up by looking for the event description\n            self.assertNotIn(b'INCORRECT EVENT', response.content)\n            self.assertTemplateUsed(response, 'search_results.html')"
            },
            {
                "function_name": "test_search_sorting_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_search_sorting_works************************')\n            print()\n            #testReport = Report.objects.filter(title='Test title 1').first()\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            loggin_data = {'username':testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n    \n            response = self.client.get(\"http://127.0.0.1:8000/search/?q=Test%20Title%201&page=1sort=date_year&sort=date_year&direction=asc\")\n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            response = self.client.get(\"http://127.0.0.1:8000/search/?q=Test%20Title%201&page=1sort=date_year&sort=date_month&direction=asc\")\n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n            \n            response = self.client.get(\"http://127.0.0.1:8000/search/?q=Test%20Title%201&page=1sort=date_year&sort=date_day&direction=asc\")\n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            response = self.client.get(\"http://127.0.0.1:8000/search/?q=Test%20Title%201&page=1sort=date_year&sort=company_name&direction=asc\")\n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            response = self.client.get(\"http://127.0.0.1:8000/search/?q=Test%20Title%201&page=1sort=date_year&sort=company_ticker&direction=asc\")\n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            response = self.client.get(\"http://127.0.0.1:8000/search/?q=Test%20Title%201&page=1sort=date_year&sort=company_industry&direction=asc\")\n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            response = self.client.get(\"http://127.0.0.1:8000/search/?q=Test%20Title%201&page=1sort=date_year&sort=analyst_first_name&direction=asc\")\n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            response = self.client.get(\"http://127.0.0.1:8000/search/?q=Test%20Title%201&page=1sort=date_year&sort=analyst_last_name&direction=asc\")\n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)"
            },
            {
                "function_name": "test_profile_page_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_profile_page_works************************')\n            print()\n            \n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            profile1 = Profile.objects.filter(first_name='First Name test').first()\n            loggin_data = {'username': testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n            response = self.client.get(\"http://127.0.0.1:8000/profile\")\n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            response_content_str = response.content.decode('utf-8')\n            self.assertIn(profile1.email, response_content_str) \n            self.assertIn(profile1.phone, response_content_str)\n            self.assertIn(profile1.firm, response_content_str)\n            self.assertIn(profile1.title, response_content_str)\n            self.assertTemplateUsed(response, 'profile.html')"
            },
            {
                "function_name": "test_change_password_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_change_password_works************************')\n            print()\n    \n            # Setup code for logging in\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            profile1 = Profile.objects.filter(first_name='First Name test').first()\n            loggin_data = {'username': testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n    \n            response = self.client.get(\"http://127.0.0.1:8000/password_change\")\n    \n    \n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            # Check that the response contains certain text.\n            response_content_str = response.content.decode('utf-8')\n            self.assertIn('Reset Password', response_content_str)\n    \n            # Check that the correct template was used\n            self.assertTemplateUsed(response, 'change_password.html')"
            },
            {
                "function_name": "test_company_page_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_company_page_works************************')\n            print()\n    \n            # Setup code for logging in\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            profile1 = Profile.objects.filter(first_name='First Name test').first()\n            loggin_data = {'username': testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n    \n            response = self.client.get(\"http://127.0.0.1:8000/company/the-comp\")\n    \n    \n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            # Check that the response contains certain text.\n            response_content_str = response.content.decode('utf-8')\n            self.assertIn('Comp', response_content_str)\n    \n            # Check that the correct template was used\n            self.assertTemplateUsed(response, 'company_page.html')"
            },
            {
                "function_name": "test_drafter_mainpage_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_drafter_mainpage_works************************')\n            print()\n    \n            # Setup code for logging in\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            profile1 = Profile.objects.filter(first_name='First Name test').first()\n            loggin_data = {'username': testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n    \n            response = self.client.get(\"http://127.0.0.1:8000/drafter/\")\n    \n    \n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            # Check that the response contains certain text.\n            response_content_str = response.content.decode('utf-8')\n            self.assertIn('your text here', response_content_str)\n    \n            # Check that the correct template was used\n            self.assertTemplateUsed(response, 'drafter_mainpage.html')"
            },
            {
                "function_name": "test_email_template_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_email_template_works************************')\n            print()\n    \n            # Setup code for logging in\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            profile1 = Profile.objects.filter(first_name='First Name test').first()\n            loggin_data = {'username': testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n    \n            response = self.client.get(\"http://127.0.0.1:8000/report/<slug:slug>/email-template/\")\n    \n    \n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            # Check that the response contains certain text.\n            response_content_str = response.content.decode('utf-8')\n            self.assertIn('your text here', response_content_str)\n    \n            # Check that the correct template was used\n            self.assertTemplateUsed(response, 'email_template.html')"
            },
            {
                "function_name": "test_home_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_home_works************************')\n            print()\n    \n            # Setup code for logging in\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            profile1 = Profile.objects.filter(first_name='First Name test').first()\n            loggin_data = {'username': testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n    \n            response = self.client.get(\"http://127.0.0.1:8000/home\")\n    \n    \n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            # Check that the response contains certain text.\n            response_content_str = response.content.decode('utf-8')\n            self.assertIn('your text here', response_content_str)\n    \n            # Check that the correct template was used\n            self.assertTemplateUsed(response, 'home.html')"
            },
            {
                "function_name": "test_login_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_login_works************************')\n            print()\n    \n            # Setup code for logging in\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            profile1 = Profile.objects.filter(first_name='First Name test').first()\n            loggin_data = {'username': testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n    \n            response = self.client.get(\"http://127.0.0.1:8000/login\")\n    \n    \n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            # Check that the response contains certain text.\n            response_content_str = response.content.decode('utf-8')\n            self.assertIn('your text here', response_content_str)\n    \n            # Check that the correct template was used\n            self.assertTemplateUsed(response, 'login.html')"
            },
            {
                "function_name": "test_magic_link_login_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_magic_link_login_works************************')\n            print()\n    \n            # Setup code for logging in\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            profile1 = Profile.objects.filter(first_name='First Name test').first()\n            loggin_data = {'username': testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n    \n            response = self.client.get(\"http://127.0.0.1:8000/login/magic-link-login/<slug:token>\")\n    \n    \n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            # Check that the response contains certain text.\n            response_content_str = response.content.decode('utf-8')\n            self.assertIn('your text here', response_content_str)\n    \n            # Check that the correct template was used\n            self.assertTemplateUsed(response, 'magic_link_login.html')"
            },
            {
                "function_name": "test_magic_link_screen_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_magic_link_screen_works************************')\n            print()\n    \n            # Setup code for logging in\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            profile1 = Profile.objects.filter(first_name='First Name test').first()\n            loggin_data = {'username': testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n    \n            response = self.client.get(\"http://127.0.0.1:8000/login/magic-link/\")\n    \n    \n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            # Check that the response contains certain text.\n            response_content_str = response.content.decode('utf-8')\n            self.assertIn('your text here', response_content_str)\n    \n            # Check that the correct template was used\n            self.assertTemplateUsed(response, 'magic_link_screen.html')"
            },
            {
                "function_name": "test_pdf_report_template_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_pdf_report_template_works************************')\n            print()\n    \n            # Setup code for logging in\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            profile1 = Profile.objects.filter(first_name='First Name test').first()\n            loggin_data = {'username': testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n    \n            response = self.client.get(\"http://127.0.0.1:8000/pdf-template/<slug:slug>/\")\n    \n    \n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            # Check that the response contains certain text.\n            response_content_str = response.content.decode('utf-8')\n            self.assertIn('your text here', response_content_str)\n    \n            # Check that the correct template was used\n            self.assertTemplateUsed(response, 'pdf_report_template.html')"
            },
            {
                "function_name": "test_profile_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_profile_works************************')\n            print()\n    \n            # Setup code for logging in\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            profile1 = Profile.objects.filter(first_name='First Name test').first()\n            loggin_data = {'username': testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n    \n            response = self.client.get(\"http://127.0.0.1:8000/profile\")\n    \n    \n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            # Check that the response contains certain text.\n            response_content_str = response.content.decode('utf-8')\n            self.assertIn('your text here', response_content_str)\n    \n            # Check that the correct template was used\n            self.assertTemplateUsed(response, 'profile.html')"
            },
            {
                "function_name": "test_report_page_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_report_page_works************************')\n            print()\n    \n            # Setup code for logging in\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            profile1 = Profile.objects.filter(first_name='First Name test').first()\n            loggin_data = {'username': testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n    \n            response = self.client.get(\"http://127.0.0.1:8000/report/<slug:slug>/\")\n    \n    \n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            # Check that the response contains certain text.\n            response_content_str = response.content.decode('utf-8')\n            self.assertIn('your text here', response_content_str)\n    \n            # Check that the correct template was used\n            self.assertTemplateUsed(response, 'report_page.html')"
            },
            {
                "function_name": "test_search_results_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_search_results_works************************')\n            print()\n    \n            # Setup code for logging in\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            profile1 = Profile.objects.filter(first_name='First Name test').first()\n            loggin_data = {'username': testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n    \n            response = self.client.get(\"http://127.0.0.1:8000/search/\")\n    \n    \n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            # Check that the response contains certain text.\n            response_content_str = response.content.decode('utf-8')\n            self.assertIn('your text here', response_content_str)\n    \n            # Check that the correct template was used\n            self.assertTemplateUsed(response, 'search_results.html')"
            },
            {
                "function_name": "test_signup_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_signup_works************************')\n            print()\n    \n            # Setup code for logging in\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            profile1 = Profile.objects.filter(first_name='First Name test').first()\n            loggin_data = {'username': testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n    \n            response = self.client.get(\"http://127.0.0.1:8000/signup\")\n    \n    \n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            # Check that the response contains certain text.\n            response_content_str = response.content.decode('utf-8')\n            self.assertIn('your text here', response_content_str)\n    \n            # Check that the correct template was used\n            self.assertTemplateUsed(response, 'signup.html')"
            },
            {
                "function_name": "test_signup_confirm_works",
                "parameters": [
                    "self"
                ],
                "content": "            print()\n            print()\n            print()\n            print('********************test_signup_confirm_works************************')\n            print()\n    \n            # Setup code for logging in\n            testUser1 = User.objects.filter(username='test@gmail.com').first()\n            profile1 = Profile.objects.filter(first_name='First Name test').first()\n            loggin_data = {'username': testUser1.username, 'password': testUser1.username}\n            response = self.client.post(\"http://127.0.0.1:8000/login\", data=loggin_data)\n    \n    \n            response = self.client.get(\"http://127.0.0.1:8000/signup_confirm\")\n    \n    \n            print('Response status code : ' + str(response.status_code))\n            self.assertEqual(response.status_code, 200)\n    \n            # Check that the response contains certain text.\n            response_content_str = response.content.decode('utf-8')\n            self.assertIn('your text here', response_content_str)\n    \n            # Check that the correct template was used\n            self.assertTemplateUsed(response, 'signup_confirm.html')"
            }
        ],
        "imports": [
            "models.Profile",
            "models.Signup",
            "django.test.TestCase",
            "django.test.Client",
            "django.contrib.auth.hashers.make_password",
            "datetime",
            "models.MagicLinkToken",
            "models.ReportGroup",
            "django.test.utils.teardown_test_environment",
            "django.test.LiveServerTestCase",
            "models.Company",
            "models.User",
            "django.test.utils.setup_test_environment",
            "models.Report",
            "models.Analyst"
        ]
    },
    {
        "name_of_file": "utils.py",
        "functions": [
            {
                "function_name": "send_html_email",
                "parameters": [
                    "subject",
                    "recipient"
                ],
                "content": "        # Render the HTML template with the provided context data\n        html_content = render_to_string('email_template.html')\n    \n        # Send the email using Django's send_mail function\n        send_mail(\n            subject=subject,\n            message='',  # Leave it empty as we're sending HTML content\n            from_email='myamani@paradigmcap.com',  # Use the default sender specified in EMAIL_HOST_USER\n            recipient_list=[recipient],\n            html_message=html_content\n        )",
                "documentation": "This function simplifies the distribution of emails by taking in directly the recipient and the subject of the email"
            },
            {
                "function_name": "process_json",
                "parameters": [
                    "json_data"
                ],
                "content": "        url_metrics = {}\n    \n        # Iterate through each metric object\n        for metric in json_data:\n            metric_name = metric['metricName']\n    \n            # Iterate through each item in the 'information' list\n            for info in metric['information']:\n                url = info['Url']\n    \n                # Remove the 'Url' key from the info dictionary\n                info.pop('Url', None)\n    \n                # Initialize a new dictionary for the URL if not already present\n                if url not in url_metrics:\n                    url_metrics[url] = {}\n    \n                # Add the metric information to the URL's dictionary\n                url_metrics[url][metric_name] = info\n    \n        return url_metrics",
                "documentation": "machine learing helper function that takes in the clariyt information into json"
            },
            {
                "function_name": "calculate_custom_scores",
                "parameters": [
                    "json_data",
                    "weights"
                ],
                "content": "        def calculate_aggregate(data, exclude_keys):\n            values = [float(data[key]) for key in data if key not in exclude_keys and data[key] is not None]\n            return sum(values) / len(values) if values else 0\n    \n        def normalize_scores(scores):\n            min_score = min(scores)\n            max_score = max(scores)\n            range_score = max_score - min_score\n            if range_score == 0:\n                return [0 if s <= 0 else 1 for s in scores] # Handle the case where all scores are the same\n            return [(s - min_score) / range_score for s in scores]\n    \n        raw_scores = []\n    \n        # Filter URLs to only include those containing '/report/'\n        filtered_json_data = {url: metrics for url, metrics in json_data.items() if '/report/' in url and '//research' in url}\n    \n        for url, metrics in filtered_json_data.items():\n            total_score = 0\n            for metric, values in metrics.items():\n                exclude_keys = ['sessionsWithoutMetricPercentage'] if metric in ['DeadClickCount', 'ExcessiveScroll', 'RageClickCount', 'QuickbackClick', 'ScriptErrorCount', 'ErrorClickCount'] else []\n                exclude_keys += ['totalBotSessionCount'] if metric == 'Traffic' else []\n                \n                metric_value = calculate_aggregate(values, exclude_keys)\n                total_score += metric_value * weights.get(metric, 0)\n    \n            raw_scores.append((url, total_score))\n    \n        normalized_scores = normalize_scores([score for _, score in raw_scores])\n    \n        results = []\n        for (url, _), score in zip(raw_scores, normalized_scores):\n            results.append({'Url': url, 'score': score})\n        # print(results)\n        return results",
                "documentation": "helper function for the ml model that identifies and creates a new metric to calculate viewship of a url report"
            },
            {
                "function_name": "prepare_dataframe",
                "parameters": [
                    "dictionaries"
                ],
                "content": "        # This is a placeholder for your actual database query\n        def get_report_from_slug(slug):\n            \n            if Report.objects.filter(slug=slug).exists():\n                return Report.objects.filter(slug=slug).first()\n            else:\n                return None\n            \n    \n        def count_words(text):\n            return len(text.split()) if text else 0\n    \n        data = []\n    \n        for entry in dictionaries:\n            url = entry['Url']\n            score = entry['score']\n    \n            # Check if '/report/' is in the URL\n            if '/report/' in url:\n                slug = url.split('/report/')[1].split('/')[0]\n                report = get_report_from_slug(slug)\n    \n                if report:\n                    # Extract the required information from the report\n                    name_word_count = count_words(report.title)\n                    target = report.target\n                    report_type = report.type\n                    rating = report.rating\n    \n                    event_word_count = count_words(report.event) + count_words(report.takeout)\n                    content_word_count = count_words(report.content)\n    \n                    data.append({\n                        'Name': name_word_count,  # Word count of the report's name\n                        'Target': target,\n                        'Type': report_type,\n                        'Rating': rating,\n                        'Event Word Count': event_word_count,\n                        'Content Word Count': content_word_count,\n                        'Score': score\n                    })\n    \n        return pd.DataFrame(data)",
                "documentation": "helper function to prepare a df for the ml model"
            },
            {
                "function_name": "train_or_load_model",
                "parameters": [
                    "df",
                    "load_from_file",
                    "n_estimators",
                    "max_depth",
                    "random_state",
                    "model_file",
                    "encoder_file",
                    "imputer_file"
                ],
                "content": "        if load_from_file:\n            return joblib.load(model_file)\n        \n        # One-hot encode the 'Type' and 'Rating' columns\n        encoder = OneHotEncoder(handle_unknown='ignore')\n        encoded_type = encoder.fit_transform(df[['Type']]).toarray()\n        encoded_type_df = pd.DataFrame(encoded_type, columns=encoder.get_feature_names_out(['Type']))\n    \n        encoded_rating = encoder.fit_transform(df[['Rating']]).toarray()\n        encoded_rating_df = pd.DataFrame(encoded_rating, columns=encoder.get_feature_names_out(['Rating']))\n    \n        # Combine the encoded columns with the rest of the data\n        df = pd.concat([df.drop(['Type', 'Rating'], axis=1), encoded_type_df, encoded_rating_df], axis=1)\n    \n        # Impute NaN values\n        imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n        X = imputer.fit_transform(df.drop('Score', axis=1))\n        y = df['Score']\n    \n        # Split the dataset into training and testing sets\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n    \n        # Initialize the model with hyperparameters\n        model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n    \n        # Train the model\n        model.fit(X_train, y_train)\n    \n        # Evaluate the model\n        y_pred = model.predict(X_test)\n        mse = mean_squared_error(y_test, y_pred)\n        rmse = sqrt(mse)\n        mae = mean_absolute_error(y_test, y_pred)\n        r2 = r2_score(y_test, y_pred)\n    \n        print(f'Mean Squared Error (MSE): {mse}')\n        print(f'Root Mean Squared Error (RMSE): {rmse}')\n        print(f'Mean Absolute Error (MAE): {mae}')\n        print(f'R-squared (R\u00b2): {r2}')\n    \n        # Save the model, encoder, and imputer\n        joblib.dump(model, model_file)\n        joblib.dump(encoder, encoder_file)\n        joblib.dump(imputer, imputer_file)\n    \n        return model",
                "documentation": "train the random regressor"
            },
            {
                "function_name": "full_workflow",
                "parameters": [
                    "variable"
                ],
                "content": "        timestamp_file = 'timestamp2.pkl'\n        data_file = 'data2.pkl'\n        processed_data = None\n    \n        # Check if the timestamp file exists, create with an old date if it doesn't\n        if not os.path.exists(timestamp_file):\n            with open(timestamp_file, 'wb') as f:\n                pickle.dump(datetime.datetime.min, f)\n    \n        # Load existing data if available\n        if os.path.exists(data_file):\n            with open(data_file, 'rb') as f:\n                processed_data = pickle.load(f)\n    \n        # Check if it's time to re-fetch the data\n        with open(timestamp_file, 'rb') as f:\n            timestamp = pickle.load(f)\n        if datetime.datetime.now() - timestamp >= datetime.timedelta(hours=72):\n            # Fetch new data from API\n            url = \"https://www.clarity.ms/export-data/api/v1/project-live-insights\"\n            headers = {\n                \"Authorization\": \"Bearer eyJhbGciOiJSUzI1NiIsImtpZCI6IjAzNWI5N2UxMjIyMDRkNTM5ZmQ2ZGQ5OGJhYzQyMmYxIiwidHlwIjoiSldUIn0.eyJqdGkiOiJlZDFkODk5OS0xMGE4LTRlZmItOTQ5Ny04NzdlYjllNTdiNWUiLCJzdWIiOiIxOTc1MjUzMzMyMTE4NTIyIiwic2NvcGUiOiJEYXRhLkV4cG9ydCIsIm5iZiI6MTcwMjQwODk0NiwiZXhwIjo0ODU2MDA4OTQ2LCJpYXQiOjE3MDI0MDg5NDYsImlzcyI6ImNsYXJpdHkiLCJhdWQiOiJjbGFyaXR5LmRhdGEtZXhwb3J0ZXIifQ.DaeUVkjvylUubPZKXSwH1mzbX7MYdvK8ovUHctF8qmPAoqYqhwPDgpWgczatSs-TdWMhSZR5rUJHVnb7OusT8Vjv4OTCRLeSec8-3lidtGsv2U7xIJ993mkZikY03iImoKVWCN43ipkUBgbH2t4Wz-SXPu2UhgcNhWwkxtRb7q3POSDrgUvkg2K8zgm50l5AAH_1dz29x3_KFe_tJh5I05jDg5_ZiEK3CXx7rAeHPbV-BabSp2rQkJv4ym6a73qA0ABqx4aXXPsqzrxSuvLf1n0PUF3q4Ui3ZWordEXfZWJFqwSsMNRnYPgmZ2pH9sUWGHkUSjUAJ_F9UyfGMp-Gyg\",\n                \"Content-type\": \"application/json\"\n            }\n            params = {\"numOfDays\": 3, \"dimension1\": \"URL\"}\n            new_data = requests.get(url, headers=headers, params=params).json()\n    \n            # Process and combine new data with existing data\n            new_processed_data = process_json(new_data)\n            if processed_data:\n                for url, metrics in new_processed_data.items():\n                    if url in processed_data:\n                        # Update existing entries\n                        processed_data[url].update(metrics)\n                    else:\n                        # Add new entries\n                        processed_data[url] = metrics\n            else:\n                processed_data = new_processed_data\n    \n            # Save the combined data\n            with open(data_file, 'wb') as f:\n                pickle.dump(processed_data, f)\n            with open(timestamp_file, 'wb') as f:\n                pickle.dump(datetime.datetime.now(), f)\n        else:\n            print('Not enough time has passed! remove the return below me if you want to train anyway')\n            # return None\n    \n        \n        scores = calculate_custom_scores(processed_data)  \n        print(scores)\n        df = prepare_dataframe(scores)  \n        print(df)\n        model = None\n        try:\n            model = train_or_load_model(df, load_from_file=variable, n_estimators=240)  \n        except:\n            print('There\\'s been an error training, most likely the amount of data is not enough ')\n            return \n        return model",
                "documentation": "this function takes in the process of checking if it is time to gather more data from readership, if so, then append or update, then process that data to retrain the viewership model. It also stores in the inputer and imputer used for the one shot encoding"
            },
            {
                "function_name": "predict_report_score",
                "parameters": [
                    "report",
                    "model_file",
                    "encoder_file",
                    "imputer_file"
                ],
                "content": "        # Ensure the model and encoder files exist\n        if not os.path.exists(model_file) or not os.path.exists(encoder_file) or not os.path.exists(imputer_file):\n            print(\"Model or encoder file not found.\")\n            return None\n    \n        # Load the model, encoder, and imputer\n        model = joblib.load(model_file)\n        encoder = joblib.load(encoder_file)\n        imputer = joblib.load(imputer_file)\n    \n        # features = {\n        #     'Name': [len(report.title.split())],  # word count of the name\n        #     'Target': [report.target],\n        #     'Type': [report.type],\n        #     'Rating': [report.rating],\n        #     'Event Word Count': [len(report.event.split()) + len(report.takeout.split())],\n        #     'Content Word Count': [len(report.content.split())]\n        # }\n        features = {\n            'name': [len(report.title.split())] if report.title else [0], \n            'target': [report.target] if report.target is not None else [0],\n            'type': [report.type] if report.type is not None else [0],\n            'rating': [report.rating] if report.rating is not None else [0],\n            'event word count': [len(report.event.split()) + len(report.takeout.split())] if report.event and report.takeout else [0],\n            'content word count': [len(report.content.split())] if report.content else [0]\n        }\n    \n        # Convert to DataFrame\n        df = pd.DataFrame(features)\n    \n        # Apply one-hot encoding to the 'Type' and 'Rating' columns\n        encoded_features = encoder.transform(df[['Type', 'Rating']]).toarray()\n        encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(['Type', 'Rating']))\n    \n        # Combine the encoded columns with the rest of the data\n        df = pd.concat([df.drop(['Type', 'Rating'], axis=1), encoded_df], axis=1)\n    \n        # Apply imputation to the DataFrame\n        X = imputer.transform(df)\n    \n        # Predict the score\n        score = model.predict(X)\n    \n        print(\"Predicted Score:\", score[0])\n        return score[0]",
                "documentation": "uses the trained model to predict the score of a given report"
            },
            {
                "function_name": "get_significant_features",
                "parameters": [
                    "model_file"
                ],
                "content": "        # Ensure the model file exists\n        if not os.path.exists(model_file):\n            print(\"Model file not found.\")\n            return \"No model available\"\n    \n        # Load the model\n        model = joblib.load(model_file)\n    \n        # Check if the model has the attribute 'feature_importances_'\n        if hasattr(model, 'feature_importances_'):\n            feature_importances = model.feature_importances_\n    \n            # Manually construct the feature names list including the one-hot encoded features\n            base_features = ['Name', 'Target', 'Event Word Count', 'Content Word Count']\n            type_categories = ['Type_Research Note', 'Type_Flash Note', 'Type_Sector Note']  \n            rating_categories = ['Rating_Buy', 'Rating_Sell', 'Rating_Hold', 'Rating_Tender', 'Rating_Speculative Buy']  \n            feature_names = base_features + type_categories + rating_categories\n    \n            # Combine feature names and their importances\n            features = zip(feature_names, feature_importances)\n            # Sort the features by their importance\n            sorted_features = sorted(features, key=lambda x: x[1], reverse=True)\n    \n            return sorted_features\n        else:\n            return \"Model does not support feature importances\"",
                "documentation": "it takes in the model and retrives what factors are the most valuable to get the score"
            },
            {
                "function_name": "process_and_pickle_data",
                "parameters": [
                    "days"
                ],
                "content": "        # Define the endpoint\n        def process_data(data):\n            # Define the dictionaries\n            scrollDict = data[6]\n            trafficDict = data[7]\n            engageDict = data[8]\n    \n            # Create a new list to store the dictionaries\n            new_list = []\n    \n            # Process the trafficDict\n            for item in trafficDict['information']:\n                # Create a new dictionary\n                new_dict = {}\n                new_dict['URL'] = item['Url']\n                new_dict['totalUsers'] = item['distinctUserCount']\n    \n                # Add the new dictionary to the list\n                new_list.append(new_dict)\n    \n            # Process the engageDict\n            for item in engageDict['information']:\n                for new_dict in new_list:\n                    if new_dict['URL'] == item['Url']:\n                        new_dict['totalSeconds'] = item['activeTime']\n    \n            # Process the scrollDict\n            for item in scrollDict['information']:\n                for new_dict in new_list:\n                    if new_dict['URL'] == item['Url']:\n                        new_dict['averageScroll'] = item['averageScrollDepth']\n    \n            # Print and return the final list\n            print(new_list)\n            return new_list\n        url = \"https://www.clarity.ms/export-data/api/v1/project-live-insights\"\n    \n        # Define the headers with your JWT token\n        headers = {\n            \"Authorization\": \"Bearer eyJhbGciOiJSUzI1NiIsImtpZCI6IjAzNWI5N2UxMjIyMDRkNTM5ZmQ2ZGQ5OGJhYzQyMmYxIiwidHlwIjoiSldUIn0.eyJqdGkiOiJlZDFkODk5OS0xMGE4LTRlZmItOTQ5Ny04NzdlYjllNTdiNWUiLCJzdWIiOiIxOTc1MjUzMzMyMTE4NTIyIiwic2NvcGUiOiJEYXRhLkV4cG9ydCIsIm5iZiI6MTcwMjQwODk0NiwiZXhwIjo0ODU2MDA4OTQ2LCJpYXQiOjE3MDI0MDg5NDYsImlzcyI6ImNsYXJpdHkiLCJhdWQiOiJjbGFyaXR5LmRhdGEtZXhwb3J0ZXIifQ.DaeUVkjvylUubPZKXSwH1mzbX7MYdvK8ovUHctF8qmPAoqYqhwPDgpWgczatSs-TdWMhSZR5rUJHVnb7OusT8Vjv4OTCRLeSec8-3lidtGsv2U7xIJ993mkZikY03iImoKVWCN43ipkUBgbH2t4Wz-SXPu2UhgcNhWwkxtRb7q3POSDrgUvkg2K8zgm50l5AAH_1dz29x3_KFe_tJh5I05jDg5_ZiEK3CXx7rAeHPbV-BabSp2rQkJv4ym6a73qA0ABqx4aXXPsqzrxSuvLf1n0PUF3q4Ui3ZWordEXfZWJFqwSsMNRnYPgmZ2pH9sUWGHkUSjUAJ_F9UyfGMp-Gyg\",\n            \"Content-type\": \"application/json\"\n        }\n    \n        # Define the parameters with the number of days and dimensions\n        params = {\n            \"numOfDays\": days,\n            \"dimension1\": \"URL\",\n            \"dimension2\": \"ScrollDepth\"\n        }\n    \n        # Check if data was pickled less than 24 hours ago\n        if os.path.exists('data.pkl'):\n            with open('timestamp.pkl', 'rb') as f:\n                timestamp = pickle.load(f)\n            if datetime.datetime.now() - timestamp < datetime.timedelta(hours=24):\n                print('Already pickled')\n                with open('data.pkl', 'rb') as f:\n                    return pickle.load(f)\n    \n        # Make the request\n        response = requests.get(url, headers=headers, params=params)\n    \n        # Parse the response\n        data = response.json()\n    \n        # Process the data\n        processed_data = process_data(data)\n    \n        # Pickle the data\n        with open('data.pkl', 'wb') as f:\n            pickle.dump(processed_data, f)\n        with open('timestamp.pkl', 'wb') as f:\n            pickle.dump(datetime.datetime.now(), f)\n    \n        return processed_data",
                "documentation": "takes in the data json and pickles it, used for the clarity function for not the ml model"
            },
            {
                "function_name": "run_rollover_year",
                "parameters": [
                    "company"
                ],
                "content": "        \"\"\"This function will take in a company look for FYE, if present then it will evaluate whether to prep it for roll over or not\"\"\"\n        if not company.FYE:\n            print('please add FYE to the company')\n            return\n        \n        currentDate = datetime.datetime.now()\n        done=False\n        if currentDate.month > company.FYE.month:\n            company.is_ready_to_rollover = True\n            done=True\n        elif currentDate.month == company.FYE.month:\n            if currentDate.day >= company.FYE.day:\n                company.is_ready_to_rollover = True\n                done=True\n        else:\n            company.is_ready_to_rollover = False\n            company.is_rollover = False\n        company.save()\n        return done",
                "documentation": "this looks for a companies FYE and if it is there then it ealuates wheret to roll over the year or not by concluding if it is past fye or before"
            },
            {
                "function_name": "rollover_company",
                "parameters": [
                    "company"
                ],
                "content": "        \"\"\"More simple function, if it is ready and we call this, it will roll it over.\"\"\"\n        if company.is_ready_to_rollover == True:\n            company.is_rollover = True\n        company.save()\n        return",
                "documentation": "checks if the company is rollover ready, if yes, then it will activate its rollover state"
            },
            {
                "function_name": "fetch_and_update_company_metrics",
                "parameters": [
                    "company"
                ],
                "content": "        if not company.ticker:\n            print('No ticker provided. Exiting function.')\n            return\n    \n        if has_run_in_last_hour(company.slug):\n            print('Function has run in the last hour. Exiting function.')\n            return\n        \n        ticker = company.ticker\n        if company.exchange != None:\n            ticker = company.ticker+'.'+company.exchange\n        yf_ticker = yf.Ticker(ticker)\n    \n        try:\n            # Fetching current info\n            info = yf_ticker.info\n            new_price = info.get('currentPrice', 0)\n            print(new_price)\n            new_marketcap = info.get('marketCap', 0) / 1e6  # Convert to millions\n            print(new_marketcap)\n            new_avg_volume = info.get('averageVolume', 0) / 1e3  # Convert to thousands\n            print(new_avg_volume)\n            new_shares_outstanding = info.get('sharesOutstanding', 0) / 1e6  # Convert to millions\n            print(new_shares_outstanding)\n    \n            # Updating company model fields\n            update_field(company, 'price', new_price)\n            update_field(company, 'marketcap_basic', new_marketcap)\n            update_field(company, 'avg_3month_daily_vol', new_avg_volume)\n            update_field(company, 'shares_basic', new_shares_outstanding)\n    \n            # Fetching financial statement data\n            # financials = yf_ticker.financials\n            # new_revenue = financials.loc['Total Revenue'][0] if 'Total Revenue' in financials.index else 0\n            # print(new_revenue)\n            # new_gross_profit = financials.loc['Gross Profit'][0] if 'Gross Profit' in financials.index else 0\n            # print(new_gross_profit)\n    \n            # update_field(company, 'revenue', new_revenue / 1e6)  # Convert to millions\n            # update_field(company, 'gross_profit', new_gross_profit / 1e6)  # Convert to millions\n    \n            # Update FYE (Fiscal Year End)\n            if not company.FYE:\n                latest_report_date_str = info.get('lastFiscalYearEnd')\n                if latest_report_date_str:\n                    company.FYE = datetime.datetime.fromtimestamp(latest_report_date_str).date()\n    \n            # Update Potential ROR\n            if company.current_target and company.price:\n                potential_ror_calc = (company.current_target - company.price) / company.price\n                company.potential_ror = round(potential_ror_calc * 100, 2) if potential_ror_calc >= 0 else company.potential_ror\n    \n        except Exception as e:\n            print(f\"Error fetching data from yfinance: {e}\")\n    \n        try:\n            company.save()\n            log_run(company.slug)\n        except Exception as e:\n            print(f\"Error saving company data or logging run: {e}\")",
                "documentation": "final version, if it hasent been run in an hour it will run and fetch for a companies price, marketcap and 3 month avg volume and shares and if within an eight percent change then update the value, else skip over, it also calcualtes values when possible. Lastly, it will also try to update and find its fye ased on when a company does its publishing of financial reports"
            },
            {
                "function_name": "update_field",
                "parameters": [
                    "company",
                    "field_name",
                    "new_value"
                ],
                "content": "        \"\"\"\n        Helper function to update a field in the company model if the new value\n        is different and falls within the specified threshold.\n        \"\"\"\n        old_value = getattr(company, field_name)\n        if old_value is None or old_value == \"\":\n            setattr(company, field_name, new_value)\n        elif abs(old_value - new_value) / old_value < 0.08:\n            setattr(company, field_name, new_value)"
            },
            {
                "function_name": "fetch_and_update_company_metricsDEPRECATED",
                "parameters": [
                    "company"
                ],
                "content": "        if company.ticker is None or company.ticker == '':\n            print('No ticker provided. Exiting function.')\n            return\n        if has_run_in_last_hour(company.slug):\n            print('Function has run in the last hour. Exiting function.')\n            return\n        api_key = FMP_API_KEY\n        base_url = \"https://financialmodelingprep.com/api/v3\"\n        ticker = company.ticker\n    \n        try:\n            quote_url = f\"{base_url}/quote-order/{ticker}?apikey={api_key}\"\n            quote_response = requests.get(quote_url)\n            \n            if quote_response.status_code == 200 and quote_response.json():\n                quote_data = quote_response.json()[0]\n                new_price = float(quote_data.get('price', 0))\n                new_marketcap = float(quote_data.get('marketCap', 0))\n                new_avg_volume = float(quote_data.get('avgVolume', 0))\n                new_shares_outstanding = float(quote_data.get('sharesOutstanding', 0))\n                \n                if company.price is None or company.price == \"\":\n                    company.price = new_price if new_price >= 0 else company.price\n    \n                elif abs(float(company.price) - new_price) / float(company.price) < 0.08:\n                    company.price = new_price if new_price >= 0 else company.price\n    \n    \n                if company.marketcap_basic is None or company.marketcap_basic == \"\":\n                    print(new_marketcap, \"new\")\n                    company.marketcap_basic = new_marketcap/1e6 if new_marketcap >=0 else company.marketcap_basic\n                elif abs(float(company.marketcap_basic) - new_marketcap) / float(company.marketcap_basic) < 0.08:\n                    company.marketcap_basic = new_marketcap/1e6 if new_marketcap >=0 else company.marketcap_basic\n    \n                if company.avg_3month_daily_vol is None or company.avg_3month_daily_vol == \"\":\n                    company.avg_3month_daily_vol = new_avg_volume/1e3 if new_avg_volume >= 0 else company.avg_3month_daily_vol\n                elif abs(float(company.avg_3month_daily_vol) - new_avg_volume) / float(company.avg_3month_daily_vol) < 0.08:\n                    company.avg_3month_daily_vol = new_avg_volume/1e3 if new_avg_volume >= 0 else company.avg_3month_daily_vol\n    \n                if company.shares_basic is None or company.shares_basic == \"\":\n                    company.shares_basic = new_shares_outstanding/1e6 if new_shares_outstanding >= 0 else company.shares_basic\n                elif abs(float(company.shares_basic) - new_shares_outstanding) / float(company.shares_basic) < 0.08:\n                    company.shares_basic = new_shares_outstanding/1e6 if new_shares_outstanding >= 0 else company.shares_basic\n    \n        except Exception as e:\n            print(f\"Error fetching quote data: {e}\")\n    \n        try:\n            income_statement_url = f\"{base_url}/income-statement/{ticker}?limit=1&apikey={api_key}\"\n            income_statement_response = requests.get(income_statement_url)\n            if income_statement_response.status_code == 200:\n                income_statement_data = income_statement_response.json()[0]\n                new_revenue = float(income_statement_data.get('revenue', 0))\n                new_gross_profit = float(income_statement_data.get('grossProfit', 0))\n    \n                if company.revenue is None or company.revenue == \"\":\n                    company.revenue = new_revenue/1e6 if new_revenue >= 0 else company.revenue\n                elif abs(float(company.revenue) - new_revenue) / float(company.revenue) < 0.08:\n                    company.revenue = new_revenue/1e6 if new_revenue >= 0 else company.revenue\n    \n                if company.gross_profit is None or company.gross_profit == \"\":\n                    company.gross_profit = new_gross_profit/1e6 if new_gross_profit >= 0 else company.gross_profit\n                elif abs(float(company.gross_profit) - new_gross_profit) / float(company.gross_profit) < 0.08:\n                    company.gross_profit = new_gross_profit/1e6 if new_gross_profit >= 0 else company.gross_profit\n    \n        except Exception as e:\n            print(f\"Error fetching income statement data: {e}\")\n    \n        try:\n            if not company.FYE:\n                financial_report_dates_url = f\"{base_url}/financial-reports-dates?symbol={ticker}&apikey={api_key}\"\n                financial_report_dates_response = requests.get(financial_report_dates_url)\n                if financial_report_dates_response.status_code == 200:\n                    report_dates_data = financial_report_dates_response.json()\n                    if report_dates_data and 'dates' in report_dates_data:\n                        latest_report_date_str = report_dates_data['dates'][0]['date']\n                        company.FYE = datetime.strptime(latest_report_date_str, \"%Y-%m-%d\").date()\n        except Exception as e:\n            print(f\"Error fetching financial report dates: {e}\")\n    \n        try:\n            if company.current_target and company.price:\n                potential_ror_calc = (company.current_target - company.price) / company.price \n                \n                company.potential_ror = round(potential_ror_calc*100,2) if potential_ror_calc >= 0 else company.potential_ror\n        except Exception as e:\n            print(f\"Error calculating potential rate of return: {e}\")\n    \n        try:\n            company.save()\n            log_run(company.slug)\n        except Exception as e:\n            print(f\"Error saving company data or logging run: {e}\")"
            },
            {
                "function_name": "fetch_and_update_company_metricsDEPRECATED",
                "parameters": [
                    "company"
                ],
                "content": "        if company.ticker == None or company.ticker == '':\n            print('byebye')\n            return\n        if has_run_in_last_hour(company.slug):\n            print('wait an hour')\n            return\n    \n        fetch_from_fmp(company)\n        fetch_from_yahoo_finance(company)\n        fetch_from_alpha_vantage(company)\n                \n        calculate_derived_metrics(company)\n        company.save()\n        log_run(company.slug)"
            },
            {
                "function_name": "fetch_from_alpha_vantage",
                "parameters": [
                    "company"
                ],
                "content": "        try:\n            price = get_price_alpha_vantage(company.ticker)\n            if price:\n                company.price = round(price,2)\n                print(price)\n            return company.price is not None\n        except Exception as e:\n            return False",
                "documentation": "deprecated"
            },
            {
                "function_name": "fetch_from_fmp",
                "parameters": [
                    "company"
                ],
                "content": "        try:\n            financials = get_financials_fmp(company.ticker)\n            revenue = financials.get('revenue')\n            if revenue:\n                company.revenue = round(revenue / 1e6,2)\n            gross_profit = financials.get('grossProfit')\n            if gross_profit:\n                company.gross_profit = round(gross_profit / 1e6,2)\n            shares_FD = financials.get('sharesDiluted')\n            if shares_FD:\n                company.shares_FD = round(shares_FD / 1e6,2)\n            shares_basic = get_shares_basic_fmp(company.ticker)\n            if shares_basic:\n                company.shares_basic = round(shares_basic / 1e6,2)\n            return True\n        except Exception as e:\n            return False",
                "documentation": "deprecated"
            },
            {
                "function_name": "get_shares_basic_fmp",
                "parameters": [
                    "ticker"
                ],
                "content": "        url = f\"https://financialmodelingprep.com/api/v3/key-metrics/{ticker}?apikey={FMP_API_KEY}\"\n        response = requests.get(url)\n        data = response.json()\n        if data:\n            return float(data[0].get('sharesOutstanding', 0))\n        return 0",
                "documentation": "deprecated"
            },
            {
                "function_name": "calculate_derived_metrics",
                "parameters": [
                    "company"
                ],
                "content": "        if company.price and company.shares_FD:\n            company.marketcap_FD = round((float(company.price) * float(company.shares_FD)) / 1e6,2)\n        if company.current_target and company.price:\n            company.potential_ror = round(((float(company.current_target) - float(company.price)) / float(company.price)) * 100,2)",
                "documentation": "deprecated"
            },
            {
                "function_name": "calculate_avg_3month_daily_vol",
                "parameters": [
                    "company"
                ],
                "content": "        try:\n            end_date = datetime.date.today()\n            start_date = end_date - datetime.timedelta(days=90)\n            ticker_data = yf.Ticker(company.ticker)\n            historical_data = ticker_data.history(start=start_date, end=end_date)\n            avg_volume = historical_data['Volume'].mean() / 1000\n            company.avg_3month_daily_vol = round(avg_volume,2)\n        except Exception as e:\n            pass",
                "documentation": "deprecated"
            },
            {
                "function_name": "fetch_from_yahoo_finance",
                "parameters": [
                    "company"
                ],
                "content": "        try:\n            stock_info = yf.Ticker(company.ticker).info\n            price = stock_info.get('regularMarketPrice')\n            if price:\n                company.price = round(price,2)\n            marketcap_basic = stock_info.get('marketCap')\n            if marketcap_basic:\n                company.marketcap_basic = round(marketcap_basic / 1e6,2)\n            avg_3month_daily_vol = stock_info.get('averageDailyVolume3Month')\n            if avg_3month_daily_vol:\n                company.avg_3month_daily_vol = round(avg_3month_daily_vol / 1000,2)\n            return True\n        except Exception as e:\n            return False",
                "documentation": "deprecated"
            },
            {
                "function_name": "get_price_alpha_vantage",
                "parameters": [
                    "ticker"
                ],
                "content": "        url = f\"https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol={ticker}&apikey={ALPHA_VANTAGE_API_KEY}\"\n        response = requests.get(url)\n        data = response.json()\n        return float(data.get('Global Quote', {}).get('05. price', 0))",
                "documentation": "deprecated"
            },
            {
                "function_name": "get_financials_fmp",
                "parameters": [
                    "ticker"
                ],
                "content": "        url = f\"https://financialmodelingprep.com/api/v3/income-statement/{ticker}?apikey={FMP_API_KEY}\"\n        response = requests.get(url)\n        data = response.json()\n        if data:\n            return {\n                'revenue': float(data[0].get('revenue', 0)),\n                'grossProfit': float(data[0].get('grossProfit', 0)),\n                'sharesDiluted': float(data[0].get('weightedAverageShsOutDil', 0))\n            }\n        return {}",
                "documentation": "deprecated"
            },
            {
                "function_name": "has_run_in_last_hour",
                "parameters": [
                    "slug"
                ],
                "content": "        if not Path(LOG_FILE_PATH).is_file():\n            return False\n    \n        one_hour_ago = datetime.datetime.now() - datetime.timedelta(hours=1)\n        with open(LOG_FILE_PATH, mode='r') as file:\n            reader = csv.reader(file)\n            for row in reader:\n                if row[1] == slug and datetime.datetime.fromisoformat(row[0]) > one_hour_ago:\n                    return True\n        return False",
                "documentation": "helper for fetch metrics, it looks at the csv file to see if the company is on the log and if ran lastly on an hour or more"
            },
            {
                "function_name": "log_run",
                "parameters": [
                    "slug"
                ],
                "content": "        with open(LOG_FILE_PATH, mode='a', newline='') as file:\n            writer = csv.writer(file)\n            writer.writerow([datetime.datetime.now().isoformat(), slug])"
            },
            {
                "function_name": "simple_fast_reading_time",
                "parameters": [
                    "text"
                ],
                "content": "        words = text.count(' ') + 1\n        totalReadingTime = int(round(words/235.0, 0))\n        return totalReadingTime",
                "documentation": "counts words in an optimized matter, never 0, and calcualtes the reading time assuming a reading speed of 235w per m"
            },
            {
                "function_name": "createReportLinkToShare",
                "parameters": [
                    "report"
                ],
                "content": "        testing = False\n    \n        token = secrets.token_urlsafe(20)\n        hashh = 'temp'+secrets.token_urlsafe(6)\n        \n        # Check if the user exists, if not create a new one\n        if not User.objects.filter(username=hashh).exists():\n            tempUser = User.objects.create(username=hashh, password=make_password(hashh))\n        else:\n            tempUser = User.objects.get(username=hashh)\n    \n        # Check if the profile exists, if not create a new one\n        if not Profile.objects.filter(user=tempUser).exists():\n            new_profile = Profile.objects.create(\n                user=tempUser,\n                first_name=\"temp user\",\n                last_name=str(hashh),\n                email=f\"tempUser{hashh}@temp.com\",\n                phone=1234123123,\n                firm=\"Temp firm\",\n                title=\"Temp title\",\n                city=\"Temp city\",\n                country=\"Canada\",\n                is_temp = True\n            )\n        \n        magic_link = MagicLinkToken.objects.create(user=tempUser, token=token)\n        link = ''\n        if testing:\n            link = 'http://127.0.0.1:8000/'+report.get_absolute_url()+'login/'+token\n        else:\n            link = 'https://research.paradigmcap.com/'+report.get_absolute_url()+'login/'+token\n        return link",
                "documentation": "takes in a report and generates a temporary user and a temp magic link then it sends it to return a functional share link that logs them in"
            },
            {
                "function_name": "send_notification_to",
                "parameters": [
                    "whom",
                    "profile"
                ],
                "content": "        \"\"\"Expanded method to send email notifications to different groups\n            RIGHT NOW ITS GENERAL EMAIL FOR COMP AND EDITORS, analysts do leverage of the profile setting\n        \"\"\"\n        if whom == 'editor':\n            editors = []\n            for user in User.objects.all():\n                if user_highest_permission_finder(user) == 'Editor Group':\n                    prof = get_object_or_404(Profile, user)\n    \n                    if prof.email:\n                        editors.append(prof.email)\n            \n            if len(editors) > 0:\n                send_mail('You just got a report to edit!', \n                          'A new report has been sent to you, please go to https://research.paradigmcap.com/drafter/selector to see it', \n                          'myamani@paradigmcap.com', \n                          editors)\n            return True\n        elif whom == 'compliance':\n            compliance = []\n            for user in User.objects.all():\n                if user_highest_permission_finder(user) == 'Compliance Group':\n                    prof = get_object_or_404(Profile, user)\n    \n                    if prof.email:\n                        compliance.append(prof.email)\n            \n            if len(compliance) > 0:\n                send_mail('You just got a report to review!', \n                          'A new report has been sent to you, please go to https://research.paradigmcap.com/drafter/selector to see it', \n                          'myamani@paradigmcap.com', \n                          compliance)\n            return True\n        elif whom == 'analyst':\n            analysts = []\n            for user in User.objects.all():\n                if user_highest_permission_finder(user) == 'Analyst Group':\n                    prof = get_object_or_404(Profile, user)\n                    \n                    if prof.email and prof == profile:\n                        analysts.append(prof.email)\n            \n            if len(analysts) > 0:\n                send_mail('You just got a report to analyze!', \n                          'A report has been sent back to you to check over again, please go to https://research.paradigmcap.com/drafter/selector to see it', \n                          'myamani@paradigmcap.com', \n                          analysts)\n            return True\n        \n        return False",
                "documentation": "this sends a in an email notif to the individual or editors"
            },
            {
                "function_name": "user_highest_permission_finder",
                "parameters": [
                    "user"
                ],
                "content": "        \n        REQUEST_LEVELS=[\n            \"Analyst Group\",\n            \"Editor Group\",\n            \"Compliance Group\",\n            \"Head Group\"\n        ]\n    \n        levels_str = []\n        levels = user.groups.all()\n    \n        for level in levels:\n            levels_str.append(level.name)\n        if REQUEST_LEVELS[3] in levels_str:\n            return REQUEST_LEVELS[3]\n        elif REQUEST_LEVELS[2] in levels_str:\n            return REQUEST_LEVELS[2]\n        elif REQUEST_LEVELS[1] in levels_str:\n            return REQUEST_LEVELS[1]\n        elif REQUEST_LEVELS[0] in levels_str:\n            return REQUEST_LEVELS[0]",
                "documentation": "very important method it retrives the highest permission given to an user it does not and does not need toinclusde super editor"
            },
            {
                "function_name": "process_report_content",
                "parameters": [
                    "textContainingContent"
                ],
                "content": "        reports = []\n        pattern = r\"\\$\\$\\$\\$(.*?)\\$\\$\\$\\$\"\n        matches = re.findall(pattern, textContainingContent, re.DOTALL)\n        for match in matches:\n            tickers = re.findall(r\"Ticker\\s+(.*)\", match, re.IGNORECASE)\n            ticker = None\n            for tick in tickers:\n                if tick.lower().strip() != \"disclosures\":\n                    ticker = tick\n            if ticker:\n                reports.append({'ticker': ticker,\n                                'rawContent': match})\n        \n        print(\"DEBUG: There were\", len(matches), \"Matches and\", len(reports), \"Reports created.\")\n        return reports"
            },
            {
                "function_name": "spinner",
                "parameters": [],
                "content": "        chars = r\"|/-\\\\\"\n        while not stop_spinner.is_set():\n            for char in chars:\n                print(f\"\\rLoading data, please wait a few minutes... {char}\", end=\"\", flush=True)\n                time.sleep(0.1)",
                "documentation": "simple spinner for when uploading files"
            },
            {
                "function_name": "extract_dictsOLD",
                "parameters": [
                    "input_string_or_path",
                    "is_raw_text"
                ],
                "content": "        \"\"\"\n        Extracts dictionaries from the given input string or file path.\n    \n        Parameters:\n        - input_string_or_path: Either the raw text or the path to a file containing the raw text.\n        - is_raw_text: If True, treats the first parameter as raw text. Otherwise, treats it as a file path.\n    \n        Returns:\n        - A list of dictionaries parsed from the input.\n        \"\"\"\n    \n        # Start the spinner\n        spinner_thread.start()\n    \n        if not is_raw_text:\n            with open(input_string_or_path, 'r', encoding='utf-8', errors='ignore') as f:\n                content = f.read()\n        else:\n            content = input_string_or_path\n    \n        # Stop the spinner\n        stop_spinner.set()\n        spinner_thread.join()\n        print(\"\\rLoading... done!\", end=\"\", flush=True)\n    \n        content = content.replace('\\x00', '')\n        \n        matches = re.findall(r'\\{[^}]*\\}', content)\n        \n        dicts = []\n        for match in tqdm(matches, desc=\"Processing matches\", ncols=100):\n            try:\n                parsed_dict = ast.literal_eval(match)\n                dicts.append(parsed_dict)\n            except (ValueError, SyntaxError):\n                # If an error occurs, skip this match but continue processing the rest\n                print(\"Error\")\n                continue\n        \n        return dicts"
            },
            {
                "function_name": "put_report_to_publish",
                "parameters": [
                    "request",
                    "report"
                ],
                "content": "        print('IN SPECIAL')\n        put_report_to_publishSUB(report)\n        context ={\n            'report': report\n        }\n    \n        request.session[\"uploadSlug\"] = report.slug",
                "documentation": "Important function, it is incharge or runnning the mechanic of updating the company and other objects values with the snapshot metrics and statuses of a report once it is time to set it to publishing"
            },
            {
                "function_name": "put_report_to_publishSUB",
                "parameters": [
                    "report"
                ],
                "content": "        \"\"\"\n        Updates the company with information from the report, updates or creates corresponding company metrics,\n        and sets the report as published.\n        \"\"\"\n    \n        with transaction.atomic():  \n           \n            company = report.company\n    \n            company_fields = {\n                'price': report.price,\n                'potential_ror': report.potential_ror,\n                'avg_3month_daily_vol': report.avg_3month_daily_vol,\n                'shares_basic': report.shares_basic,\n                'shares_FD': report.shares_FD,\n                'marketcap_basic': report.marketcap_basic,\n                'marketcap_FD': report.marketcap_FD,\n                'revenue': report.revenue,\n                'gross_profit': report.gross_profit,\n                # Additional fields with different naming\n                'current_target': report.target,\n                'current_rating': report.rating,\n               \n            }\n            \n            company.investment_thesis = report.report_investment_thesis\n            company.current_val = report.valuation\n    \n            for field, value in company_fields.items():\n                setattr(company, field, value)\n            company.save()\n    \n            if report.type == \"Sector Note\":\n                # print('yeah sector')\n                mets = SectorMetric.objects.filter(sectorReport=report)\n    \n                for met in mets:\n                    comp: Company = met.company\n                    if met.name.lower() == 'rating':\n                        # print('rating')\n                        comp.current_rating = met.amount\n                    elif met.name.lower() == 'target':\n                        # print('target')\n                        comp.current_target = met.amount\n    \n                    comp.save()\n                    \n    \n            \n            report_metrics = ReportMetric.objects.filter(report=report)\n            for report_metric in report_metrics:\n                if report_metric.is_estimate:\n                    if CompanyMetric.objects.filter(company=company, name=report_metric.name, year_estimated=report_metric.year_estimated).exists():\n                        compEst =  CompanyMetric.objects.filter(name=report_metric.name, year_estimated=report_metric.year_estimated).first()\n                        compEst.amount = report_metric.amount\n                    else:\n                        print()\n                        est = CompanyMetric.objects.create(company=company, name=report_metric.name, amount=report_metric.amount, year_estimated=report_metric.year_estimated, is_estimate=True)\n                        est.save()\n                else:\n                    company_metric, created = CompanyMetric.objects.update_or_create(\n                        company=company,\n                        name=report_metric.name,\n                        defaults={\n                            'amount': report_metric.amount,\n                            'year_estimated': report_metric.year_estimated,\n                            'is_estimate': report_metric.is_estimate\n                        }\n                    )\n    \n    \n            ##create report disclaimers\n            # print('re[prt]', report.company, company)\n            disclaimers = CompanyDisclaimer.objects.filter(company=report.company)\n            # print(disclaimers)\n            for disclaimer in disclaimers:\n                \n                reportDisc, created = ReportDisclaimer.objects.update_or_create(\n                    report=report,\n                    disclaimer=disclaimer.disclaimer\n                )\n            print(report.publish_date)\n            report.publish_date = datetime.datetime.now()\n            print(report.publish_date, 'current', datetime.datetime.now())\n            report.save()\n            if not report.is_published:\n                report.is_published = True\n                \n                report.save()",
                "documentation": "the actual put to publish reffer to the one without sub"
            },
            {
                "function_name": "get_highest_confidence_sentiment",
                "parameters": [
                    "text",
                    "max_retries",
                    "delay",
                    "type"
                ],
                "content": "        API_URL = \"https://api-inference.huggingface.co/models/lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\n        API_SUMMARY_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-cnn\"\n        headers = {\"Authorization\": \"Bearer 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\"}\n    \n        def query(payload):\n            if type=='sentiment':\n                response = requests.post(API_URL, headers=headers, json=payload)\n                return response.json()\n            else:\n                response = requests.post(API_SUMMARY_URL, headers=headers, json=payload)\n                return response.json()\n    \n        retries = 0\n        while retries < max_retries:\n            output = query({\n                \"inputs\": text,\n            })\n            \n            # Check if the request was successful\n            \n            if 'error' not in output:\n                \n                # Find the sentiment with the highest confidence\n                if type=='sentiment':\n                    sentiments = output[0][0]['label']\n                    confidences = output[0][0]['score']\n                    print(sentiments, confidences)\n                    highest_confidence_sentiment = (sentiments, confidences)\n                    return highest_confidence_sentiment\n                else:\n                    print('test', output[0])\n                    summary = output[0]['summary_text']\n                    \n                    return summary\n            else:\n                # Check if the error is because the model is loading\n                if 'is currently loading' in output['error']:\n                    \n                    time.sleep(delay)\n                    retries += 1\n                    continue\n                else:\n                    # If there's a different error, no need to retry\n                    return output['error']\n        \n        return \"Failed to get response after retries.\"",
                "documentation": "EXPERIMENTAL use it either summarizes with the type variable or calculaes sentiment of text or exerpt using hugginface free models"
            },
            {
                "function_name": "extract_dicts",
                "parameters": [
                    "input_string_or_path",
                    "is_raw_text",
                    "replacement_str",
                    "WordBelowAvgThreshold"
                ],
                "content": "        \"\"\"\n        Extracts dictionaries from the given input string or file path.\n    \n        Parameters:\n        - input_string_or_path: Either the raw text or the path to a file containing the raw text.\n        - is_raw_text: If True, treats the first parameter as raw text. Otherwise, treats it as a file path.\n        - replacement_str: The string to replace newline characters with.\n        - WordBelowAvgThreshold: The threshold for the number of words below which a line will have a <br> added.\n    \n        Returns:\n        - A list of dictionaries parsed from the input.\n        \"\"\"\n    \n        # Start the spinner\n        spinner_thread.start()\n    \n        if not is_raw_text:\n            with open(input_string_or_path, 'r', encoding='utf-8', errors='ignore') as f:\n                content = f.read()\n        else:\n            content = input_string_or_path\n    \n        # Stop the spinner\n        stop_spinner.set()\n        spinner_thread.join()\n        print(\"\\rLoading... done!\", end=\"\", flush=True)\n    \n        content = content.replace('\\x00', '')\n        \n        matches = re.findall(r'\\{[^}]*\\}', content)\n        \n        dicts = []\n        for match in tqdm(matches, desc=\"Processing matches\", ncols=100):\n            try:\n                parsed_dict = ast.literal_eval(match)\n                if 'content' in parsed_dict:\n                    lines = [line for line in parsed_dict['content'].split('\\n') if line.strip()]\n                    avg_words_per_line = sum(len(line.split()) for line in lines if len(line.split()) > 2) / len([line for line in lines if len(line.split()) > 2])\n                    new_content = []\n                    for line in lines:\n                        if len(line.split()) <= avg_words_per_line - WordBelowAvgThreshold:\n                            line += replacement_str\n                        new_content.append(line)\n                    parsed_dict['content'] = '\\n'.join(new_content)\n                dicts.append(parsed_dict)\n            except (ValueError, SyntaxError):\n                # If an error occurs, skip this match but continue processing the rest\n                print(\"Error\")\n                continue\n        \n        return dicts",
                "documentation": "gets from the rps dicts and makes them an actual dict to process"
            },
            {
                "function_name": "remove_figures",
                "parameters": [
                    "text"
                ],
                "content": "        \n        pattern = r\"(Figure\\s\\d{1,2}:)(.*?)(Source:)\"\n        \n        def repl(match):\n            return match.group(1) + \"\" + match.group(3)\n    \n        text_without_matches = re.sub(pattern, repl, text, flags=re.DOTALL)\n        return text_without_matches",
                "documentation": "filter"
            },
            {
                "function_name": "add_formating_to_figures",
                "parameters": [
                    "reports"
                ],
                "content": "        \n        replacement = r\"<p><br><p><strong>\\1</strong><br>\"\n        pattern = re.compile(r\"(Figure\\s\\d{1,2}:.*?Source:)\", re.DOTALL)\n    \n        for report in reports:\n            if report.content:\n                try:\n                    modified_content = pattern.sub(replacement, report.content)\n                    report.content = modified_content\n                    report.save()\n                except:\n                    pass",
                "documentation": "filter"
            },
            {
                "function_name": "add_general_formating_to_sections",
                "parameters": [
                    "reports"
                ],
                "content": "        titles = ['Highlights', 'Valuation & Conclusion']\n        for report in reports:\n            if report.content:\n                try:\n                    for i, title in enumerate(titles):\n                        # Create a case-insensitive pattern for the title with a captured group\n                        pattern = re.compile(r\"(\" + re.escape(title) + r\")\", re.IGNORECASE)\n                        \n                        # Define the replacement string with HTML tags\n                        # The header tag level depends on the index of the title\n                        replacement = r\"<br><strong><h\" + str(i+1) + r\">\\g<1></h\" + str(i+1) + r\"></strong><br>\"\n                        \n                        # Substitute the matched pattern with the replacement string\n                        modified_content = pattern.sub(replacement, report.content)\n                        \n                        # Update the report content and save\n                        report.content = modified_content\n                        report.save()\n                except:\n                    pass",
                "documentation": "filter"
            },
            {
                "function_name": "take_in_reports_remove_figures",
                "parameters": [
                    "reports"
                ],
                "content": "    \n        for report in reports:\n            if report.content:\n                report.content = remove_figures(report.content)\n                report.save()",
                "documentation": "filer"
            },
            {
                "function_name": "take_in_reports_justify_contentOLD",
                "parameters": [
                    "reports"
                ],
                "content": "        for report in reports:\n            if report.content:\n                try:\n                    newCont = report.content.replace('<p>', '<p style=\"text-align: justify;\">')\n                    # print(newCont)\n                    report.content = newCont\n                    report.save()\n                except:\n                    pass",
                "documentation": "filter"
            },
            {
                "function_name": "take_in_reports_justify_content",
                "parameters": [
                    "reports"
                ],
                "content": "        for report in reports:\n            if report.content:\n                try:\n                    newCont = '<p style=\"text-align: justify;\">' + report.content + '</p>'\n                    report.content = newCont\n                    report.save()\n                except:\n                    pass",
                "documentation": "filter"
            },
            {
                "function_name": "take_in_reports_remove_headersOLD",
                "parameters": [
                    "reports"
                ],
                "content": "        regex = re.compile(r\"\\.\\s+([^\\.]+\\|\\s+\\w+\\s+\\d{1,2},\\s+\\d{4})\", re.DOTALL | re.MULTILINE)\n        subst = \"\"\n        \n        for report in reports:\n            if report.content:\n                try:\n                    result = regex.sub(subst, report.content)\n                    report.content = result\n                    print(result)\n                    report.save()\n                except:\n                    print('PASS')",
                "documentation": "filter"
            },
            {
                "function_name": "take_in_reports_remove_headers",
                "parameters": [
                    "reports"
                ],
                "content": "        regex = re.compile(r\"([A-Z]+\\s+[A-Z]+\\s*\\|\\s*.*?\\d{4})\", re.DOTALL | re.MULTILINE)\n        subst = \"\"\n        \n        for report in reports:\n            if report.content:\n                try:\n                    result = regex.sub(subst, report.content)\n                    report.content = result\n                    report.save()\n                except:\n                    print('PASS')",
                "documentation": "filter"
            },
            {
                "function_name": "take_in_reports_remove_disclaimerTEXT",
                "parameters": [
                    "reports"
                ],
                "content": "        pattern = re.compile(r\"(?i)disclaimer.*\", re.DOTALL)\n        for report in reports:\n            if report.content:\n                try:\n                    result = pattern.sub('', report.content)\n                    report.content = result\n                    report.save()\n                except:\n                    pass",
                "documentation": "filter"
            },
            {
                "function_name": "take_in_reports_remove_firstTableTEXT",
                "parameters": [
                    "reports"
                ],
                "content": "        pattern = re.compile(r\"(?i)(rating:.*?)(page)\", re.DOTALL)\n        for report in reports:\n            if report.content:\n                try:\n                    matches = pattern.findall(report.content)\n                    for match in matches:\n                        if re.search(r'\\d', match[0]):  # check if the match contains at least one number\n                            report.content = report.content.replace(match[0], '')\n                    report.save()\n                except:\n                    pass",
                "documentation": "filter"
            },
            {
                "function_name": "take_in_reports_clean_comp_title_from_in_text",
                "parameters": [
                    "reports"
                ],
                "content": "        for report in reports:\n            if report.content and report.company.name:\n                pattern = re.compile(r'((<br\\s*/?>\\s*)+)' + re.escape(report.company.name) + r'(|\\.)(\\s*<br\\s*/?>)', re.IGNORECASE)\n                try:\n                    result = pattern.sub(r'\\1\\4', report.content)\n                    report.content = result\n                    report.save()\n                except:\n                    pass",
                "documentation": "filter"
            },
            {
                "function_name": "take_in_reports_remove_u",
                "parameters": [
                    "reports"
                ],
                "content": "        pattern = re.compile(r'((<br\\s*/?>\\s*)+)u(\\s+)', re.IGNORECASE)\n        for report in reports:\n            if report.content:\n                try:\n                    result = pattern.sub(r'\\1\u2022\\3', report.content)\n                    report.content = result\n                    report.save()\n                except:\n                    pass",
                "documentation": "filter"
            },
            {
                "function_name": "take_in_reports_remove_u_version2",
                "parameters": [
                    "reports"
                ],
                "content": "        pattern = re.compile(r'(\\.\\s+)u(\\s+)', re.IGNORECASE)\n        for report in reports:\n            if report.content:\n                try:\n                    result = pattern.sub(r'\\1\u2022\\2', report.content)\n                    report.content = result\n                    report.save()\n                except:\n                    pass",
                "documentation": "filter"
            },
            {
                "function_name": "take_in_report_remove_pageHeaderNONDYNAMIC_TEXT",
                "parameters": [
                    "reports"
                ],
                "content": "        \"\"\"Non dynamic in this context implies that it does not remove the company name that it is ussually precedded or followed by. A\n        dynamic option would instead check that from report.company.name and add it to the regex... significantly slower however\"\"\"\n        pattern = re.compile(r\"(?i)page\\s*\\|\\s*\\d{1,2}\", re.DOTALL)\n        for report in reports:\n            if report.content:\n                try:\n                    result = pattern.sub('', report.content)\n                    report.content = result\n                    report.save()\n                except:\n                    pass",
                "documentation": "filter"
            },
            {
                "function_name": "take_in_reports_remove_thesisToEventSELECTIVE",
                "parameters": [
                    "reports"
                ],
                "content": "        \"\"\"This one deletes everything and including, between investment thesis and event\"\"\"\n        pattern = re.compile(r\"(?i)investment thesis.*event\", re.DOTALL)\n        for report in reports:\n            if report.content:\n                try:\n                    result = pattern.sub('', report.content)\n                    report.content = result\n                    report.save()\n                except:\n                    pass",
                "documentation": "filter"
            },
            {
                "function_name": "take_in_reports_remove_thesisToEvent_NON_SELECTIVE",
                "parameters": [
                    "reports"
                ],
                "content": "        \"\"\"This one deletes everything and including, the first time the word event shows up until highlights\"\"\"\n        pattern = re.compile(r\"(?i)(.*?)Highlights\", re.DOTALL)\n        for report in tqdm(reports, desc=\"Processing reports\"):\n            if report.content:\n                try:\n                    result = pattern.sub('Highlights', report.content)\n                    report.content = result\n                    report.save()\n                except:\n                    pass",
                "documentation": "filter"
            },
            {
                "function_name": "extract_figures",
                "parameters": [
                    "text"
                ],
                "content": "        pattern = r\"figure\\s\\d{1,2}:.*?source:\"\n        matches = re.findall(pattern, text, re.DOTALL)\n        figures = []\n        for match in matches:  \n            figures.append(match)",
                "documentation": "filter"
            },
            {
                "function_name": "extract_content",
                "parameters": [
                    "input_string"
                ],
                "content": "        target_phrase = \"Our disclosure statements are located at the end of this report.\"\n        \n        closest_match, score = process.extractOne(target_phrase, [input_string], scorer=fuzz.token_sort_ratio)\n        \n        if score < 70:  \n            return None\n    \n        start_pos = input_string.find(closest_match) + len(closest_match)\n        \n     \n        subsequent_content = input_string[start_pos:].strip()\n    \n      \n        year_pattern = re.search(r'20\\d{2}', subsequent_content)\n        if year_pattern:\n            return subsequent_content[:year_pattern.end()]\n    \n        return None",
                "documentation": "filter"
            },
            {
                "function_name": "helper",
                "parameters": [
                    "a",
                    "b"
                ],
                "content": "        for i, l_a in enumerate(a):\n            if b == l_a:\n                return i\n        return -1"
            },
            {
                "function_name": "diff",
                "parameters": [
                    "a",
                    "b"
                ],
                "content": "        t_b = b.copy()\n        c_i = 0\n        for c in a:\n            t_i = helper(t_b, c)\n            if t_i != -1 and (t_i > c_i or t_i == c_i):\n                c_i = t_i\n                del t_b[c_i]\n    \n        t_a = a.copy()\n        c_i = 0\n        for c in b:\n            t_i = helper(t_a, c)\n            if t_i != -1 and (t_i > c_i or t_i == c_i):\n                c_i = t_i\n                del t_a[c_i]\n    \n        if not t_b and not t_a:  # both lists are empty\n            return None\n    \n        return \"Changed:\"+ ' '.join(t_b) +\" to -> \"+ ' '.join(t_a)"
            },
            {
                "function_name": "listDiff",
                "parameters": [
                    "oldTextContent",
                    "newTextContent"
                ],
                "content": "        \"\"\"Splits the old and new content and then sub-devides it into sets of three\n        Then it check on each subset if words changed, if so then it records it\"\"\"\n        \n        wordsNew = newTextContent.split()\n        wordsOld = oldTextContent.split()\n    \n        groupListNew = [wordsNew[i:i+3] for i in range(0, len(wordsNew), 3)]\n        groupListOld = [wordsOld[i:i+3] for i in range(0, len(wordsOld), 3)]\n    \n        answerList = []\n        for i, setw in enumerate(groupListOld):\n            try:\n                diff_result = diff(groupListNew[i], setw)\n                if diff_result is not None:  # only append if result is not None\n                    # print('in')\n                    # print(diff_result)\n                    answerList.append(diff_result)\n            except:\n                pass\n    \n        return answerList",
                "documentation": "this is is charge of the differences engine used to detect what is sent back to an analyst"
            },
            {
                "function_name": "listDiffNEW",
                "parameters": [
                    "original_text",
                    "edited_text"
                ],
                "content": "        d = difflib.Differ()\n        diff = d.compare(original_text.split(), edited_text.split())\n    \n        changes = []\n        add_buffer = []\n        rem_buffer = []\n    \n        for line in diff:\n            if line.startswith('+ '):\n                add_buffer.append(line[2:])\n            elif line.startswith('- '):\n                rem_buffer.append(line[2:])\n            elif add_buffer or rem_buffer:\n                change_dict = {}\n                if add_buffer and rem_buffer:\n                    change_dict['action'] = 'changed'\n                    change_dict['old'] = ' '.join(rem_buffer)\n                    change_dict['new'] = ' '.join(add_buffer)\n                elif add_buffer:\n                    change_dict['action'] = 'added'\n                    change_dict['text'] = ' '.join(add_buffer)\n                else:\n                    change_dict['action'] = 'removed'\n                    change_dict['text'] = ' '.join(rem_buffer)\n                changes.append(change_dict)\n                add_buffer, rem_buffer = [], []\n    \n        return json.dumps(changes)",
                "documentation": "new"
            },
            {
                "function_name": "avgWordsPerReport",
                "parameters": [
                    "reports"
                ],
                "content": "    \n        totalWords = 0\n        avgWords = -1\n        for report in reports:\n    \n            if report.event:\n                totalWords += report.event.count(' ') + 1\n            if report.content:\n                totalWords+= report.content.count(' ') + 1\n        try:\n            avgWords = totalWords/len(reports)\n        except:\n            return None\n        return int(avgWords)",
                "documentation": "calculates the average amount of words per report "
            },
            {
                "function_name": "extract_text_from_pdf",
                "parameters": [
                    "pdf_path"
                ],
                "content": "        with open(pdf_path, 'rb') as pdf_file:\n            reader = PyPDF2.PdfReader(pdf_file)\n            text = \"\"\n            for page in reader.pages:\n                text += page.extract_text()\n        return text"
            },
            {
                "function_name": "extractDatesFromPDF",
                "parameters": [
                    "pdf_path"
                ],
                "content": "        \"\"\"Can extract all dates in Month day, year format in a pdf\"\"\"\n        default = [\"No date found\"]\n        text_body = extract_text_from_pdf(pdf_path)\n        pattern = re.compile(r\"[A-Za-z]+\\s(0?[1-9]|[12][0-9]|3[01]),\\s20\\d\\d\", re.IGNORECASE) \n        matches = pattern.search(text_body)\n        \n        if len(matches.group()) >= 1:\n            return matches\n        else:\n            print(\"no dates found\")\n            return default"
            },
            {
                "function_name": "extractPublishDateFromTechnicalPDF",
                "parameters": [
                    "pdf_path"
                ],
                "content": "        \"\"\"To be used with technical reports from aazan\"\"\"\n        publishDate = extractDatesFromPDF(pdf_path)[0]\n        #print(publishDate)\n    \n        if publishDate != \"no dates found\":\n            return publishDate.strip()\n        else:\n            return None"
            },
            {
                "function_name": "extractEventFromResearchPDF",
                "parameters": [
                    "pdf_path"
                ],
                "content": "        \"\"\"To be used with our Research Note pdf's\"\"\"\n        text = extract_text_from_pdf(pdf_path)\n        pattern = re.compile(r\"Event(\\s+(.*)\\s+)Highlights\", re.DOTALL)\n        matches = pattern.search(text)\n        # print(matches[1])\n    \n        try:\n            if len(matches.group()) >= 1:\n                return matches[1].strip()\n            else:\n                print('no event found')\n                return None\n        except:\n            print('no event found')\n            return None"
            },
            {
                "function_name": "extractReportTitleFromResearchPDF",
                "parameters": [
                    "pdf_path"
                ],
                "content": "        \"\"\"To be used to extract the title of a Research note PDF\"\"\"\n        text = extract_text_from_pdf(pdf_path)\n        pattern = re.compile(r\"statements are located at the end of this report.(\\s+(.*)\\s+)Investment Thesis\", re.DOTALL)\n        matches = pattern.search(text)\n        # print(matches[1])\n    \n        try:\n            if len(matches.group()) >= 1:\n                proceedTitle = matches[1].replace(\".\", \"\").strip()\n                return proceedTitle\n            else:\n                print('no title found')\n                return None\n        except:\n            print('no title found')\n            return None"
            },
            {
                "function_name": "extractCompanyTickerFromResearchPDF",
                "parameters": [
                    "pdf_path"
                ],
                "content": "        \"\"\"extracts the company Ticker from a research note\"\"\"\n        text = extract_text_from_pdf(pdf_path)\n        pattern = re.compile(\"Ticker\\s+(.*)\", re.IGNORECASE)\n        matches = pattern.search(text)\n        # print(matches[1])\n    \n        try:\n            if len(matches.group()) >= 1:\n                index = matches[1].find(\"-\")\n                if index != -1:\n                     proceedTicker = matches[1][:index].strip()\n                     return proceedTicker\n                else:\n                     proceedTicker = matches[1].strip()\n                     return proceedTicker\n                \n            else:\n                print('no ticker found')\n                return None\n        except:\n            print('no ticker found')\n            return None"
            },
            {
                "function_name": "extractRatingFromResearchPDF",
                "parameters": [
                    "pdf_path"
                ],
                "content": "        \"\"\"Extracts the rating from a research note PDF\"\"\"\n        text = extract_text_from_pdf(pdf_path)\n        pattern = re.compile(r\"Rating:(\\s+(.*))\", re.IGNORECASE)\n        matches = pattern.search(text)\n        # print(matches[1])\n    \n        try:\n            if len(matches.group()) >= 1:\n                proceedTitle = matches[1].strip()\n                return proceedTitle\n            else:\n                print('no rating found')\n                return None\n        except:\n            print('no rating found')\n            return None"
            },
            {
                "function_name": "extractTargetFromResearchPDF",
                "parameters": [
                    "pdf_path"
                ],
                "content": "        \"\"\"Extracts the rating from a research note PDF\"\"\"\n        text = extract_text_from_pdf(pdf_path)\n        pattern = re.compile(r\"Target :(\\s+(.*)\\s+)\", re.IGNORECASE)\n        matches = pattern.search(text)\n        # print(text)\n    \n        try:\n            if len(matches.group()) >= 1:\n                proceedTarget = matches[1].strip()\n                return proceedTarget\n            else:\n                print('no target found')\n                return None\n        except:\n            print('no target found')\n            return None"
            },
            {
                "function_name": "determineIfResearchPDF",
                "parameters": [
                    "pdf_path"
                ],
                "content": "        \"\"\"Checks for the existance of RESEARCH NOTE regardless of spacing is present on a document\"\"\"\n        text = extract_text_from_pdf(pdf_path)\n        pattern = re.compile(r\"RESEARCH\\s+NOTE\", re.IGNORECASE)\n        matches = pattern.search(text)\n    \n        try:\n            if len(matches.group()) >= 1:\n                return True\n            else:\n                return False\n        except:\n            return False"
            },
            {
                "function_name": "extractCompanyNameResearchPDF",
                "parameters": [
                    "pdf_path"
                ],
                "content": "        \"\"\"Extracts the company title from a research pdf\"\"\"\n        mainText = extract_text_from_pdf(pdf_path)\n        text = mainText.lower()\n        \n        researchIndex = text.find('research')\n    \n        if researchIndex > 0:\n            compTitle = mainText[:researchIndex].replace(\".\",\"\").strip()\n            \n            return compTitle\n        else:\n            return None"
            },
            {
                "function_name": "extractInvestmentThesisResearchPDF",
                "parameters": [
                    "pdf_path"
                ],
                "content": "        \"\"\"Extracts the investment thesis from a research pdf\"\"\"\n        text = extract_text_from_pdf(pdf_path)\n        pattern = re.compile(r\"Investment Thesis((\\s|)+(.*)\\s+)Event\", re.DOTALL)\n        matches = pattern.search(text)\n        # print(matches[1])\n    \n        try:\n            if len(matches.group()) >= 1:\n                return matches[1].strip()\n            else:\n                print('no thesis')\n                return None\n        except:\n            print('no thesis')\n            return None"
            },
            {
                "function_name": "extractAllPhoneNumbers",
                "parameters": [
                    "pfd_path"
                ],
                "content": "        \"\"\"Returns a list with all phone numbers in a document\"\"\"\n        text = extract_text_from_pdf(pdf_path)\n        pattern = re.compile(r\"[0-9]+\\.[0-9]+\\.[0-9]+\")\n        matches = pattern.findall(text)\n        return matches"
            },
            {
                "function_name": "extractMainAnalystPhoneNumberResearchPDF",
                "parameters": [
                    "pdf_path",
                    "formatToSimpleNumber",
                    "formatToInt"
                ],
                "content": "        \"\"\"Returns the main Analyst Phone number, can be formated to remove dots and to convert to int\"\"\"\n        if formatToInt:\n            return int(extractAllPhoneNumbers(pdf_path)[0].replace(\".\",\"\").strip())\n        if formatToSimpleNumber:\n            return extractAllPhoneNumbers(pdf_path)[0].replace(\".\",\"\").strip()\n        else:\n            return extractAllPhoneNumbers(pdf_path)[0].strip()"
            },
            {
                "function_name": "find_headings_remove_tags",
                "parameters": [
                    "text"
                ],
                "content": "        pattern = r\"<h[0-9].*?>(.*?)<\\/h[0-9]>\"\n        matches = re.findall(pattern, text)\n        good = []\n        for match in matches:\n            \n            pattern_tag = r\"<.*?>(.*?)<.*?>\"\n            match = re.sub(pattern_tag, '', match)\n            good.append(match)\n    \n        return good"
            },
            {
                "function_name": "find_headings",
                "parameters": [
                    "text"
                ],
                "content": "        pattern = r\"(<h[0-9].*?>.*?<\\/h[0-9]>)\"\n        matches = re.findall(pattern, text)\n        return matches"
            },
            {
                "function_name": "find_inner_content",
                "parameters": [
                    "text"
                ],
                "content": "        pattern = r\"<h[0-9].*?>.*?<\\/h[0-9]>(.*)<h[0-9].*?>.*?<\\/h[0-9]>\"\n        matches = re.findall(pattern, text, re.DOTALL)\n        return matches"
            },
            {
                "function_name": "find_inner_content_remove_tags",
                "parameters": [
                    "text",
                    "remove_special"
                ],
                "content": "        pattern = r\"<h[0-9].*?>.*?<\\/h[0-9]>(.*)<h[0-9].*?>.*?<\\/h[0-9]>\"\n        matches = re.findall(pattern, text, re.DOTALL)\n    \n        good1 = []\n        for match in matches:\n            \n            pattern_tag = r\"<.*?>(.*?)<.*?>\"\n            matches2 = re.findall(pattern_tag, match.strip())\n            paragraph_content = \"\"\n    \n            for p in matches2:\n                paragraph_content += p\n                \n    \n            if remove_special == True:\n                good1.append(paragraph_content.replace(\"&nbsp\",\"\").strip())\n            else:\n                good1.append(paragraph_content.strip())\n    \n        return good1"
            },
            {
                "function_name": "find_headings_bs4",
                "parameters": [
                    "text"
                ],
                "content": "    \n        soup = bs4.BeautifulSoup(text, 'html.parser')\n        headings = soup.find_all(re.compile('^h[1-6]$'))\n    \n        return headings"
            },
            {
                "function_name": "find_headings_remove_tags_bs4",
                "parameters": [
                    "text"
                ],
                "content": "    \n        soup = bs4.BeautifulSoup(text, 'html.parser')\n        headings = soup.find_all(re.compile('^h[1-6]$'))\n    \n        good = []\n    \n        for h in headings:\n            good.append(h.text.strip())\n    \n        return good"
            },
            {
                "function_name": "get_text_after_last_heading",
                "parameters": [
                    "text"
                ],
                "content": "    \n        soup = bs4.BeautifulSoup(text, 'html.parser')\n        headings = soup.find_all(re.compile('^h[1-6]$'))\n        last_heading = headings[-1] if headings else None\n    \n        \n        if last_heading is None:\n            return soup.get_text(strip=True)\n        \n        element = last_heading.next_sibling\n        text_after = ''\n        while element:\n            if hasattr(element, 'text'):\n                text_after += element.text.strip() + ' '\n            element = element.next_sibling\n    \n        return text_after.strip()"
            },
            {
                "function_name": "get_headings_and_texts",
                "parameters": [
                    "text"
                ],
                "content": "        \n        soup = bs4.BeautifulSoup(text, 'html.parser')\n        headings = soup.find_all(re.compile('^h[1-6]$'))\n    \n        headings_and_texts = []\n        #between\n        for i in range(len(headings) - 1):\n            element = headings[i].next_sibling\n            text_between = ''\n            while element and element != headings[i + 1]:\n                if hasattr(element, 'text'):\n                    text_between += element.text.strip() + ' '\n                element = element.next_sibling\n            headings_and_texts.append((headings[i].text.strip(), text_between.strip()))\n    \n        ## last heading\n        if headings:\n            last_heading = headings[-1]\n            element = last_heading.next_sibling\n            text_after = ''\n            while element:\n                if hasattr(element, 'text'):\n                    text_after += element.text.strip() + ' '\n                element = element.next_sibling\n            headings_and_texts.append((last_heading.text.strip(), text_after.strip()))\n    \n        return headings_and_texts"
            },
            {
                "function_name": "calculate_aggregate",
                "parameters": [
                    "data",
                    "exclude_keys"
                ],
                "content": "            values = [float(data[key]) for key in data if key not in exclude_keys and data[key] is not None]\n            return sum(values) / len(values) if values else 0"
            },
            {
                "function_name": "normalize_scores",
                "parameters": [
                    "scores"
                ],
                "content": "            min_score = min(scores)\n            max_score = max(scores)\n            range_score = max_score - min_score\n            if range_score == 0:\n                return [0 if s <= 0 else 1 for s in scores] # Handle the case where all scores are the same\n            return [(s - min_score) / range_score for s in scores]",
                "documentation": "normailzes using min max all of the scores of the machine learning set"
            },
            {
                "function_name": "get_report_from_slug",
                "parameters": [
                    "slug"
                ],
                "content": "            \n            if Report.objects.filter(slug=slug).exists():\n                return Report.objects.filter(slug=slug).first()\n            else:\n                return None",
                "documentation": "given a slug returns a report"
            },
            {
                "function_name": "count_words",
                "parameters": [
                    "text"
                ],
                "content": "            return len(text.split()) if text else 0"
            },
            {
                "function_name": "process_data",
                "parameters": [
                    "data"
                ],
                "content": "            # Define the dictionaries\n            scrollDict = data[6]\n            trafficDict = data[7]\n            engageDict = data[8]\n    \n            # Create a new list to store the dictionaries\n            new_list = []\n    \n            # Process the trafficDict\n            for item in trafficDict['information']:\n                # Create a new dictionary\n                new_dict = {}\n                new_dict['URL'] = item['Url']\n                new_dict['totalUsers'] = item['distinctUserCount']\n    \n                # Add the new dictionary to the list\n                new_list.append(new_dict)\n    \n            # Process the engageDict\n            for item in engageDict['information']:\n                for new_dict in new_list:\n                    if new_dict['URL'] == item['Url']:\n                        new_dict['totalSeconds'] = item['activeTime']\n    \n            # Process the scrollDict\n            for item in scrollDict['information']:\n                for new_dict in new_list:\n                    if new_dict['URL'] == item['Url']:\n                        new_dict['averageScroll'] = item['averageScrollDepth']\n    \n            # Print and return the final list\n            print(new_list)\n            return new_list"
            },
            {
                "function_name": "query",
                "parameters": [
                    "payload"
                ],
                "content": "            if type=='sentiment':\n                response = requests.post(API_URL, headers=headers, json=payload)\n                return response.json()\n            else:\n                response = requests.post(API_SUMMARY_URL, headers=headers, json=payload)\n                return response.json()"
            },
            {
                "function_name": "repl",
                "parameters": [
                    "match"
                ],
                "content": "            return match.group(1) + \"\" + match.group(3)"
            }
        ],
        "imports": [
            "models.Profile",
            "models.NewsObject",
            "secrets",
            "models.ReportMetric",
            "re",
            "math.sqrt",
            "json",
            "PyPDF2",
            "requests",
            "models.MagicLinkToken",
            "ast",
            "models.SectorMetric",
            "django.shortcuts.get_object_or_404",
            "bs4",
            "django.template.loader.render_to_string",
            "numpy",
            "sklearn.impute.SimpleImputer",
            "tqdm.tqdm",
            "fuzzywuzzy.fuzz",
            "django.shortcuts.redirect",
            "models.CompanyDisclaimer",
            "models.Company",
            "django.shortcuts.render",
            "string",
            "sklearn.model_selection.train_test_split",
            "time",
            "fuzzywuzzy.process",
            "sklearn.metrics.mean_absolute_error",
            "pandas",
            "sklearn.metrics.r2_score",
            "sklearn.ensemble.RandomForestRegressor",
            "models.CompanyMetric",
            "csv",
            "models.Analyst",
            "pickle",
            "sklearn.preprocessing.OneHotEncoder",
            "yfinance",
            "django.core.mail.send_mail",
            "datetime",
            "django.contrib.auth.hashers.make_password",
            "sklearn.metrics.mean_squared_error",
            "models.ReportDisclaimer",
            "threading",
            "difflib",
            "os",
            "django.db.transaction",
            "joblib",
            "models.User",
            "models.Report",
            "pathlib.Path"
        ]
    },
    {
        "name_of_file": "views.py",
        "functions": [
            {
                "function_name": "home",
                "parameters": [
                    "request"
                ],
                "content": "    \n        if MAINTINANCE_MODE == True:\n            if request.user.is_superuser:\n                pass\n            else:\n                return redirect('maintinance')\n    \n    \n        # total_start_time = time.time()  \n    \n        # start_time = time.time()\n    \n        # watchlists = list(ReportGroup.objects.exclude(name=\"\")) <- Decide to keep or not\n        # print(\"Time to fetch watchlists: \", time.time() - start_time)\n    \n        # start_time = time.time()\n    \n        are_there_edits = Report.objects.filter(is_reviewing=True).exists()\n        # print(\"Time to check if there are edits: \", time.time() - start_time)\n    \n        # start_time = time.time()\n        user_highest_permission = user_highest_permission_finder(request.user)\n        # print(\"Time to find user's highest permission: \", time.time() - start_time)\n    \n        # start_time = time.time()\n        are_there_drafts = False\n        if user_highest_permission == \"Analyst Group\":\n            try:\n                are_there_drafts = Report.objects.filter(is_draft=True, analyst__profile__user=request.user).exclude(Q(comments='') | Q(comments=None)).exists()\n            except:\n                print('not an analyst')\n        # print(\"Time to check if there are drafts: \", time.time() - start_time)\n    \n        # start_time = time.time()\n        all_reports = None\n        if user_highest_permission != None and user_highest_permission.lower() in [\"analyst group\", \"editor group\", \"compliance group\", \"head group\"]:\n            # all_reports = list(Report.objects.select_related('company').only('company__name', 'company__ticker','analyst','type','truncated_event','is_draft', 'is_reviewing', 'is_compliance', 'is_published', 'title', 'publish_date').all()[:7])\n            published_reports = list(Report.objects.select_related('company','analyst').only('company__name', 'company__ticker','analyst__profile','type','truncated_event', 'is_published', 'title', 'publish_date').filter(is_published=True)[:7])\n        else:\n            published_reports = list(Report.objects.select_related('company','analyst__profile').only('company__name', 'company__ticker','analyst__profile','type','truncated_event', 'is_published', 'title', 'publish_date').filter(is_published=True)[:7])\n    \n        latest_reports_big_screen = None\n        latest_reports_mid_screen = None\n        # if all_reports != None:\n        #     latest_reports_big_screen = all_reports[:5]\n        #     latest_reports_mid_screen = all_reports\n        if all_reports != None:\n            latest_reports_big_screen = published_reports[:5]\n            latest_reports_mid_screen = published_reports\n        latest_reports_big_screen_CLEAN = published_reports[:5]\n        latest_reports_mid_screen_CLEAN = published_reports\n    \n        # print(\"Time to fetch latest reports: \", time.time() - start_time)\n    \n        # start_time = time.time()\n        context = {\n            \"latest_reports_small_big\": latest_reports_big_screen,\n            \"latest_reports_mid\": latest_reports_mid_screen,\n            \"latest_reports_small_big_CLEAN\": latest_reports_big_screen_CLEAN,\n            \"latest_reports_mid_CLEAN\": latest_reports_mid_screen_CLEAN,\n            # \"watchlists\": watchlists,\n            'are_there_edits': are_there_edits,\n            'are_there_drafts': are_there_drafts,\n            'user_permission': user_highest_permission\n        }\n        # print(\"Time to prepare context: \", time.time() - start_time)\n    \n        # total_time = time.time() - total_start_time\n        # print(\"Total time to run the function: \", total_time)\n    \n        # # Append the time to a CSV file\n        # with open('times.csv', 'a', newline='') as file:\n        #     writer = csv.writer(file)\n        #     writer.writerow([total_time])\n    \n    \n        return render(request, \"home.html\", context)",
                "documentation": "the main view, it now just simply recalls the top published reports and displaysthem"
            },
            {
                "function_name": "maintinance",
                "parameters": [
                    "request"
                ],
                "content": "        return render(request, 'maintinance_screen.html')",
                "documentation": "a view that renders the maintincnae screen, the maintinance state must be set by variable outside the function"
            },
            {
                "function_name": "login_view",
                "parameters": [
                    "request"
                ],
                "content": "        if request.method == 'POST':\n            username = request.POST.get('username')\n            password = request.POST.get('password')\n    \n            #user = User.objects.create_user('add', 'admin@example.com', '123123')\n            user = authenticate(request, username=username, password=password)\n            \n            \n            if user is not None:\n    \n                login(request, user)\n    \n                # Retrieve the associated Profile object\n                profile = Profile.objects.get(user=user)\n    \n                # Store the profile ID in the session\n                request.session['profile_id'] = profile.id\n    \n                signed_username = signing.dumps(user.username)\n                response = redirect('home')\n                response.set_cookie('pciu', signed_username)\n    \n                return response\n            else:\n                error_message = 'Invalid username or password.'\n                context = {\n                'hide_search': True,\n                'error_message': error_message\n                }\n                return render(request, 'login.html', context)\n        context = {\n            'hide_search': True\n        }\n        return render(request, 'login.html', context)",
                "documentation": "main login view it processes and authenticates an user via post if sent else it just renders the view"
            },
            {
                "function_name": "logout_view",
                "parameters": [
                    "request"
                ],
                "content": "        logout(request)\n        return redirect('home')",
                "documentation": "log out render view"
            },
            {
                "function_name": "browse_metrics_AJAX",
                "parameters": [
                    "request",
                    "slug"
                ],
                "content": "        if request.method == \"POST\":\n            received_data = json.loads(request.body)\n            direction = received_data.get(\"direction\")\n            slugg = received_data.get(\"slug\")\n    \n            current_report = get_object_or_404(Report, slug=slugg)\n            \n          \n            next_report = None\n            if direction == 'f':\n                \n                next_report = Report.objects.filter(\n                    company=current_report.company,\n                    is_published=True,\n                    publish_date__gt=current_report.publish_date\n                ).order_by('publish_date').first()\n                \n            elif direction == 'b':\n                \n                next_report = Report.objects.filter(\n                    company=current_report.company,\n                    is_published=True,\n                    publish_date__lt=current_report.publish_date\n                ).order_by('-publish_date').first()\n                \n            \n            if not next_report:\n                return JsonResponse({\"message\": \"No more reports in this direction!\"})\n           \n            metrics = ReportMetric.objects.filter(report=next_report)\n            metrics_data_list = [{\"name\": metric.name, \"amount\": str(metric.amount)} for metric in metrics]\n    \n            metrics_data = {\n                \"new_slug\": next_report.slug,\n                \"rating\": next_report.rating,\n                \"target\": next_report.target,\n                \"price\": next_report.price,\n                \"potential_ror\": next_report.potential_ror,\n                \"avg_3month_daily_vol\": next_report.avg_3month_daily_vol,\n                \"shares_basic\": next_report.shares_basic,\n                \"shares_FD\": next_report.shares_FD,\n                \"marketcap_basic\": next_report.marketcap_basic,\n                \"marketcap_FD\": next_report.marketcap_FD,\n                \"revenue\": next_report.revenue,\n                \"gross_profit\": next_report.gross_profit,\n                \"additional_metrics\": metrics_data_list\n            }\n            \n            return JsonResponse(metrics_data)",
                "documentation": "deprecated method that let the user use the arrows div on the combinedreports template that let them browse trough the metrics of reports past and ahead of the report we are looking for "
            },
            {
                "function_name": "excel_api",
                "parameters": [
                    "request"
                ],
                "content": "        if request.method == 'POST':\n            data = json.loads(request.body)\n    \n            company_slug = data.get('company_slug')\n            stat_name = data.get('name')\n            stat_value = data.get('value')\n            api_token = data.get('api_token')\n            if MagicLinkToken.objects.filter(token=api_token, is_api_token=True).exists():\n                try:\n                    company = Company.objects.filter(slug=company_slug).first()\n                    if not company:\n                        return JsonResponse({'error': 'Company not found'}, status=404)\n    \n                    # Update company if the stat matches a company field\n                    if hasattr(company, stat_name):\n                        setattr(company, stat_name, stat_value)\n                        company.save()\n    \n                    # Check if a company metric exists\n                    else:\n                        company_metric_query = CompanyMetric.objects.filter(company=company, name=stat_name, is_estimate=False)\n                        if company_metric_query.exists():\n                            company_metric = company_metric_query.first()\n                            company_metric.amount = stat_value\n                            # company_metric.is_estimate = False\n                            company_metric.save()\n                        else:\n                            CompanyMetric.objects.create(\n                                company=company, \n                                name=stat_name, \n                                amount=stat_value, \n                                is_estimate=False\n                            )\n    \n                    print('Received data:', data)\n                    return JsonResponse({'company_slug': company_slug, 'name': stat_name, 'value': stat_value})\n    \n                except Exception as e:\n                    return JsonResponse({'error': str(e)}, status=500)\n            else:\n                JsonResponse({'error': 'Invalid API'}, status=400)\n    \n        else:\n            return JsonResponse({'error': 'Invalid request'}, status=400)",
                "documentation": "takes in an api request from excel processes the api token and then updates a company responsibaly"
            },
            {
                "function_name": "excel_apiDEPRECATED",
                "parameters": [
                    "request"
                ],
                "content": "       \n        if request.method == 'POST':\n            \n            data = json.loads(request.body)\n            \n            \n            avg30 = data.get('avg30')\n            median30 = data.get('median30')\n            \n            obj1 = ExcelStatistic.objects.update_or_create(name='avg30', value=avg30)\n            obj2 = ExcelStatistic.objects.update_or_create(name='median30', value=median30)\n    \n            print('excel statistics recieved')\n            \n            return JsonResponse({'status': 'ok'})\n    \n        else:\n            return JsonResponse({'error': 'Invalid request'}, status=400)"
            },
            {
                "function_name": "report_tts",
                "parameters": [
                    "request",
                    "slug"
                ],
                "content": "        report = get_object_or_404(Report, slug=slug)\n    \n        textToTts = report.embed_string()\n    \n        obj = gTTS(text=textToTts, lang='en-us', slow=False)\n    \n        # current_directory = os.getcwd()\n        # mp3_file = os.path.join('media', \"tempAudioReportTts.mp3\")  \n        mp3_file = \"tempAudioReportTts.mp3\"\n        obj.save(mp3_file)\n    \n        # data = {\n        #     'mp3_file': request.build_absolute_uri(static(mp3_file)),\n        # }\n        data = FileResponse(open(mp3_file, 'rb'))\n        return data",
                "documentation": "takes in an ajaz request slug, finds the report and then gets its embendable text and then it processes its tts adn returns it LOADED"
            },
            {
                "function_name": "report",
                "parameters": [
                    "request",
                    "slug"
                ],
                "content": "    \n    \n        \n    \n        report = get_object_or_404(Report,slug=slug)\n        company = get_object_or_404(Company, name=report.company.name)\n        latest_reports_long = Report.objects.filter(company=company, is_published=True).order_by('-publish_date').values()\n        latest_reports = latest_reports_long[:6]\n    \n        latest_PCI_reports_long = Report.objects.filter(is_published=True).order_by('-publish_date').values()\n        latest_PCI_reports = latest_PCI_reports_long[:6]\n        reading_time = 2\n    \n        metrics = ReportMetric.objects.filter(report=report, is_estimate=False) ##Change this to ReportMetric\n        \n        user_highest_permission = user_highest_permission_finder(request.user)\n        \n        previous_reports = Report.objects.filter(company=company, publish_date__lt=report.publish_date).order_by('-publish_date')[:2]\n        twelve_months_back = report.publish_date - timedelta(days=365)\n        previous_reports_chart = Report.objects.filter(company=report.company, publish_date__lt=report.publish_date, publish_date__gte=twelve_months_back, type='Research Note', is_published=True).order_by('-publish_date').values('publish_date', 'target', 'rating') \n        ### ^^^^ MADE IT ONLY PUBLISHED\n        all_previous_reports = Report.objects.filter(\n            company=report.company,\n            publish_date__lte=report.publish_date,\n            type='Research Note'\n        ).order_by('-publish_date', '-id')  \n    \n    \n        print(\"DEBUGGG: \", report.get_absolute_url())\n    \n            \n        report_metric_fields = [\n            'target', 'price', 'potential_ror', 'avg_3month_daily_vol',\n            'shares_basic', 'shares_FD', 'marketcap_basic', 'marketcap_FD',\n            'revenue', 'gross_profit'\n        ]\n    \n        \n        metric_comparison = {}\n        \n        for field_name in report_metric_fields:\n            current_value = getattr(report, field_name)\n            metric_comparison[field_name] = None  \n            for prev_report in previous_reports:\n                prev_value = getattr(prev_report, field_name)\n                if current_value is not None and prev_value is not None:\n                    if current_value > prev_value:\n                        metric_comparison[field_name] = \"up\"\n                        break  \n                    elif current_value < prev_value:\n                        metric_comparison[field_name] = \"down\"\n                        break  \n    \n       \n        current_report_metrics = ReportMetric.objects.filter(report=report)\n        for metric in current_report_metrics:\n            metric_comparison[metric.name] = None  # Default value\n            for prev_report in previous_reports:\n                try:\n                    prev_metric = ReportMetric.objects.get(report=prev_report, name=metric.name)\n                    if metric.amount is not None and prev_metric.amount is not None:\n                        if metric.amount > prev_metric.amount:\n                            metric_comparison[metric.name] = \"up\"\n                            break\n                        elif metric.amount < prev_metric.amount:\n                            metric_comparison[metric.name] = \"down\"\n                            break\n                except ReportMetric.DoesNotExist:\n                    continue\n    \n    \n        if report.content:\n            if report.type == 'Research Note' or report.type == 'Sector':\n                if report.content and report.event:\n                    reading_time = simple_fast_reading_time(report.content + report.event)\n                elif report.content:\n                    reading_time = simple_fast_reading_time(report.content) ##oops I did double if and all of this, I didnt see I had content before, can leave it but should remove it\n                elif report.event:\n                    reading_time = simple_fast_reading_time(report.event)\n                else:\n                    reading_time = \"Less than a\"\n            else:\n                reading_time = simple_fast_reading_time(report.content)\n                if reading_time < 1:\n                    reading_time = \"Less than a\"\n        else:\n            reading_time = \"Less than a\"\n    \n        # company_disclaimers = CompanyDisclaimer.objects.select_related('disclaimer').filter(company=company)\n        # disclaimer_ids = company_disclaimers.values_list('disclaimer_id', flat=True)\n        # disclaimers = Disclaimer.objects.filter(id__in=disclaimer_ids)\n        company_disclaimers = ReportDisclaimer.objects.select_related('disclaimer').filter(report=report) #report_disclaimers now\n        disclaimer_ids = company_disclaimers.values_list('disclaimer_id', flat=True)\n        disclaimers = Disclaimer.objects.filter(id__in=disclaimer_ids)\n    \n        related_disclaimers = []\n        \n        for sub_comp in report.companies.all():\n            company_disclaimers2 = CompanyDisclaimer.objects.select_related('disclaimer').filter(company=sub_comp)\n            disclaimer_ids2 = company_disclaimers2.values_list('disclaimer_id', flat=True)\n            disclaimers2 = Disclaimer.objects.filter(id__in=disclaimer_ids2).values()\n    \n            new_comp_disclaimers = [sub_comp, disclaimers2]\n            related_disclaimers.append(new_comp_disclaimers)\n            \n    \n        group_list = ['Analyst Group', 'Editor Group', 'Compliance Group', 'Head Group']\n    \n        # estimate_metrics = ReportMetric.objects.filter(\n        #     report=report, \n        #     is_estimate=True\n        # ).order_by('name', 'year_estimated')\n        from collections import defaultdict\n    \n        # estimate_metrics = ReportMetric.objects.filter(is_estimate=True, report=report)\n    \n        ##ROLL OVER NOT TESTED HERE##ROLL OVER NOT TESTED HERE##ROLL OVER NOT TESTED HERE##ROLL OVER NOT TESTED HERE##ROLL OVER NOT TESTED HERE##ROLL OVER NOT TESTED HERE\n        current_year = report.publish_date.year\n        if report.company.FYE:\n            if report.publish_date.month > report.company.FYE.month:\n                current_year += 1\n            elif report.publish_date.month == report.company.FYE.month:\n                if report.publish_date.day >= report.company.FYE.day:\n                    current_year += 1\n        ##ROLL OVER NOT TESTED HERE##ROLL OVER NOT TESTED HERE##ROLL OVER NOT TESTED HERE##ROLL OVER NOT TESTED HERE##ROLL OVER NOT TESTED HERE##ROLL OVER NOT TESTED HERE\n        \n        previous_year = current_year - 1\n        next_year = current_year + 1\n    \n        estimate_metrics = ReportMetric.objects.filter(\n            report=report,\n            is_estimate=True,\n            year_estimated__in=[previous_year, current_year, next_year]\n        )\n    \n        # Grouping by metric name\n        grouped_estimate_metrics = {}\n        for metric in estimate_metrics:\n            if metric.name not in grouped_estimate_metrics:\n                grouped_estimate_metrics[metric.name] = {\n                    \"previous_year\": None,\n                    \"current_year\": None,\n                    \"next_year\": None\n                }\n            if metric.year_estimated == previous_year:\n                grouped_estimate_metrics[metric.name][\"previous_year\"] = metric.amount\n            elif metric.year_estimated == current_year:\n                grouped_estimate_metrics[metric.name][\"current_year\"] = metric.amount\n            elif metric.year_estimated == next_year:\n                grouped_estimate_metrics[metric.name][\"next_year\"] = metric.amount\n    \n    \n        ###unchaged logic\n    \n        \n        previous_report = Report.objects.filter(\n            company=report.company,\n            publish_date__year=previous_year\n        ).first()\n    \n        if previous_report:\n            previous_report_estimates = ReportMetric.objects.filter(\n                report=previous_report,\n                is_estimate=True\n            )\n            ###########THIS WORKS FROM OLD TO NEW\n            \n            # for metric in previous_report_estimates:\n            #     if metric.name in grouped_estimate_metrics and metric.year_estimated in [previous_year, current_year, next_year]:\n            #         if grouped_estimate_metrics[metric.name][f\"{metric.year_estimated}\"] != metric.amount:\n            #             grouped_estimate_metrics[metric.name][f\"previous_{metric.year_estimated}\"] = metric.amount\n            #         else:\n            #             grouped_estimate_metrics[metric.name][f\"previous_{metric.year_estimated}\"] = \"Unchanged\"\n            #     else: ##this just add the unchaged if nothing matches\n            #         grouped_estimate_metrics[metric.name][f\"previous_{metric.year_estimated}\"] = \"Unchanged\"\n            ###########THIS WORKS FROM OLD TO NEW\n    \n            ###########THIS WORKS FROM NEW TO OLD\n            previous_report_estimates_dict = {f\"{metric.name}_{metric.year_estimated}\": metric.amount for metric in previous_report_estimates}\n    \n            # Iterate over the estimates of the current report\n            for metric_name, years in grouped_estimate_metrics.items():\n                new_items = {}  # Create a dictionary to store new items\n                for year, amount in years.items():\n                    key = f\"{metric_name}_{year}\"\n                    if key in previous_report_estimates_dict:\n                        if amount != previous_report_estimates_dict[key]:\n                            new_items[f\"previous_{year}\"] = previous_report_estimates_dict[key]\n                        else:\n                            new_items[f\"previous_{year}\"] = \"Unchanged\"\n                    else:\n                        new_items[f\"previous_{year}\"] = \"Unchanged\"\n                years.update(new_items)  # Update the original dictionary after the loop\n            ###########THIS WORKS FROM NEW TO OLD\n        ###unchaged logic\n        pubProcess = False\n        if request.method == 'POST': ##missing move to draft?\n            if 'send_to_editing' in request.POST:\n                try:\n                    reportLog: GeneralLog = GeneralLog.objects.create(report=report, by_whom=get_object_or_404(Profile, user=request.user))\n                    reportLog.moved_to_edit()\n                except:\n                                print('error logging')\n                report.is_draft = False\n                report.is_reviewing = True\n                report.save()\n                send_notification_to('editor')\n            elif 'send_to_compliance' in request.POST:\n                try:\n                    reportLog: GeneralLog = GeneralLog.objects.create(report=report, by_whom=get_object_or_404(Profile, user=request.user))\n                    reportLog.moved_to_compliance()\n                except:\n                                print('error logging')\n                report.is_reviewing = False\n                report.is_compliance = True\n                report.save()\n                send_notification_to('compliance')\n            elif 'send_to_editor' in request.POST:\n                try:\n                    reportLog: GeneralLog = GeneralLog.objects.create(report=report, by_whom=get_object_or_404(Profile, user=request.user))\n                    reportLog.sent_back_to_editor()\n                except:\n                                print('error logging')\n                report.is_compliance = False\n                report.is_reviewing = True\n                report.save()\n                send_notification_to('editor')\n            elif 'publish_report' in request.POST:\n                try:\n                    reportLog: GeneralLog = GeneralLog.objects.create(report=report, by_whom=get_object_or_404(Profile, user=request.user))\n                    reportLog.approved_to_publish()\n                except:\n                                print('error logging')\n                report.is_compliance = False\n                report.is_published = True\n                report.save()\n                put_report_to_publish(request, report)\n                pubProcess = True\n            elif 'convert_from_legacy' in request.POST:\n                try:\n                    reportLog: GeneralLog = GeneralLog.objects.create(report=report, by_whom=get_object_or_404(Profile, user=request.user))\n                    reportLog.validate_legacy()\n                except:\n                                print('error logging')\n                report.is_published = True\n                report.is_draft = False\n                report.is_compliance = False\n                report.is_reviewing = False\n                report.is_validated = True\n                report.save()\n                \n        report_path_aws = report.temp_pdf_path or \"nopdf\"\n        try:\n            report_path_aws = report.temp_pdf_path.rpartition('/')[-1].partition('.')[0]+'.pdf'\n        except:\n            print('none detected in path', report_path_aws)\n        context = {\n            \"report\": report,\n            \"latest_reports\": latest_reports,\n            \"latest_PCI_reports\": latest_PCI_reports,\n            \"reading_time\": reading_time,\n            \"disclaimers\": disclaimers,\n            \"related_disclaimers\": related_disclaimers,\n            \"metrics\": metrics,\n            \"metric_comparison\": metric_comparison,\n            \"previous_reports\": previous_reports_chart,\n            'all_previous_reports': all_previous_reports,\n            'pdf_url': f'https://s3djangostatic.s3.ca-central-1.amazonaws.com/{report_path_aws}',\n            'group_list': group_list,\n            'user_permission': user_highest_permission,\n            \"grouped_estimate_metrics\": grouped_estimate_metrics,\n            \"current_year\": current_year,\n            \"previous_year\": previous_year,\n            \"next_year\": next_year,\n        }\n        # https://research.paradigmcap.com/media//WELL/WELL_2023_07_24.pdf\n        # https://research.paradigmcap.com/media/{report.company.slug}/{report.pdf}\n        try:\n            del request.session[\"output_data\"] #for email generator\n        except:\n            #no data\n            pass\n    \n        if report.type == 'Sector' or report.type == 'Sector Note':\n            associatedCompanyMetrics = SectorMetric.objects.filter(sectorReport=report)\n            print(associatedCompanyMetrics)\n            SectorMetrics = []\n            metricsRating = associatedCompanyMetrics.filter(name='Rating')\n            metricsTarget = associatedCompanyMetrics.filter(name='Target')\n    \n            for rating in metricsRating:\n                for target in metricsTarget:\n                    if rating.company.name == target.company.name:\n                        compp = get_object_or_404(Company, name=rating.company.name)\n                        secDict = {\n                            'comp': rating.company.name,\n                            'company': compp,\n                            'rating': rating.amount,\n                            'target': target.amount\n                        }\n                        \n                        SectorMetrics.append(secDict)\n            context['companies'] = SectorMetrics\n    \n            \n    \n            \n        if pubProcess == True:\n            # request.session['pdf'] = report.slug\n            return redirect('upload-pdf', slug=report.slug)\n        if report.is_legacy == True and report.is_validated == False:\n            return render(request, \"legacy_report.html\", context)\n        if report.type == 'Research Note' or report.type == 'Sector' or report.type == 'Sector Note':\n            return render(request, 'combined_report_page.html', context)\n            # return render(request, \"report_page.html\", context)\n        else:\n            return render(request, 'combined_report_page.html', context)",
                "documentation": "the report view, it is in charge of determining and loading the selected report and what type is it, it load legacy sector flash and init and normal report notes as well as determining the arrows and uncahnged values of a rpeort and its abilityt to send them"
            },
            {
                "function_name": "magic_report_view",
                "parameters": [
                    "request",
                    "slug",
                    "token"
                ],
                "content": "        if request.user.is_authenticated:\n            login(request, request.user)\n    \n        signed_username = request.COOKIES.get('pciu')\n        username = None\n        if signed_username:\n            try:\n                # Decrypt the username\n                username = signing.loads(signed_username)\n            except signing.BadSignature:\n                # Handle the exception here (e.g., the cookie was tampered with)\n                pass\n            if User.objects.filter(username=username).exists():\n                theUser = User.objects.filter(username=username).first()\n                login(request, theUser)\n                report = get_object_or_404(Report, slug=slug)\n                return redirect(report.get_absolute_url())\n        magic_link = get_object_or_404(MagicLinkToken, token=token)\n    \n        \n        if timezone.now() > ( magic_link.issued + timedelta(days=7) ):\n            if Profile.objects.filter(user=magic_link.user).exists():\n                Profile.objects.filter(user=magic_link.user).first().delete()\n            magic_link.user.delete()\n            magic_link.delete()\n            redirect('login')\n        \n        login(request, magic_link.user)\n    \n        report = get_object_or_404(Report, slug=slug)\n        return redirect(report.get_absolute_url())",
                "documentation": "not visible really but in charge of the magic link tokens"
            },
            {
                "function_name": "share_report_AJAX",
                "parameters": [
                    "request",
                    "slug"
                ],
                "content": "        # print('test?')\n        share_link = createReportLinkToShare(Report.objects.get(slug=slug))\n        return JsonResponse({'shareLink': share_link})",
                "documentation": "sharing report ajax from a report"
            },
            {
                "function_name": "upload_pdf",
                "parameters": [
                    "request",
                    "slug"
                ],
                "content": "        report = get_object_or_404(Report, slug=slug)\n        print('TOUCHED')\n        put_report_to_publish(request, report)\n        # slug = request.session['uploadSlug']\n        \n        if request.method == 'POST':\n            print('TOUCHED')\n            file = request.FILES.get('pdf_file')\n            if file:\n                # Upload to S3\n                publish_date = report.publish_date or timezone.now()  \n                date_str = publish_date.strftime(\"%Y_%m_%d\")  \n                ticker = report.company.ticker\n    \n                report_type = report.type.lower()  \n                type_str = \"\"\n                if report_type == 'research note':\n                    type_str = \"\"\n                elif report_type == 'flash note':\n                    type_str = \"_Flash_note\"\n                elif report_type == 'sector note':\n                    type_str = \"_Sector_note\"\n                elif report_type == 'initiation report':\n                    type_str = \"_Initiation_report\"\n    \n                filename = f\"{ticker}_{date_str}{type_str}.pdf\"  \n                print(filename)\n                bucket_name = 's3djangostatic'\n                s3_path = f\"{bucket_name}/{filename}\"\n                \n                try:\n                    s3 = boto3.client('s3', aws_access_key_id=settings.AWS_ACCESS_KEY_ID, aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY)\n                    s3.upload_fileobj(file, bucket_name, filename)\n                    report.temp_pdf_path = s3_path\n                    report.save()\n                    return redirect('home')\n                except:\n               \n                    print('failed')\n                    context = {'error': 'S3 failed',\n                           'report': report}\n                    return render(request, 'tempUploadPage.html', context)\n            else:\n                # If no file is uploaded, redisplay the form with an error message\n                context = {'error': 'No file uploaded',\n                           'report': report}\n                return render(request, 'tempUploadPage.html', context)\n        \n        context = {\n            'report': report,\n        }\n    \n        return render(request, 'tempUploadPage.html', context)",
                "documentation": "this is the last step on the uplaod process it will request the user to upload a file after published and it will save it using the correct nomenclature to s3 bucket"
            },
            {
                "function_name": "pdf_report_template",
                "parameters": [
                    "request",
                    "slug"
                ],
                "content": "        report = get_object_or_404(Report, slug=slug)\n        \n        # Retrieve all estimated metrics and sort them by name and then by year\n        estimated_metrics = report.report_id_CHANGETHIS.filter(is_estimate=True).order_by('name', 'year_estimated')\n    \n        # Extract unique years and sort them\n        unique_years = sorted(set(metric.year_estimated for metric in estimated_metrics if metric.year_estimated is not None))\n    \n        # Create a list of lists structure\n        metrics_list = []\n        metrics_grouped = defaultdict(list)\n        for metric in estimated_metrics:\n            metrics_grouped[metric.name].append(metric)\n    \n        for name, metrics in metrics_grouped.items():\n            row = [name]\n            for year in unique_years:\n                metric_for_year = next((m.amount for m in metrics if m.year_estimated == year), None)\n                row.append(metric_for_year)\n            metrics_list.append(row)\n    \n        # print(metrics_list)\n        # other_analysts = report.other_analysts.all()\n    \n        previous_report = Report.objects.filter(publish_date__lt=report.publish_date, is_published = True, type__in=['Research Note', 'Sector Note', 'Initiating Coverage']).order_by('-publish_date').first()\n    \n        # Check if the rating and target are the same or different\n        rating_change = \"Unchanged\"\n        if previous_report:\n            if previous_report.rating and previous_report.rating != report.rating:\n                rating_change = f\"Previously {previous_report.rating}\"\n    \n        target_change = \"Unchanged\"\n        if previous_report:\n            if previous_report.target and previous_report.target != report.target:\n                target_change = f\"Previously {previous_report.target}\"\n    \n        context = {\n            'report': report,\n            'metrics_list': metrics_list,\n            'unique_years': unique_years,\n            'rating_change': rating_change,\n            'target_change': target_change,\n            \n        } #'other_analysts': other_analysts,\n    \n        return render(request, 'pdf_report_templateTAILWIND.html', context)",
                "documentation": "load the pdf tepalte given a rpeort it does use tailwind"
            },
            {
                "function_name": "report_email_template",
                "parameters": [
                    "request",
                    "slug"
                ],
                "content": "        report_instance = get_object_or_404(Report, slug=slug)\n        all_reports = Report.objects.all().values('title', 'slug')\n        output_content = \"\"\n        output_content = request.session.get(\"output_data\")\n        added_reports = []\n        if request.method == \"POST\":\n            # Extract data directly from request.POST\n            # title = request.POST.get('title')\n            # rating = request.POST.get('rating')\n            # target = request.POST.get('target')\n            # type_ = request.POST.get('type')\n            event = report_instance.event #request.POST.get('event')\n    \n            \n            extra_reports = request.POST.getlist('report_slug')\n            print('DEBUGGGGGGG:', extra_reports)\n            for report in extra_reports:\n                report_slug = report\n                additional_report = Report.objects.get(slug=report_slug)\n    \n                rating = additional_report.rating if additional_report.rating is not None else additional_report.company.current_rating\n                target = additional_report.target if additional_report.target is not None else additional_report.company.current_target\n    \n    \n                report_data = {\n                    'publish_date': additional_report.publish_date.strftime(\"%B %d, %Y\"),\n                    'type': additional_report.type,\n                    'rating': rating,\n                    'target': target,\n                    'title': additional_report.title,\n                    'event': additional_report.event,\n                    'company_name': additional_report.company.name,\n                    'company_current_target': additional_report.company.current_target,\n                    'full_report': additional_report\n                }\n                added_reports.append(report_data)\n    \n            # Render the email content using a template\n            output_content = render_to_string('email_output_template.html', {\n                'title': report_instance.title,\n                'rating':  report_instance.rating if report_instance.rating is not None else report_instance.company.current_rating,\n                'target': report_instance.target if report_instance.target is not None else report_instance.company.current_target,\n                'type': report_instance.type,\n                'event': event,\n                'report': report_instance,\n                'added_reports': added_reports\n            })\n            subject = f'Research Brief:{report_instance.company.name}'\n            if added_reports:\n                ticker_list = [added['full_report'].company.ticker for added in added_reports]\n                ticker_list.append(report_instance.company.ticker)\n                unique_tickers = ', '.join(set(ticker_list))  # Ensures each ticker is only listed once\n                subject = f'Research Brief: {unique_tickers}'\n            else:\n                subject = f'Research Brief: {report_instance.company.name}'\n            message = '' \n            from_email = 'Paradigm Research <myamani@paradigmcap.com>'\n            recipient_list = ['apolo@paradigmcap.com', 'alejandrogarcia2423@hotmail.com']\n            html_message=output_content\n    \n            send_mail(subject, message, from_email, recipient_list, html_message=html_message)\n    \n        context= {'report': report_instance, \n                  'output_content': output_content,\n                  'all_reports': all_reports}\n        \n        return render(request, 'email_template.html', context)",
                "documentation": "it takes care of taking in a rpeort and publishing and sending its research brienf email"
            },
            {
                "function_name": "report_email_template2",
                "parameters": [
                    "request",
                    "slug"
                ],
                "content": "        report_instance = get_object_or_404(Report, slug=slug)\n        all_reports = Report.objects.all().values('title', 'slug')\n    \n        if request.method == \"POST\":\n            # Extract data directly from request.POST\n            title = request.POST.get('title')\n            rating = request.POST.get('rating')\n            target = request.POST.get('target')\n            type_ = request.POST.get('type')\n            event = request.POST.get('event')\n            save_to_model = 'save_to_model' in request.POST\n    \n            added_reports = []\n            total_reports = int(request.POST.get('total_reports', 0))\n            for i in range(1, total_reports + 1):\n                report_slug = request.POST.get(f'report_slug_{i}')\n                additional_report = Report.objects.get(slug=report_slug)\n                report_data = {\n                    'publish_date': additional_report.publish_date.strftime(\"%B %d, %Y\"),\n                    'type': additional_report.type,\n                    'rating': additional_report.rating,\n                    'target': additional_report.target,\n                    'title': additional_report.title,\n                    'event': additional_report.event,\n                    'company_name': additional_report.company.name,\n                    'company_current_target': additional_report.company.current_target\n                    # Add more fields as needed\n                }\n                added_reports.append(report_data)\n    \n            # Render the email content using a template\n            output_content = render_to_string('email_output_template.html', {\n                'title': title,\n                'rating': rating,\n                'target': target,\n                'type': type_,\n                'event': event,\n                'report': report_instance,\n                'added_reports': added_reports\n            })\n    \n            if save_to_model:\n                # Save the data to the model\n                report_instance.title = title\n                report_instance.rating = rating\n                report_instance.target = target\n                report_instance.type = type_\n                report_instance.event = event\n                report_instance.save()\n     \n            subject = f'Research Brief:{report_instance.company.name}'\n            if added_reports:\n                ticker_list = [added['full_report'].company.ticker for added in added_reports]\n                unique_tickers = ', '.join(set(ticker_list))  # Ensures each ticker is only listed once\n                subject = f'Research Brief: {unique_tickers}'\n            else:\n                subject = f'Research Brief: {report_instance.company.name}'\n            # Example email sending (customize as needed)\n            \n            message = '' \n            from_email = 'Paradigm Research <myamani@paradigmcap.com>'\n            recipient_list = ['apolo@paradigmcap.com', 'alejandrogarcia2423@hotmail.com']\n            html_message=output_content\n    \n            send_mail(subject, message, from_email, recipient_list, html_message=html_message)\n    \n            return redirect('email_template', slug=slug)\n    \n        return render(request, 'email_template.html', {\n            'report': report_instance,\n            'all_reports': all_reports,\n            # 'output_content': output_content  \n        })"
            },
            {
                "function_name": "report_email_templateDEPRECRATED",
                "parameters": [
                    "request",
                    "slug"
                ],
                "content": "        print('dep')\n        report_instance = Report.objects.get(slug=slug)\n        all_reports = Report.objects.all()\n        output_content = \"\"\n        \n        report_instance.publish_date =  str(report_instance.publish_date)\n        print(report_instance.publish_date)\n        \n        if request.method == \"POST\":\n            form = EmailTemplateReportForm(request.POST, instance=report_instance)\n            print(form.errors)\n            if form.is_valid():\n                title = form.cleaned_data['title']\n                rating = form.cleaned_data['rating']\n                target = form.cleaned_data['target']\n                type_ = form.cleaned_data['type']\n                event = form.cleaned_data['event']\n                \n                \n                added_reports = []\n                for i in range(1, int(request.POST.get('total_reports', 0)) + 1):\n                    reportTitle = request.POST.get(f'title_{i}')\n                    reportEvent = request.POST.get(f'event_{i}')\n                    company_name = \"\"\n                    company_current_target = \"\"\n                    company_industry = \"\"\n                    try:\n                        company_name = all_reports.get(title=reportTitle).company.name\n                        company_current_target = all_reports.get(title=reportTitle).company.current_target\n                        company_industry = all_reports.get(title=reportTitle).company.industry\n                    except:\n                        company_name = all_reports.get(event=reportEvent).company.name\n                        company_current_target = all_reports.get(event=reportEvent).company.current_target\n                        company_industry = all_reports.get(event=reportEvent).company.industry\n    \n                    report_data = {\n                        'publish_date': request.POST.get(f'publish_date_{i}'),\n                        'type': request.POST.get(f'type_{i}'),\n                        'rating': request.POST.get(f'rating_{i}'),\n                        'target': request.POST.get(f'target_{i}'),\n                        'title': reportTitle,\n                        'event': reportEvent,\n                        'industry': company_industry,\n                        'company_name': company_name,\n                        'company_current_target': company_current_target\n                    }\n                    added_reports.append(report_data)\n                \n                \n                save_to_model = 'save_to_model' in request.POST\n                if save_to_model:\n                    form.save()\n                \n                data = form.cleaned_data\n                output_content = render_to_string('email_output_template.html', {'data': data, 'report': report_instance, 'added_reports': added_reports})\n                request.session[\"output_data\"] = output_content\n                \n                subject = f'Research Brief:{report_instance.company.name}'\n                message = '' \n                from_email = 'Paradigm Research <myamani@paradigmcap.com>'\n                recipient_list = ['apolo@paradigmcap.com', 'alejandrogarcia2423@hotmail.com']\n                html_message=output_content\n    \n                send_mail(subject, message, from_email, recipient_list, html_message=html_message)\n                return redirect('email_template', slug=slug)\n        else:\n            form = EmailTemplateReportForm(instance=report_instance)\n        output_content = request.session.get(\"output_data\")\n    \n        return render(request, 'email_template.html', {'form': form, 'report': report_instance, 'output_content': output_content, 'all_reports': all_reports})"
            },
            {
                "function_name": "magic_link",
                "parameters": [
                    "request"
                ],
                "content": "    \n        error_message = False\n        \n        context = {\n            'error_message': error_message,\n            'hide_search': True\n        }\n        if request.method == \"POST\":\n            email = request.POST.get('email')\n            user = User.objects.filter(username=email).first()\n            print('IN POST and: ', user)\n            if user:\n                if MagicLinkToken.objects.filter(user=user).first() != None:\n                    ## expiration logic here too\n                    return redirect('login')\n                token = secrets.token_urlsafe(20)\n                \n                MagicLinkToken.objects.create(user=user, token=token)\n    \n                link = request.build_absolute_uri(reverse('magic_link_login', args=[token]))\n                print(link)\n    \n                send_mail(\n                    subject='Paradigm Capital login request',\n                    message=f'Your magic link login is this {link}',  # Leave it empty as we're sending HTML content\n                    from_email='myamani@paradigmcap.com',  # Use the default sender specified in EMAIL_HOST_USER,\n                    recipient_list= [email], # in prod we change it to f'{email}'[MAIL_TEMPLATE_OUTPUT_EMAIL]\n                    html_message=f'Your magic link login is this <a href={link}>{link}</a>'\n                )\n    \n                return redirect('login') ## we need to create a success and failiour template for these things too\n            else:\n                error_message = True\n                context = {\n                    'error_message': error_message,\n                    'hide_search': True\n                }\n                return render(request, 'magic_link_screen.html', context)\n    \n        return render(request, 'magic_link_screen.html')",
                "documentation": "the actual view if you do a magic link log in"
            },
            {
                "function_name": "magic_link_login",
                "parameters": [
                    "request",
                    "token"
                ],
                "content": "        magic_link = MagicLinkToken.objects.filter(token=token).first()\n    \n        if magic_link:\n    \n            ## Need to add expiration logic\n            # if magic_link.issued + \n            # print(magic_link)\n            login(request, magic_link.user)\n            \n            if timezone.now() > magic_link.issued + timedelta(days=1):\n                magic_link.delete()\n    \n            return redirect('home')\n        # else:\n        #     return redirect('magic_link_login')\n        \n        return redirect('login')",
                "documentation": "the view to process the magic link login if successful"
            },
            {
                "function_name": "sentiment_analysis_api",
                "parameters": [
                    "request",
                    "slug"
                ],
                "content": "        \n        if request.method == 'POST':\n            \n            try:\n                data = json.loads(request.body)\n                \n                text = data['text']\n                \n                if text != 'None' and text != \"\":\n                    \n                    sentiment = get_highest_confidence_sentiment(text, type='summary')\n                    print(\"in\")\n                    return JsonResponse({'sentiment': sentiment})\n                else:\n                    print('out')\n                    return JsonResponse({'sentiment': \"No event\"})\n            except Exception as e:\n                print('fail')\n                return JsonResponse({'error': str(e)})",
                "documentation": "ajax for experimental sentimental and summary views"
            },
            {
                "function_name": "company",
                "parameters": [
                    "request",
                    "slug"
                ],
                "content": "        company = get_object_or_404(Company, slug=slug)\n        fetch_and_update_company_metrics(company)\n        latest_reports = Report.objects.filter(company=company).filter(is_published=True).values()\n        metrics = CompanyMetric.objects.filter(company=company, is_estimate=False)\n    \n        company_disclaimers = CompanyDisclaimer.objects.select_related('disclaimer').filter(company=company)\n        disclaimer_ids = company_disclaimers.values_list('disclaimer_id', flat=True)\n        disclaimers = Disclaimer.objects.filter(id__in=disclaimer_ids)\n        \n        available_disclaimers = Disclaimer.objects.exclude(id__in=disclaimer_ids)\n    \n        if request.method == 'POST':\n            action = request.POST.get('action')\n            disclaimer_id = request.POST.get('disclaimer_id')\n    \n            if action == 'add':\n                disclaimer = get_object_or_404(Disclaimer, id=disclaimer_id)\n                CompanyDisclaimer.objects.get_or_create(company=company, disclaimer=disclaimer)\n            elif action == 'remove':\n                CompanyDisclaimer.objects.filter(company=company, disclaimer_id=disclaimer_id).delete()\n            \n            new_metrics = request.POST.get('metrics', '').strip()\n            company.metrics = new_metrics\n            company.save()\n            metrics = CompanyMetric.objects.filter(company=company)\n    \n            return redirect(f'company', slug=slug)  \n        \n        current_year = datetime.now().year\n    \n        if company.is_rollover:\n            current_year += 1\n    \n        estimated_metrics = CompanyMetric.objects.filter(company=company, is_estimate=True, year_estimated__range=[current_year-1, current_year+1])\n      \n        ordered_metrics = estimated_metrics.order_by('name', 'year_estimated')\n        \n        em_list = list(ordered_metrics)\n    \n        \n        def sort_func(x):\n            if 'ebdita' in x[0].name:\n                return 0\n            elif 'Revenue' in x[0].name:\n                return 1\n            elif 'EPS' in x[0].name:\n                return 2\n            else:\n                return 3\n        # def sort_func(x):\n        #     name = x[0].name.lower()  \n        #     if 'eps' in name:\n        #         return 0\n        #     elif 'revenue' in name:\n        #         return 1\n        #     elif 'ebdita' in name:\n        #         return 2\n        #     else:\n        #         return 3\n    \n        \n    \n        grouped_estimates = [em_list[n:n+3] for n in range(0, len(em_list), 3)]\n        grouped_estimates.sort(key=sort_func)\n    \n        context = {\n            \"company\": company,\n            \"latest_reports\": latest_reports,\n            \"metrics\": metrics,\n            \"disclaimers\": disclaimers,\n            \"available_disclaimers\": available_disclaimers,\n            \"estimates\": grouped_estimates,\n        }\n    \n        return render(request, \"company_page.html\", context)",
                "documentation": "the company page in charge of fetching updated metrics and all of the concurent actions"
            },
            {
                "function_name": "drafter_masterview",
                "parameters": [
                    "request",
                    "slug"
                ],
                "content": "        \"\"\"Used to evaluate and dislay the logic for the head analyst to use\"\"\"\n        full_workflow()\n        if slug:\n            slugSelected = True\n        else:\n            slugSelected = False\n        all_reports = Report.objects.all()\n        all_analysts = Analyst.objects.all()\n        \n        statisticsData = process_and_pickle_data()\n        reportData = []\n        homeDicts = []\n        companyData = []\n        searchData = []\n    \n        i = 0\n        for dicts in statisticsData:\n            if '127.0.0.1:8000' in dicts['URL'] or 'http://127.0.0.1:8000/report/' in dicts['URL'] or '127' in dicts['URL']:\n                statisticsData.remove(dicts)\n                print('Yupp:', dicts)\n                del statisticsData[i]\n            i += 1\n    \n        for dicts in statisticsData:\n            if 'report' in dicts['URL']:\n                reportData.append(dicts)\n            elif 'company' in dicts['URL']:\n                companyData.append(dicts)\n            elif '/search/' in dicts['URL']:\n                searchData.append(dicts)\n            elif 'home' in dicts['URL'] or dicts['URL'] == 'https://research.paradigmcap.com/':\n                # print('Home is here $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$')\n                homeDicts.append(dicts)\n    \n        if len(homeDicts) > 1:\n            tempDic = homeDicts[0]\n            tempDic['totalUsers'] = str(int(tempDic['totalUsers']) + int(homeDicts[1]['totalUsers']))\n            tempDic['totalSeconds'] = str(int(tempDic['totalSeconds']) + int(homeDicts[1]['totalSeconds']))\n            tempDic['averageScroll'] = str((float(tempDic['averageScroll']) + float(homeDicts[1]['averageScroll']))/2 )\n            homeDicts = tempDic\n            # print('more than one', tempDic, 'and', homeDicts)\n    \n    \n        statisticsData = {'reportData':reportData,\n                          'companyData':companyData, \n                          'homeData': homeDicts, \n                          'searchData': searchData,\n                          }\n        print(statisticsData)\n        \n        data_by_analyst = [] ##It goes like this,\n        ######################0 analyst, 1 published reports, 2 in_compliance, 3 in_review, 4 drafts, 5 sent_back_reports, 6 latest report, \n        ######################7 currently drafting, 8 avg words per report\n        for analyst in all_analysts:\n            group = [analyst]\n            group.append(len(Report.objects.filter(analyst=analyst, publish_date__gte=datetime.now()-timedelta(days=7)).order_by('publish_date').values()))\n            group.append(len(Report.objects.filter(analyst=analyst, is_compliance=True).order_by('updated').values()))\n            group.append(len(Report.objects.filter(analyst=analyst, is_reviewing=True).order_by('updated').values()))\n            group.append(len(Report.objects.filter(analyst=analyst, is_draft=True).order_by('updated').values()))\n    \n            group.append(len(Report.objects.filter(analyst=analyst, is_draft=True).exclude(comments=None).exclude(comments=\"\")))\n            # group.append(Report.objects.all().order_by('updated')[:7]) #first seven\n            # companies_this_week = []\n            # for report in Report.objects.filter(analyst=analyst, publish_date__gte=datetime.now()-timedelta(days=7)).order_by('publish_date'):\n            #     companies_this_week.append(report.company)\n            # group.append(companies_this_week)\n    \n    \n            if Report.objects.filter(analyst=analyst, is_published=True).exists():\n                group.append(Report.objects.filter(analyst=analyst, is_published=True).order_by('publish_date').first())\n            else:\n                group.append(\"None published\")\n    \n    \n            \n            if Report.objects.filter(analyst=analyst, is_draft=True).exists():\n                group.append(Report.objects.filter(analyst=analyst, is_draft=True).order_by('publish_date').first())\n            else:\n                group.append(\"None drafting\")\n    \n            group.append(avgWordsPerReport(Report.objects.filter(analyst=analyst, publish_date__gte=datetime.now()-timedelta(days=10)).order_by('publish_date')))\n    \n            data_by_analyst.append(group)\n        \n        general_data = []\n    \n        reports_published_this_week = Report.objects.filter(publish_date__gte=datetime.now()-timedelta(days=7)).order_by('publish_date')\n        general_data.append(reports_published_this_week) ## It goes like this, 0 reports_pub_this_week, 1 \n        \n    \n        count_data = [] ## it goes like, 0 total count of reports, currently in 1 drafts, 2 review, 3 compliance, 4 how many published this week, 5 avg words per publish, 6 latest published,\n        ##                 7 sent back reports\n    \n        count_data.append(len(all_reports))\n        count_data.append(len(Report.objects.filter(is_draft=True)))\n        count_data.append(len(Report.objects.filter(is_reviewing=True)))\n        count_data.append(len(Report.objects.filter(is_compliance=True)))\n        count_data.append(len(reports_published_this_week))\n        count_data.append(avgWordsPerReport(Report.objects.filter(publish_date__gte=datetime.now()-timedelta(days=10)).order_by('publish_date')))\n        if Report.objects.filter(is_published=True).order_by('publish_date').first():\n            count_data.append(str(Report.objects.filter(is_published=True).order_by('publish_date').first().analyst.profile))\n        else: \n            count_data.append(\"None published\")\n    \n        count_data.append(len(Report.objects.filter(is_draft=True, comments__isnull=False)))\n        \n    \n        current_drafts_scores = Report.objects.filter( \n                                                        Q(is_draft=True) | Q(is_reviewing=True) | Q(is_compliance=True),\n                                                        is_published=False\n                                                    )\n        results = []\n        for reportS in current_drafts_scores:\n            result = [reportS]\n            appendium = None\n            try:\n                appendium = predict_report_score(reportS)\n            except:\n                print('error in appendium, masterview, predict_report_score ##$$##$$##$$#')\n                appendium = None\n            result.append(appendium)\n            results.append(result)\n    \n        features_string = get_significant_features()\n        if features_string == None or features_string == 'No model available':\n            features_string = None\n        print('FEATURES:', features_string)\n        context = {\n            \"slugSelected\": slugSelected,\n            \"data_by_analyst\": data_by_analyst,\n            \"general_data\": general_data,\n            \"count_data\": count_data,\n            \"statisticsData\": statisticsData,\n            'reports_scores': results,\n            'model_features_string':features_string\n        }\n    \n        if ExcelStatistic.objects.filter(name='avg30').exists() and ExcelStatistic.objects.filter(name='median30').exists():\n            context['excelData'] = {'avg30': ExcelStatistic.objects.filter(name='avg30').first().value*100 , 'median30':ExcelStatistic.objects.filter(name='median30').first().value*100}\n        print(\"general start\")\n        print(general_data)\n        print(\"general end\")\n        print(\"count start\")\n        print(count_data)\n        print(\"count end\")\n    \n        if slugSelected == True:\n            selectedAnalyst = get_object_or_404(Analyst, profile__email=slug)\n            context['selectedAnalyst'] = selectedAnalyst\n        return render(request, 'drafter_masterview.html', context)",
                "documentation": "this masterview is in charge of fetcing all of the metrics of all analysts and pages as well from clarity and from excel morning notes, it also is in chrage of updaing and fetching nw info for the ml model every 3 days at minimum if ran and it runs it into every analyst there that is drafting compliying or editing a report"
            },
            {
                "function_name": "company_drafter",
                "parameters": [
                    "request"
                ],
                "content": "    \n        if request.method == 'POST':\n            user = request.user\n            profile = get_object_or_404(Profile, user=user)\n            analyst = get_object_or_404(Analyst, profile=profile)\n            comp_name = request.POST.get('company_name')\n            ticker = request.POST.get('ticker')\n            industry = request.POST.get('industry')\n            comp_descrp = request.POST.get('company_description')\n            invest_ths = request.POST.get('investment_thesis')\n            slug= slugify(comp_name+ticker)\n    \n            comp, created = Company.objects.update_or_create(name=comp_name, slug=slug,ticker=ticker, company_description=comp_descrp, investment_thesis=invest_ths, analyst=analyst, industry=industry, coverage=True)\n            comp.save()\n        \n        return render(request, 'company_drafter.html')",
                "documentation": "this is the place where analysts alike can generate a new company an admin SHOULD then fully fill it on the backend"
            },
            {
                "function_name": "company_selector",
                "parameters": [
                    "request"
                ],
                "content": "    \n        user = request.user\n        user_highest_permission = user_highest_permission_finder(user)\n        profile = get_object_or_404(Profile, user=user)\n        analyst = None\n        analystCompanies = None\n        if user_highest_permission == 'Analyst Group' or user_highest_permission == 'Head Group':\n            analyst = get_object_or_404(Analyst, profile=profile)\n            relatedAnalysts = Analyst.objects.filter(sector__icontains=analyst.sector)\n            \n            # Get the IDs of the related analysts\n            relatedAnalysts_ids = relatedAnalysts.values_list('id', flat=True)\n            \n            # Include the ID of the current analyst in the list\n            analyst_ids = list(relatedAnalysts_ids) + [analyst.id]\n            \n            analystCompanies = Company.objects.filter(analyst__id__in=analyst_ids, coverage=True)\n    \n        context = {\n            'user_permission': user_highest_permission,\n            'profile': profile,\n            'companies': analystCompanies,\n    \n        }\n    \n        return render(request, 'company_selector.html', context)",
                "documentation": "the selector view to choose and view revelant information about a company"
            },
            {
                "function_name": "report_selector",
                "parameters": [
                    "request"
                ],
                "content": "        \"\"\"This view is in charge of connecting the analyst, editor, compliance officers into their main menu for editing, think of it\n        as a main menu that we can expand upon later, as of now it gives statuses on report and directly connects them to the drafter app\n        where they may work and edit their reports (or comply them)\"\"\"\n        \n        if request.method == 'POST': ##add if analyst if expanded later\n            selected_reports = request.POST.getlist('selectedReports')\n            # print(selected_reports)\n            if 'delete' in request.POST:\n                Report.objects.filter(id__in=selected_reports).delete()\n            elif 'edit' in request.POST:\n                reports = Report.objects.filter(id__in=selected_reports).update(is_draft=False, is_reviewing=True)\n                print(reports)\n    \n        is_super_editor = False\n        user = request.user\n        user_highest_permission = user_highest_permission_finder(user)\n        profile = get_object_or_404(Profile, user=user)\n    \n        analyst = None\n        reportDrafts, editingDrafts, complyDrafts = None, None, None\n    \n        if user_highest_permission == 'Analyst Group' or user_highest_permission == 'Head Group':\n            analyst = get_object_or_404(Analyst, profile=profile)\n            \n            eight_days_ago = timezone.now() - timedelta(days=8)\n            relatedAnalysts = Analyst.objects.filter(sector__icontains=analyst.sector)\n            \n            # reportDrafts = Report.objects.filter(\n            #     analyst=analyst,\n            #     is_draft=True\n            # ) | Report.objects.filter(\n            #     analyst=analyst,\n            #     is_reviewing=True\n            # ) | Report.objects.filter(\n            #     analyst=analyst,\n            #     is_compliance=True\n            # ) | Report.objects.filter(\n            #     analyst=analyst,\n            #     is_published=True,\n            #     publish_date__lte=eight_days_ago\n            # ).order_by('created').values()\n    \n            # reportDrafts = Report.objects.filter(\n            #     Q(analyst__in=relatedAnalysts),\n            #     Q(is_draft=True) |\n            #     Q(is_reviewing=True) |\n            #     Q(is_compliance=True) |\n            #     (Q(is_published=True) & Q(publish_date__lte=eight_days_ago))\n            # ).order_by('created').values()\n            # print('DEBDEDBUGGGGG', len(reportDrafts))\n            reportDrafts = Report.objects.filter(\n                analyst__in=relatedAnalysts,\n                is_draft=True\n            ) | Report.objects.filter(\n                analyst__in=relatedAnalysts,\n                is_reviewing=True\n            ) | Report.objects.filter(\n                analyst__in=relatedAnalysts,\n                is_compliance=True\n            ) | Report.objects.filter(\n                analyst__in=relatedAnalysts,\n                is_published=True,\n                publish_date__gte=eight_days_ago\n            ).order_by('created').values()\n        elif user_highest_permission == 'Editor Group':\n            editingDrafts = Report.objects.filter(is_reviewing=True).order_by('created').exclude(company__slug='')\n    \n            ####THIS WILL SLOW DOWN\n    \n            logs = GeneralLog.objects.filter(title='Report moved to edit')\n    \n            report_log_pairs = []\n    \n            for report in editingDrafts:\n                log = logs.filter(report=report).order_by('-time_logged').first()\n                if log is not None:\n                    report_log_pairs.append({\n                        'report': report,\n                        'time_logged': log.time_logged\n                    })\n                else:\n                    report_log_pairs.append({\n                        'report': report,\n                        'time_logged': report.created\n                    })\n    \n            editingDrafts = report_log_pairs\n    \n    \n            ####remove if slow\n            \n        elif user_highest_permission == 'Analyst Group':\n            pass\n        elif user_highest_permission == 'Compliance Group':\n            complyDrafts = Report.objects.filter(is_compliance=True).order_by('created')\n    \n            levels_str = []\n            levels = user.groups.all()\n    \n            for level in levels:\n                levels_str.append(level.name)\n            # print(levels, user.groups.all())\n            if 'Editor Group' in levels_str:\n                is_super_editor = True\n                editingDrafts = Report.objects.filter(is_reviewing=True).order_by('created').exclude(company__slug='')\n    \n                ####THIS WILL SLOW DOWN\n    \n                logs = GeneralLog.objects.filter(title='Report moved to edit')\n    \n                report_log_pairs = []\n    \n                for report in editingDrafts:\n                    log = logs.filter(report=report).order_by('-time_logged').first()\n                    if log is not None:\n                        report_log_pairs.append({\n                            'report': report,\n                            'time_logged': log.time_logged\n                        })\n                    else:\n                        report_log_pairs.append({\n                            'report': report,\n                            'time_logged': report.created\n                        })\n    \n                editingDrafts = report_log_pairs\n    \n        context = {\n            'user_permission': user_highest_permission,\n            'profile': profile,\n            'reportDrafts': reportDrafts,\n            'editingDrafts': editingDrafts,\n            'complyDrafts': complyDrafts,\n            'is_super_editor': is_super_editor\n    \n        }\n        \n        return render(request, 'report_selector.html', context)",
                "documentation": "report selector view, alike company selector it dysplays the status and selection list of report per every analyst and their associates"
            },
            {
                "function_name": "autosave_drafter",
                "parameters": [
                    "request",
                    "slug"
                ],
                "content": "        if request.method == 'POST':\n            report = None\n            try:\n                report = Report.objects.get(slug=slug)\n            except:\n                return JsonResponse({'error': 'error autosaving, report not found...'})\n    \n            \n            try:\n                recomendation = request.POST.get('recomendation')\n                target = request.POST.get('target')\n                price = request.POST.get('price')\n                potential_ror = request.POST.get('potential_ror')\n                avg_3month_daily_vol = request.POST.get('avg_3month_daily_vol')\n                shares_basic = request.POST.get('shares_basic')\n                shares_FD = request.POST.get('shares_FD')\n                marketcap_basic = request.POST.get('marketcap_basic')\n                marketcap_FD = request.POST.get('marketcap_FD')\n                revenue = request.POST.get('revenue')\n                gross_profit = request.POST.get('gross_profit')\n                content = request.POST.get('content')\n                event = request.POST.get('event')\n                title = request.POST.get('title')\n                investmentThesis = request.POST.get('investmentThesis')\n                takeout = request.POST.get('takeout')\n                valuation = request.POST.get('valuation')\n    \n                if recomendation not in (\"\", None):\n                    report.rating = recomendation\n                if target not in (\"\", None):\n                    report.target = target\n                if price not in (\"\", None):\n                    report.price = price\n                if potential_ror not in (\"\", None):\n                    report.potential_ror = potential_ror\n                if avg_3month_daily_vol not in (\"\", None):\n                    report.avg_3month_daily_vol = avg_3month_daily_vol\n                if shares_basic not in (\"\", None):\n                    report.shares_basic = shares_basic\n                if shares_FD not in (\"\", None):\n                    report.shares_FD = shares_FD\n                if marketcap_basic not in (\"\", None):\n                    report.marketcap_basic = marketcap_basic\n                if marketcap_FD not in (\"\", None):\n                    report.marketcap_FD = marketcap_FD\n                if revenue not in (\"\", None):\n                    report.revenue = revenue\n                if gross_profit not in (\"\", None):\n                    report.gross_profit = gross_profit\n                if content not in (\"\", None):\n                    report.content = content\n                if event not in (\"\", None):\n                    report.event = event\n                if title not in (\"\", None):\n                    report.title = title\n                if investmentThesis not in (\"\", None):\n                    report.report_investment_thesis = investmentThesis\n                if takeout not in (\"\", None):\n                    report.takeout = takeout\n                if valuation not in (\"\", None):\n                    report.valuation = valuation\n    \n    \n                report.save() \n    \n                return JsonResponse({'status': 'success'})\n            except Exception as e:\n                print('error in autosave:', e)\n                return JsonResponse({'error': 'error autosaving, report not found...'})",
                "documentation": "this ajax is used to autosave the data on a rpeort every twenty second"
            },
            {
                "function_name": "main_drafter",
                "parameters": [
                    "request",
                    "slug"
                ],
                "content": "        \"\"\"This is the main view that handles all requests for the creation, edit, and compliance view of reports\n        It is permission based, meaning that only specific sections are shown to users given what role they have\n        \n        -It optionally takes in a slug as a variable on the url request\"\"\"\n    \n        \n        # Here i set the highest permision of the user in order to dysplay what they need to see. The\n        # logic behind this is that if an user is for some reason\n        # given more than one role, they may see the one of highest priority first\n        super_editor = False\n        current_year = datetime.today().year\n        \n        user_highest_permission = user_highest_permission_finder(request.user)\n        if user_highest_permission == 'Compliance Group':\n            levels_str = []\n            levels = request.user.groups.all()\n    \n            for level in levels:\n                levels_str.append(level.name)\n            # print(levels, user.groups.all())\n            if 'Editor Group' in levels_str:\n                super_editor = True\n        reports_to_edit = []\n        reports_to_approve = []\n        if user_highest_permission == \"Editor Group\":\n            query = Report.objects.filter(is_reviewing=True).values()\n            for report in query:\n                reports_to_edit.append(report)\n            \n        if user_highest_permission == \"Compliance Group\":\n            query = Report.objects.filter(is_compliance=True).values()\n            for report in query:\n                reports_to_approve.append(report)\n    \n    \n        ## This Part handles a url request where our slug is not empty, aka, someone clicked on the edit, compliance, or edit of a specific report\n        if slug != None:\n            reportedSlug = get_object_or_404(Report, slug=slug)\n            #If we are not receving information from a form But we have the slug of a report in our url, we enter here\n            if request.method != \"POST\":\n                # All of this section we just find the report and its attributes and we send it back to the template\n                report_drafts = Report.objects.filter(analyst=reportedSlug.analyst, is_draft=True).order_by('created').values() ##maybe later filter also by comments to upbring those who need revision\n                selected_company_past_reports = Report.objects.filter(company=reportedSlug.company).order_by('publish_date').values()\n                is_rollover = reportedSlug.company.is_rollover\n                if reportedSlug.company.is_rollover:\n                    current_year += 1\n                \n                ##prepop-content field\n                form = ReportDraftForm(initial={'content': reportedSlug.content})\n    \n                company_disclaimers = CompanyDisclaimer.objects.select_related('disclaimer').filter(company=reportedSlug.company)\n                disclaimer_ids = company_disclaimers.values_list('disclaimer_id', flat=True)\n                disclaimers = Disclaimer.objects.filter(id__in=disclaimer_ids)\n                metrics = CompanyMetric.objects.filter(company=reportedSlug.company, is_estimate=False)  \n                print('DELETE LATERRR with slug:', metrics)\n                other_analysts = reportedSlug.other_analysts.all()\n                sections = []\n                if user_highest_permission == \"Editor Group\":\n                    query = Section.objects.filter(report=reportedSlug).values()\n                    for section in query:\n                        sections.append(section)\n    \n                # report_metrics = ReportMetric.objects.filter(report=reportedSlug).order_by('updated', 'created', 'name', 'amount').values()\n    \n                current_year = datetime.now().year\n                relevant_years = {current_year - 1, current_year, current_year + 1}\n                from django.db.models import Case, When, Value, BooleanField\n                                                                                            #take this out to return to annotate behaviour\n                report_metrics = ReportMetric.objects.filter(report=reportedSlug, is_estimate=False).annotate(\n                    display_metric=Case(\n                        When(is_estimate=True, year_estimated__in=relevant_years, then=Value(True)),\n                        When(is_estimate=False, then=Value(True)),\n                        default=Value(False),\n                        output_field=BooleanField(),\n                    )\n                ).order_by('updated', 'created', 'name', 'amount').values()\n                send_back_comments = reportedSlug.comments\n    \n                \n                def get_color(value1, value2):\n                    if not value1 or not value2:\n                        return \"\"\n                    return \"bg-green-200/40\" if value1 == value2 else \"bg-red-200/50\"\n    \n                metrics_with_colors = []\n    \n    \n                # estimated_metrics = reportedSlug.report_id_CHANGETHIS.filter(is_estimate=True) ##ShouldbeCompanyMetrics\n                estimated_metrics = CompanyMetric.objects.filter(company=reportedSlug.company ,is_estimate=True)\n                metrics_by_name = {}\n    \n                for metric in estimated_metrics:\n                    if metric.name not in metrics_by_name:\n                        metrics_by_name[metric.name] = {\n                            'previous' : 0,\n                            'current': 0,\n                            'next': 0\n                        }\n    \n                    if metric.year_estimated == current_year - 1:\n                        metrics_by_name[metric.name]['previous'] = metric.amount\n                    elif metric.year_estimated == current_year:\n                        metrics_by_name[metric.name]['current'] = metric.amount\n                    elif metric.year_estimated == current_year + 1:\n                        metrics_by_name[metric.name]['next'] = metric.amount\n    \n                estimated_metrics = reportedSlug.report_id_CHANGETHIS.filter(is_estimate=True) ##ShouldbeCompanyMetrics\n                for name, data in metrics_by_name.items():\n                    for year_key, year in [('previous', current_year - 1), ('current', current_year), ('next', current_year + 1)]:\n                        if data[year_key] == 0:\n    \n                            ReportMetric.objects.create(\n                                report=reportedSlug,\n                                name=name,\n                                amount=0,\n                                year_estimated=year,\n                                is_estimate=True\n                            )\n                        \n    \n                ordered_metrics = estimated_metrics.order_by('name')\n    \n                em_list = list(ordered_metrics)\n    \n                grouped_estimates = [em_list[n:n+3] for n in range(0, len(em_list), 3)]\n                print(grouped_estimates)\n    \n                # for group in grouped_estimates: ##ONLY FOR PRINTING\n                #     for metric in group:\n                #         print(f\"Name: {metric.name}, Amount: {metric.amount}\")\n                #     print(\"---\")\n               \n                static_metrics = [\n                    'price', \n                    'potential_ror', \n                    'avg_3month_daily_vol', \n                    'shares_basic', \n                    'shares_FD', \n                    'marketcap_basic', \n                    'marketcap_FD', \n                    'revenue', \n                    'gross_profit'\n                ]\n                for metric_name in static_metrics:\n                    company_value = getattr(reportedSlug.company, metric_name, None)\n                    report_value = getattr(reportedSlug, metric_name, None)\n                    color = get_color(company_value, report_value)\n                    metrics_with_colors.append({\n                        'name': metric_name.replace('_', ' ').capitalize(),\n                        'value': company_value,\n                        'color': color\n                    })\n    \n                \n                for metric in CompanyMetric.objects.filter(company=reportedSlug.company, is_estimate=False):\n                    company_value = metric.amount\n                    report_metric = ReportMetric.objects.filter(report=reportedSlug, name=metric.name).first()\n                    report_value = report_metric.amount if report_metric else None\n                    color = get_color(company_value, report_value)\n                    metrics_with_colors.append({\n                        'name': metric.name,\n                        'value': company_value,\n                        'color': color\n                    })\n    \n    \n               \n    \n                print(\"BIG DEBUG: invest\", reportedSlug.company.investment_thesis)\n                is_ready_rollover = run_rollover_year(reportedSlug.company)\n                \n                context ={\n    \n                            'selected_company': reportedSlug.company,\n                            'profile': reportedSlug.analyst.profile,\n                            'analyst': reportedSlug.analyst,\n                            'report_drafts': report_drafts,\n                            'in_drafter': True,\n                            'selected_company_past_reports': selected_company_past_reports,\n                            'report_type': reportedSlug.type,\n                            'datetimeNow': reportedSlug.publish_date,\n                            'valid_request': True,\n                            'event': reportedSlug.event,\n                            'report_title': reportedSlug.title,\n                            'content': reportedSlug.content,\n                            'form': form,\n                            'recomendation': reportedSlug.rating,\n                            'target': reportedSlug.target,\n                            'disclaimers': disclaimers,\n                            'metrics': metrics,\n                            'report': reportedSlug,\n                            'other_analysts': other_analysts,\n                            'user_permission': user_highest_permission,\n                            'reports_to_edit': reports_to_edit,\n                            'sections': sections,\n                            'report_metrics': report_metrics,\n                            'send_back_comments': send_back_comments,\n                            'metrics_with_colors': metrics_with_colors,\n                            'reports_to_approve': reports_to_approve,\n                            'estimate_metrics': metrics_by_name,\n                            'grouped_estimates': grouped_estimates,\n                            'super_editor': super_editor,\n                            'is_ready_rollover': is_ready_rollover,\n                            'is_rollover': is_rollover\n                        }\n                \n                ### sector area\n    \n                companies = Company.objects.filter().values()\n                context['companies'] = companies\n    \n                existingSectorMetrics = []\n                sectorMetricsRating = SectorMetric.objects.filter(sectorReport=reportedSlug, name='Rating')\n                sectorMetricsTarget = SectorMetric.objects.filter(sectorReport=reportedSlug, name='Target')\n    \n                for rating in sectorMetricsRating:\n                    for target in sectorMetricsTarget:\n                        if rating.company.name == target.company.name:\n                            secDict = {\n                                'comp': rating.company.name,\n                                'rating': rating.amount,\n                                'target': target.amount\n                            }\n                            existingSectorMetrics.append(secDict)\n    \n                context['existingSectorMetrics'] = existingSectorMetrics\n                print(existingSectorMetrics)\n                ### sector area end\n    \n                return render(request, 'drafter_mainpage.html', context)\n        \n        ### IF we are not on an url that has a slug and we are not recieving data from a form, then we are on a report creation (and or standby) position\n        ## we can pull data related to the analyst/profile and display it\n    \n        companies = Company.objects.all() ## if at one point this query slows us down to much we can instead only cache load the ones related to the analyst and if the analyst tries to search for one outside of the companies they cover, only then do we load the rest of the companies\n        userUsername = request.user.username\n        profile = Profile.objects.filter(user__username=userUsername).first()\n        analyst = Analyst.objects.filter(profile=profile).first()\n    \n        report_drafts = Report.objects.filter(analyst=analyst, is_draft=True).order_by('created').values()\n        \n        # for report in report_drafts:\n        #     print(report['title'])\n        form = ReportDraftForm()\n    \n        \n    \n        draftSelect = Company()\n    \n        ## we send to template\n        context ={\n            'companies': companies,\n            'profile': profile,\n            'analyst': analyst,\n            'report_drafts': report_drafts,\n            'in_drafter': True,\n            'form': form,\n            'selected_company': draftSelect,\n            'user_permission': user_highest_permission,\n            'reports_to_edit': reports_to_edit,\n            'reports_to_approve': reports_to_approve,\n            'super_editor': super_editor\n        }\n    \n        ## This is the first POST request, if we are in an url with or without slug, and recieve a form, it automatically goes into this logic bracket. It just means\n        ## tat the user either finished creating a report, or updating it\n    \n        if request.method == \"POST\": \n            form = ReportDraftForm(request.POST)\n    \n            ## This part is more analyst based, if an analyst sends a form in the header area, the form will contain a header_form item, and we go in here\n            if request.POST.get('form_id') == 'header_form':\n                print(form.errors)\n                if form.is_valid():\n                    print(\"also valid... HEADER\")\n                    report_type = request.POST.get(\"report_type\")\n                    print(report_type)\n                    if report_type == \"\" or report_type == \" \":\n                        report_type = 'Research Note'\n                    selected_company_name = form.cleaned_data['company_name']\n                    selected_company_id_or_name = form.cleaned_data['company_name']\n    \n                    selected_company = None\n                    \n                    if selected_company_id_or_name.isdigit():\n                        \n                        selected_company = get_object_or_404(Company, id=selected_company_id_or_name)\n                    else:\n                        if companies.filter(ticker=selected_company_id_or_name.upper()).exists():\n                            selected_company = companies.filter(ticker=selected_company_id_or_name.upper()).first()\n                        elif companies.filter(name__icontains=selected_company_id_or_name).exists():\n                            selected_company = companies.filter(name__icontains=selected_company_id_or_name).first()\n                        else:\n                            return render(request, 'drafter_mainpage.html', context)\n                    print(selected_company.name)\n                    selected_ticker = selected_company_name.upper()\n                    \n                    datetimeNow = datetime.now().date()\n                   \n                    is_rollover = selected_company.is_rollover\n                    if selected_company.is_rollover:\n                        current_year += 1\n    \n                    selected_company_past_reports = Report.objects.filter(company=selected_company).order_by('publish_date').values()\n                    metrics = CompanyMetric.objects.filter(company=selected_company, is_estimate=False)  \n                    print('DELETE LATERRR:', metrics)\n    \n                    estimated_metrics = CompanyMetric.objects.filter(company=selected_company, is_estimate=True)\n                \n                    metrics_by_name = {}\n    \n                    for metric in estimated_metrics:\n                        if metric.name not in metrics_by_name:\n                            metrics_by_name[metric.name] = {\n                                'previous' : 0,\n                                'current': 0,\n                                'next': 0\n                            }\n    \n                        if metric.year_estimated == current_year - 1:\n                            metrics_by_name[metric.name]['previous'] = metric.amount\n                        elif metric.year_estimated == current_year:\n                            metrics_by_name[metric.name]['current'] = metric.amount\n                        elif metric.year_estimated == current_year + 1:\n                            metrics_by_name[metric.name]['next'] = metric.amount\n    \n                    ## All we did here is fetch the type of report or note we want to start CREATING and with which company is it associated to\n                    ## prepopulate fields with availible information \n    \n                    ##in analyst, if not opened yet, it opens the drafting body area with the is valid variable being true\n                    latestRecomendation = selected_company.recomendation\n                    latestTarget = selected_company.current_target\n                    is_ready_rollover = run_rollover_year(selected_company)\n                    \n                    context ={\n    \n                        'companies': companies,\n                        'profile': profile,\n                        'analyst': analyst,\n                        'report_drafts': report_drafts,\n                        'in_drafter': True,\n                        'selected_company': selected_company,\n                        'selected_company_past_reports': selected_company_past_reports,\n                        'report_type': report_type,\n                        'datetimeNow': datetimeNow,\n                        'valid_request': True,\n                        'form': form,\n                        'metrics': metrics,\n                        'user_permission': user_highest_permission,\n                        'reports_to_edit': reports_to_edit,\n                        'recomendation': latestRecomendation,\n                        'target': latestTarget,\n                        'estimate_metrics': metrics_by_name,\n                        'super_editor': super_editor,\n                        'is_ready_rollover': is_ready_rollover,\n                        'is_rollover': is_rollover,\n                    }\n    \n                    return render(request, 'drafter_mainpage.html', context)\n            elif request.POST.get('form_id') == 'body_form':\n                ## IF However, the form is being sent from the body of the analyst section, then this is run\n                # This is where the main saving proccess takes place for the editor place\n    \n                print(\"bodu\")\n                print(form.errors)\n                \n                if form.is_valid():\n                    \n                    ## we could also check for other indicators\n                    report_title = form.cleaned_data['report_title']\n                    \n                    draftedReport = None\n                    report_type = request.POST.get(\"report_type\")\n                    report_investment_thesis = request.POST.get(\"investment_thesis\")\n                    report_valuation = request.POST.get('valuation')\n    \n                    selected_company_name = form.cleaned_data['company_name']\n                    selected_ticker = selected_company_name.upper()\n                    selected_company = None\n                    \n                    if companies.filter(ticker=selected_ticker).exists():\n                        selected_company = companies.filter(ticker=selected_ticker).first()\n                        print(\"in\")\n                    elif companies.filter(name__icontains=selected_company_name).exists():\n                        selected_company = companies.filter(name__icontains=selected_company_name).first()\n                    else:\n                        return render(request, 'drafter_mainpage.html', context)\n                    \n                    if report_title == \"\" or report_title == None:\n                        draftedReport = Report()\n                        draftedReport.company = selected_company\n                        random_seed = random.randint(1000, 9999)\n                        draftedReport.title = f\"Default, report #{random_seed}\"\n                        if form.cleaned_data['analyst_full_name']:\n                            fullN = profile.first_name + \"\" + profile.last_name\n                            if fullN.lower() == form.cleaned_data['analyst_full_name']:\n                                draftedReport.analyst = analyst\n    \n                    elif Report.objects.filter(title__icontains=report_title).filter(is_draft=True).exists():\n                        draftedReport = Report.objects.filter(title__icontains=report_title).filter(is_draft=True).first()\n                    else:\n                        draftedReport = Report()\n                        draftedReport.company = selected_company\n                        if form.cleaned_data['analyst_full_name']:\n                            fullN = profile.first_name + \"\" + profile.last_name\n                            if fullN.lower() == form.cleaned_data['analyst_full_name']:\n                                draftedReport.analyst = analyst\n                        \n                    if form.cleaned_data['report_title']  != None and form.cleaned_data['report_title']  != \"\" and form.cleaned_data['report_title']  != 0:\n                        draftedReport.title = form.cleaned_data['report_title']\n                    if form.cleaned_data['report_type']  != None and form.cleaned_data['report_type']  != \"\" and form.cleaned_data['report_type']  != 0:\n                        draftedReport.type = form.cleaned_data['report_type']\n                    if form.cleaned_data['publish_date']  != None and form.cleaned_data['publish_date']  != \"\" and form.cleaned_data['publish_date']  != 0:\n                        date_parts = form.cleaned_data['publish_date'].split(',')\n                        if len(date_parts) >= 2:\n    \n                            month = date_parts[0].split(' ')\n                            print()\n                            month[0] = month[0][:3]\n    \n                            date = ' '.join(month) + ''.join(date_parts[1])\n                            draftedReport.publish_date = datetime.strptime(date.strip(), '%b %d %Y')\n                        \n                    # if form.cleaned_data['content']  != None and form.cleaned_data['content']  != \"\" and form.cleaned_data['content']  != 0:\n                    #     draftedReport.content = form.cleaned_data['content']\n                    draftedReport.content = request.POST.get(\"content\")\n                    # print(draftedReport.content)\n                    # print(form.cleaned_data['event'])  \n                    draftedReport.event = request.POST.get('eventEditor')\n                    if form.cleaned_data['event']  != None and form.cleaned_data['event']  != \"\" and form.cleaned_data['event']  != 0:\n                        draftedReport.event = form.cleaned_data['event']\n    \n                    if form.cleaned_data['recomendation'] != None and form.cleaned_data['recomendation'] != \"\" and form.cleaned_data['recomendation'] != 0:\n                        draftedReport.rating = form.cleaned_data['recomendation']\n    \n                    if form.cleaned_data['target'] != None and form.cleaned_data['target'] != \"\" and form.cleaned_data['target'] != 0:\n                        draftedReport.target = form.cleaned_data['target']\n                    # if form.cleaned_data['d']  != None or form.cleaned_data['d']  != \"\" or form.cleaned_data['d']  != 0:\n                    #     draftedReport.content = form.cleaned_data['d']\n    \n                    # if form.cleaned_data['takeout'] != None and form.cleaned_data['takeout'] != \"\" and form.cleaned_data['takeout'] != 0:\n                    #     draftedReport.takeout = form.cleaned_data['takeout']\n                    if request.POST.get(\"takeout\"):\n                        draftedReport.takeout = request.POST.get(\"takeout\")\n                    \n                    changedCounter = 0\n    \n                    if request.POST.get(\"price\"):\n                        draftedReport.price = request.POST.get(\"price\")\n                        changedCounter += 1\n                        print(draftedReport.price)\n                    if request.POST.get(\"potential_ror\"):\n                        draftedReport.potential_ror = request.POST.get(\"potential_ror\")\n                        changedCounter += 1\n                    if request.POST.get(\"avg_3month_daily_vol\"):\n                        draftedReport.avg_3month_daily_vol = request.POST.get(\"avg_3month_daily_vol\")\n                        changedCounter += 1\n                    if request.POST.get(\"shares_basic\"):\n                        draftedReport.shares_basic = request.POST.get(\"shares_basic\")\n                        changedCounter += 1\n                    if request.POST.get(\"shares_FD\"):\n                        draftedReport.shares_FD = request.POST.get(\"shares_FD\")\n                        changedCounter += 1\n                    if request.POST.get(\"marketcap_basic\"):\n                        draftedReport.marketcap_basic = request.POST.get(\"marketcap_basic\")\n                        changedCounter += 1\n                    if request.POST.get(\"marketcap_FD\"):\n                        draftedReport.marketcap_FD = request.POST.get(\"marketcap_FD\")\n                        changedCounter += 1\n                    if request.POST.get(\"revenue\"):\n                        draftedReport.revenue = request.POST.get(\"revenue\")\n                        changedCounter += 1\n                    if request.POST.get(\"gross_profit\"):\n                        draftedReport.gross_profit = request.POST.get(\"gross_profit\")\n                        changedCounter += 1\n    \n                    # print(changedCounter)\n                    \n                    \n                    is_rollover = selected_company.is_rollover\n                    if selected_company.is_rollover:\n                        current_year += 1\n    \n                    selected_company_past_reports = Report.objects.filter(company=selected_company).order_by('publish_date').values()\n                    try:\n                        if draftedReport.analyst == None: #########################      NEWWWWWW if this report has an analyst... then dont replace stuff, may break stuff so look here first \n                            draftedReport.analyst = analyst\n                    except:\n                        draftedReport.analyst = analyst\n                    sectorMetrics = []\n                    if draftedReport.type == 'Sector Note':\n                        print('saving Sector companies...')\n                        comp_names = request.POST.getlist('SectorName')\n                        comp_ratings = request.POST.getlist('SectorRating')\n                        comp_targets = request.POST.getlist('SectorTarget')\n    \n                        \n    \n                        for name, rating, target in zip(comp_names, comp_ratings, comp_targets):\n    \n                            sectorDict = {'comp': name, 'rating': rating, 'target': target}\n                            sectorMetrics.append(sectorDict)\n    \n                        draftedReport.save()   \n                        draftedReport.companies.clear()\n                        for sectorDic in sectorMetrics:\n                            \n                            SectorMetric.objects.update_or_create(sectorReport=draftedReport, company=get_object_or_404(Company, name__icontains=sectorDic['comp']) ,name='Rating', amount=sectorDic['rating'] ) \n                            SectorMetric.objects.update_or_create(sectorReport=draftedReport, company=get_object_or_404(Company, name__icontains=sectorDic['comp']) ,name='Target', amount=sectorDic['target'] ) \n                            \n                            draftedReport.companies.add(get_object_or_404(Company, name__icontains=sectorDic['comp']))\n                    draftedReport.save()\n                    if draftedReport.other_analysts.count() == 0:\n                        print('No other anlaysts... adding them now')\n                        relatedAnalysts = Analyst.objects.filter(sector__icontains=draftedReport.analyst.sector).exclude(id=draftedReport.analyst.id)\n                        for other in relatedAnalysts:\n                            draftedReport.other_analysts.add(other)\n                            print('added other..')\n                    if request.POST.get('analyst_send_to_edit'):\n                        draftedReport.is_draft = False\n                        draftedReport.is_reviewing = True\n                        \n                        draftedReport.save()\n                        try:   \n                            reportLog: GeneralLog = GeneralLog.objects.create(report=draftedReport, by_whom=get_object_or_404(Profile, user=request.user))\n                            reportLog.moved_to_edit()\n                        except:\n                                print('error logging')\n                        return redirect('report_selector')\n                    \n                    \n                    draftedReport.save()\n                    draftedReport.report_investment_thesis = report_investment_thesis\n                    draftedReport.valuation = report_valuation\n                    for key, values in request.POST.lists():\n                        if ReportMetric.objects.filter(report=draftedReport, name=key).exists():\n                            for i, value in enumerate(values):\n                                try:\n                                    year = current_year - 1 + i  # -1 for previous, 0 for current, +1 for next year\n                                    report_metric = ReportMetric.objects.get(\n                                        report=draftedReport, \n                                        name=key, \n                                        year_estimated=year\n                                    )\n                                    \n                                    if report_metric.is_estimate:\n                                        print('saving', report_metric.name, report_metric.amount)\n                                        report_metric.amount = value\n                                        report_metric.save()\n                                \n                                except ReportMetric.DoesNotExist:\n                                    print(f\"ReportMetric with name '{key}' and year {year} not found or not an estimate.\")\n                    print('#################Debuging###################')\n                    for key, value in request.POST.items(): ##Already created and pubbed\n                        \n                        if CompanyMetric.objects.filter(name=key).exists():\n                            metric_name = key\n                            metric_amount = value\n                            report_metric, created = ReportMetric.objects.get_or_create(\n                                report=draftedReport,\n                                name=metric_name,\n                                defaults={\"amount\": metric_amount}\n                            )\n                            # print(key)\n                            # print(metric_amount)\n                            # print(\"inside\")\n                            if not created:\n                                report_metric.amount = metric_amount\n                                report_metric.save()\n    \n                    for key, value in request.POST.items(): ##Already created and pubbed\n                        \n                        if ReportMetric.objects.filter(name=key).exists():\n                            try:\n                                metric_name = key\n                                metric_amount = value\n                                report_metric, created = ReportMetric.objects.get_or_create(\n                                    report=draftedReport,\n                                    name=metric_name,\n                                    defaults={\"amount\": metric_amount}\n                                )\n                                # print(key)\n                                # print(metric_amount)\n                                # print(\"inside\")\n                                if not created:\n                                    report_metric.amount = metric_amount\n                                    report_metric.save()\n                            except:\n                                pass\n    \n                    print('#################Debuging###################')\n    \n                    length = len(request.POST.getlist('Metric NameName'))\n    \n                    # Loop through both lists\n                    for i in range(length):\n                        metric_name = request.POST.getlist('Metric NameName')[i]\n                        metric_amount = request.POST.getlist('Metric NameAmount')[i]\n    \n                        report_metric, created = ReportMetric.objects.get_or_create(\n                                report=draftedReport,\n                                name=metric_name,\n                                defaults={\"amount\": metric_amount}\n                            )\n                        print('out')\n                        if not created:\n                                print('should be here')\n                                report_metric.amount = metric_amount\n                                report_metric.save()\n                    \n                    ##saving the metrics on the form\n                    grouped_data = {}\n                    for key, value in request.POST.items():\n                        \n                        if key.startswith(\"tosave\"):  \n                            \n                            metric_name, year_estimated = key.rsplit('_', 1)  \n                            metric_name = metric_name.replace(\"tosave\", \"\")  \n                            print('debug special', metric_name, year_estimated)\n                            \n                            year_estimated = int(year_estimated)\n                            \n                            amount = float(value)\n                            \n                            saveMet = ReportMetric.objects.filter(report=draftedReport, name=metric_name, year_estimated=year_estimated, is_estimate=True).first()\n                            saveMet.amount = amount\n                            saveMet.save()\n                            \n    \n                            if metric_name not in grouped_data:\n                                grouped_data[metric_name] = []\n                            grouped_data[metric_name].append({\n                                'year_estimated': year_estimated,\n                                'amount': amount\n                            })\n                    \n                    ### saving metrics in form\n    \n                    ##saving the newly created ones\n                    new_metric_names = request.POST.getlist('newMetricName[]')\n                    new_metric_last_years = request.POST.getlist('newMetricLastYear[]')\n                    new_metric_this_years = request.POST.getlist('newMetricThisYear[]')\n                    new_metric_next_years = request.POST.getlist('newMetricNextYear[]')\n    \n                    for i in range(len(new_metric_names)):\n                        metric_name = new_metric_names[i]\n    \n                        # Last Year\n                        ReportMetric.objects.update_or_create(\n                            report=draftedReport,\n                            name=metric_name,\n                            year_estimated=current_year - 1,\n                            defaults={'amount': new_metric_last_years[i], 'is_estimate': True}\n                        )\n    \n                        # This Year\n                        ReportMetric.objects.update_or_create(\n                            report=draftedReport,\n                            name=metric_name,\n                            year_estimated=current_year,\n                            defaults={'amount': new_metric_this_years[i], 'is_estimate': True}\n                        )\n    \n                        # Next Year\n                        ReportMetric.objects.update_or_create(\n                            report=draftedReport,\n                            name=metric_name,\n                            year_estimated=current_year + 1,\n                            defaults={'amount': new_metric_next_years[i], 'is_estimate': True}\n                        )\n                    ##saving the newly created ones\n                    draftedReport.save()\n    \n                    if request.POST.get('delete_draft'):\n                        print(\"IN\")\n                        try:\n                            reportLog: GeneralLog = GeneralLog.objects.create(report=report, by_whom=get_object_or_404(Profile, user=request.user))\n                            reportLog.deleted_draft()\n                        except:\n                            print('error logging')\n                        draftedReport.delete()\n    \n                    company_disclaimers = CompanyDisclaimer.objects.select_related('disclaimer').filter(company=draftedReport.company)\n                    disclaimer_ids = company_disclaimers.values_list('disclaimer_id', flat=True)\n                    disclaimers = Disclaimer.objects.filter(id__in=disclaimer_ids)\n                    \n                    metrics = CompanyMetric.objects.filter(company=draftedReport.company) \n    \n                    if request.POST.get('save_report'):\n                        draftedReport.save()\n                        return redirect('drafter', slug=draftedReport.slug)\n                    \n                    is_ready_rollover = run_rollover_year(selected_company)\n                    \n                    context ={\n    \n                        'companies': companies,\n                        'profile': profile,\n                        'analyst': analyst,\n                        'report_drafts': report_drafts,\n                        'in_drafter': True,\n                        'selected_company': selected_company,\n                        'selected_company_past_reports': selected_company_past_reports,\n                        'report_type': report_type,\n                        'datetimeNow': datetime.now().date,\n                        'valid_request': True,\n                        'metrics': metrics,\n                        'disclaimers': disclaimers,\n                        'user_permission': user_highest_permission,\n                        'reports_to_edit': reports_to_edit,\n                        'super_editor': super_editor,\n                        'is_ready_rollover': is_ready_rollover,\n                        'is_rollover': is_rollover,\n                    }\n    \n                return render(request, 'drafter_mainpage.html', context)\n            elif request.POST.get('form_id') == 'metrics_id': ##my old way of saving and creating metrics can be deleted super safely\n                report_title = request.POST.get('title_copy')\n    \n                try:\n                    reportM = get_object_or_404(Report, title__icontains=report_title)\n                except:\n                    return render(request, 'drafter_mainpage.html', context)\n                    \n                print('TITLE: ', report_title)\n                print('debug special')\n                new_metric_names = request.POST.getlist('newMetricName[]')\n                new_metric_last_years = request.POST.getlist('newMetricLastYear[]')\n                new_metric_this_years = request.POST.getlist('newMetricThisYear[]')\n                new_metric_next_years = request.POST.getlist('newMetricNextYear[]')\n    \n                for i in range(len(new_metric_names)):\n                    metric_name = new_metric_names[i]\n    \n                    # Last Year\n                    ReportMetric.objects.update_or_create(\n                        report=reportM,\n                        name=metric_name,\n                        year_estimated=current_year - 1,\n                        defaults={'amount': new_metric_last_years[i], 'is_estimate': True}\n                    )\n    \n                    # This Year\n                    ReportMetric.objects.update_or_create(\n                        report=reportM,\n                        name=metric_name,\n                        year_estimated=current_year,\n                        defaults={'amount': new_metric_this_years[i], 'is_estimate': True}\n                    )\n    \n                    # Next Year\n                    ReportMetric.objects.update_or_create(\n                        report=reportM,\n                        name=metric_name,\n                        year_estimated=current_year + 1,\n                        defaults={'amount': new_metric_next_years[i], 'is_estimate': True}\n                    )\n    \n                print('debug special') \n                context['metricSlug'] = reportM\n            elif request.POST.get('form_id') == 'editor_form':\n                ## This is from where the editor form will be read and saved\n                print('Editor')\n    \n                ## Should never be none\n                if slug != None:\n                    \n                    if form.is_valid():\n    \n                        changesMade = \"\"\"\\n------------------------------------------------------ \\n\"\"\"\n                        changes_dict = {}\n                        mainReport = Report.objects.get(slug=slug)\n    \n                        fields = [\n                            ('mainEditorFirstName', mainReport.analyst.profile.first_name, request.POST.get('mainEditorFirstName')),\n                            ('mainEditorLastName', mainReport.analyst.profile.last_name, request.POST.get('mainEditorLastName')),\n                            ('recomendation', mainReport.rating, request.POST.get(\"recomendation\")),\n                            ('target', mainReport.target, request.POST.get(\"target\")),\n                            ('price', mainReport.price, request.POST.get(\"price\")),\n                            ('potential_ror', mainReport.potential_ror, request.POST.get(\"potential_ror\")),\n                            ('avg_3month_daily_vol', mainReport.avg_3month_daily_vol, request.POST.get(\"avg_3month_daily_vol\")),\n                            ('shares_basic', mainReport.shares_basic, request.POST.get(\"shares_basic\")),\n                            ('shares_FD', mainReport.shares_FD, request.POST.get(\"shares_FD\")),\n                            ('marketcap_basic', mainReport.marketcap_basic, request.POST.get(\"marketcap_basic\")),\n                            ('marketcap_FD', mainReport.marketcap_FD, request.POST.get(\"marketcap_FD\")),\n                            ('revenue', mainReport.revenue, request.POST.get(\"revenue\")),\n                            ('gross_profit', mainReport.gross_profit, request.POST.get(\"gross_profit\")),\n                            ('takeawayEditor', mainReport.takeout, request.POST.get(\"takeawayEditor\")),\n                            ('eventEditor', mainReport.event, request.POST.get('eventEditor')),\n                            ('content', mainReport.content, request.POST.get('content')),\n                            ('valuationEditor', mainReport.valuation, request.POST.get('valuationEditor'))\n                        ]\n    \n    \n                        print(f\"old: {mainReport.price}-------- new: {request.POST.get('price')}\")\n                        for field_name, old_value, new_value in fields:\n                            changes = listDiffNEW(str(old_value), str(new_value))\n                            changes_list = json.loads(changes)  # Deserialize to a Python list\n                            if changes_list:  # Check if the list is non-empty\n                                changes_dict[field_name] = changes_list  # Add to changes_dict only if non-empty\n    \n                        changes_json = json.dumps(changes_dict)\n                        changesMade += f\"{changes_json}\"\n                        \n                        print(changesMade)\n                        mainReport.analyst.profile.first_name =  request.POST.get('mainEditorFirstName')\n                        mainReport.analyst.profile.last_name = request.POST.get('mainEditorLastName')\n                        mainReport.rating = request.POST.get(\"recomendation\")\n                        def convert_to_float(value):\n                            final = None\n                            try:\n                                \n                                final = float(value)\n                            except:\n                                final = None\n                            return final\n    \n                        mainReport.target = convert_to_float(request.POST.get(\"target\"))\n                        mainReport.price = convert_to_float(request.POST.get(\"price\"))\n                        mainReport.potential_ror = convert_to_float(request.POST.get(\"potential_ror\"))\n                        mainReport.avg_3month_daily_vol = convert_to_float(request.POST.get(\"avg_3month_daily_vol\"))\n                        mainReport.shares_basic = convert_to_float(request.POST.get(\"shares_basic\"))\n                        mainReport.shares_FD = convert_to_float(request.POST.get(\"shares_FD\"))\n                        mainReport.marketcap_basic = convert_to_float(request.POST.get(\"marketcap_basic\"))\n                        mainReport.marketcap_FD = convert_to_float(request.POST.get(\"marketcap_FD\"))\n                        mainReport.revenue = convert_to_float(request.POST.get(\"revenue\"))\n                        mainReport.gross_profit = convert_to_float(request.POST.get(\"gross_profit\"))\n    \n                        mainReport.takeout = request.POST.get(\"takeawayEditor\")\n                        mainReport.valuation = request.POST.get(\"valuationEditor\")\n                        mainReport.event = request.POST.get('eventEditor')\n                        mainReport.content = request.POST.get('content')\n    \n                        mainReport.comments = request.POST.get('sendBackComments')\n    \n    \n    \n                        ################### DANGERUS NOT SURE\n                        for key, value in request.POST.items(): ##Already created and pubbed\n                            \n                            if CompanyMetric.objects.filter(name=key).exists():\n                                metric_name = key\n                                metric_amount = value\n                                report_metric, created = ReportMetric.objects.get_or_create(\n                                    report=mainReport,\n                                    name=metric_name,\n                                    defaults={\"amount\": metric_amount}\n                                )\n                                # print(key)\n                                # print(metric_amount)\n                                # print(\"inside\")\n                                if not created:\n                                    report_metric.amount = metric_amount\n                                    report_metric.save()\n    \n                        for key, value in request.POST.items(): ##Already created and pubbed\n                            \n                            if ReportMetric.objects.filter(name=key).exists():\n                                try:\n                                    metric_name = key\n                                    metric_amount = value\n                                    report_metric, created = ReportMetric.objects.get_or_create(\n                                        report=mainReport,\n                                        name=metric_name,\n                                        defaults={\"amount\": metric_amount}\n                                    )\n                                    # print(key)\n                                    # print(metric_amount)\n                                    # print(\"inside\")\n                                    if not created:\n                                        report_metric.amount = metric_amount\n                                        report_metric.save()\n                                except:\n                                    pass\n                        ################### DANGERUS NOT SURE\n                        ##saving the metrics on the form\n                        grouped_data = {}\n                        for key, value in request.POST.items():\n                            \n                            if key.startswith(\"tosave\"):  \n                                \n                                metric_name, year_estimated = key.rsplit('_', 1)  \n                                metric_name = metric_name.replace(\"tosave\", \"\")  \n                                print('debug special', metric_name, year_estimated)\n                                \n                                year_estimated = int(year_estimated)\n                                \n                                amount = float(value)\n                                \n                                saveMet = ReportMetric.objects.filter(report=mainReport, name=metric_name, year_estimated=year_estimated, is_estimate=True).first()\n                                saveMet.amount = amount\n                                saveMet.save()\n                                \n    \n                                if metric_name not in grouped_data:\n                                    grouped_data[metric_name] = []\n                                grouped_data[metric_name].append({\n                                    'year_estimated': year_estimated,\n                                    'amount': amount\n                                })\n                        \n                        if request.POST.get('save_report'):\n                            mainReport.save()\n                            return redirect('drafter', slug=mainReport.slug)\n    \n                        if request.POST.get(\"sendBackToAnalyst\"):\n    \n                            # print(\"CAREFUL IN\")\n                            try:\n                                reportLog: GeneralLog = GeneralLog.objects.create(report=mainReport, by_whom=get_object_or_404(Profile, user=request.user))\n                                reportLog.sent_back_to_analyst()\n                            except:\n                                print('error logging')\n                            mainReport.is_reviewing = False\n                            mainReport.is_draft = True\n    \n                             #removes old changes\n                            if '--------------------------------------------------' in mainReport.comments:\n                                mainReport.comments = mainReport.comments[:mainReport.comments.index('--------------------------------------------------')-1]\n    \n                            mainReport.comments += changesMade\n    \n                            mainReport.save()\n                            return redirect('report_selector')\n    \n                        \n                        elif request.POST.get(\"sendToCompliance\"):\n                            print('send to compliance')\n                            try:\n                                reportLog: GeneralLog = GeneralLog.objects.create(report=mainReport, by_whom=get_object_or_404(Profile, user=request.user))\n                                reportLog.moved_to_compliance()\n                            except:\n                                print('error logging')\n                            mainReport.is_reviewing = False\n                            mainReport.is_compliance = True\n                            mainReport.save()\n                            return redirect('report_selector')\n    \n                        mainReport.save()\n            elif request.POST.get('form_id') == 'compliance_form':\n                print('Compliance')\n    \n                ## Should never be none\n                if slug != None:\n                    mainReport = Report.objects.get(slug=slug)\n                    if request.POST.get(\"sendBackToEditor\"):\n                        try:\n                            reportLog: GeneralLog = GeneralLog.objects.create(report=mainReport, by_whom=get_object_or_404(Profile, user=request.user))\n                            reportLog.sent_back_to_editor()\n                        except:\n                                print('error logging')\n                        mainReport.is_compliance = False\n                        mainReport.is_reviewing = True\n                        send_notification_to('editor')\n                    elif request.POST.get(\"sendToPublishing\"):\n                        try:\n                            reportLog: GeneralLog = GeneralLog.objects.create(report=mainReport, by_whom=get_object_or_404(Profile, user=request.user))\n                            reportLog.approved_to_publish()\n                        except:\n                                print('error logging')\n                        mainReport.is_compliance = False\n                        mainReport.is_published = True\n                        mainReport.save()\n                        put_report_to_publish(mainReport)\n                        return render(request, 'tempUploadPage.html', {'report': mainReport})\n                        # we could also do mainReport.comments = None or \"\" if we need to save space\n                    mainReport.save()\n    \n                        \n    \n    \n    \n    \n    \n        \n        ## Here is the render if we are not in a post request\n        \n        return render(request, 'drafter_mainpage.html', context)",
                "documentation": "this is the most IMPORTANT view on the project as it is the main drafting engine, this view works for all of the users and it lets then edit, draft, or comply reports alike, it features an intircate logic system and refer to inline comments for guidance of when and where things are ran"
            },
            {
                "function_name": "ticker",
                "parameters": [
                    "request",
                    "slug"
                ],
                "content": "    \n        company = get_object_or_404(Company,slug=slug)\n    \n        latest_reports = Report.objects.filter(company=company)\n    \n        context = {\n            \"company\": company,\n            \"latest_reports\": latest_reports\n        }\n    \n        return render(request, \"ticker_page.html\", context)",
                "documentation": "deprecated"
            },
            {
                "function_name": "profile",
                "parameters": [
                    "request"
                ],
                "content": "    \n        profile = get_object_or_404(Profile, user=request.user)\n        permission = user_highest_permission_finder(request.user)\n        is_anal = Analyst.objects.filter(profile=profile).exists()\n    \n        apiKeys = MagicLinkToken.objects.filter(is_api_token=True, user=request.user)\n        context = {\n            \"profile\": profile,\n            \"permission\": permission,\n            \"is_anal\": is_anal,\n            'apiKeys': apiKeys\n        }\n        \n        if request.POST:\n            selected_value = request.POST.get('group_selector')\n            generate = request.POST.get('generateKey', '')\n            if generate == 'generate':\n                token = secrets.token_urlsafe(20)\n                try:\n                    MagicLinkToken.objects.create(user=profile.user, token=token, is_api_token=True)\n                except:\n                    pass\n            user = request.user\n            if selected_value == \"Analyst Group\":\n                group = Group.objects.get(name=\"Analyst Group\")\n                user.groups.clear()\n                user.groups.add(group)\n            elif selected_value == \"Editor Group\":\n                group = Group.objects.get(name=\"Editor Group\")\n                user.groups.clear()\n                user.groups.add(group)\n            elif selected_value == \"Compliance Group\":\n                group = Group.objects.get(name=\"Compliance Group\")\n                user.groups.clear()\n                user.groups.add(group)\n            elif selected_value == \"Head Group\":\n                group = Group.objects.get(name=\"Head Group\")\n                user.groups.clear()\n                user.groups.add(group)\n            elif selected_value == \"Super Editor Group\":\n                group1 = Group.objects.get(name=\"Compliance Group\")\n                group2 = Group.objects.get(name=\"Editor Group\")\n                user.groups.clear()\n                user.groups.add(group1)\n                user.groups.add(group2)\n        \n        if request.session.get(\"hasBeenReset\") == \"True\":\n            request.session[\"hasBeenReset\"] = \"False\"\n            \n        else:\n            request.session[\"message\"] = \"False\"\n            \n        return render(request, 'profile.html', context)",
                "documentation": "the profile view, it is in charge of generating the api tokens for excel analyst and some settings for admins as well as contact info for anyone and change password section"
            },
            {
                "function_name": "signup_confirm",
                "parameters": [
                    "request"
                ],
                "content": "        context = {\n            'hide_search': True\n        }\n        return render(request, 'signup_confirm.html', context)",
                "documentation": "singup view"
            },
            {
                "function_name": "signup",
                "parameters": [
                    "request"
                ],
                "content": "        success = False\n        if request.method == 'POST':\n            form = SignupForm(request.POST)\n    \n            if form.is_valid():\n                signup_email = form.cleaned_data['email']\n                subject = 'New Signup Requested'\n                message = f'A Signup has been requested by {signup_email}.\\n\\nVisit: https://research.paradigmcap.com/myadmin' \n                from_email = 'Paradigm Research <myamani@paradigmcap.com>'\n                recipient_list = ['shawndavison5@gmail.com','apolo@paradigmcap.com']\n    \n                send_mail(subject, message, from_email, recipient_list)\n    \n                form.save()\n                success = True\n                return redirect('signup_confirm')\n        else:\n            form = SignupForm()\n    \n        context = {\n            'form': form,\n            'success': success,\n            'hide_search': True\n        }\n    \n        return render(request, 'signup.html', context)",
                "documentation": "singup view as well"
            },
            {
                "function_name": "search_results",
                "parameters": [
                    "request",
                    "watchlist"
                ],
                "content": "        total_start_time = time.time()\n        \n        q = watchlist if watchlist else request.GET.get(\"q\", '')\n        publish_date_start = request.GET.get('publishDateStart', None)\n        publish_date_end = request.GET.get('publishDateEnd', None)\n        selected_company_ticker = request.GET.get('company_ticker', None)\n        selected_analyst = request.GET.get('analyst', None)\n        selected_type = request.GET.get('type', None)\n        sort = request.GET.get('sort', None)\n        direction = request.GET.get('direction', 'asc')\n        page_number = request.GET.get('page', 1)\n    \n        if not q:\n            results = Report.objects.filter(is_published=True, company__coverage=True).select_related('company','analyst').only('title', 'company__name', 'analyst', 'publish_date','type')\n        else:\n            registered_words = ['technical', 'diversified', 'technology', 'healthcare', 'industrial', 'metals', 'gold', 'energy', 'mining']\n            if q.lower() in registered_words:\n                if q.lower() == 'gold':\n                    results = Report.objects.filter(is_published=True, company__coverage=True).filter(\n                        Q(report_group__industry__icontains='Precious Metal') | Q(report_group__name__icontains='Precious Metal') | Q(report_group__name__icontains='gold') | Q(report_group__industry__icontains='gold')\n                    ).select_related('company','analyst').only('title', 'company__name', 'analyst', 'publish_date','type')\n                else:\n                    results = Report.objects.filter(is_published=True, company__coverage=True).filter(\n                        Q(report_group__industry__icontains=q) | Q(report_group__name__icontains=q)\n                    ).select_related('company','analyst').only('title', 'company__name', 'analyst', 'publish_date','type')\n            else:\n                results = Report.objects.filter(is_published=True, company__coverage=True).filter(\n                    Q(title__icontains=q) | Q(company__name__icontains=q) |\n                    Q(company__ticker__icontains=q) | Q(report_group__name__icontains=q) |\n                    Q(report_group__industry__icontains=q) | Q(analyst__profile__first_name__icontains=q) |\n                    Q(analyst__profile__last_name__icontains=q) | Q(company__industry__icontains=q) \n                ).select_related('company','analyst').only('title', 'company__name', 'analyst', 'publish_date','type')       #defer('content', 'comments','event')  #|Q(event__icontains=q) | Q(content__icontains=q)\n            words = q.split()\n            if len(words) == 2:\n                results = Report.objects.filter(is_published=True, company__coverage=True).filter(\n                    Q(analyst__profile__first_name__in=words[0]) | Q(analyst__profile__last_name__icontains=words[1]) |\n                    Q(analyst__profile__first_name__icontains=words[1]) | Q(analyst__profile__last_name__icontains=words[0])\n                ).select_related('company','analyst').only('title', 'company__name', 'analyst', 'publish_date','type')\n    \n                if not results:\n                    print('In')\n                    results = Report.objects.filter(is_published=True, company__coverage=True).filter(\n                    Q(title__icontains=q) | Q(company__name__icontains=q) |\n                    Q(company__ticker__icontains=q) | Q(report_group__name__icontains=q) |\n                    Q(report_group__industry__icontains=q) | Q(analyst__profile__first_name__icontains=q) |\n                    Q(analyst__profile__last_name__icontains=q) | Q(company__industry__icontains=q) \n                ).select_related('company','analyst').only('title', 'company__name', 'analyst', 'publish_date','type')   #.defer('content', 'comments','event')   #|Q(event__icontains=q) | Q(content__icontains=q)\n    \n        if selected_company_ticker:\n            results = results.filter(company__ticker=selected_company_ticker)\n        if selected_analyst:\n            results = results.filter(analyst__profile__email=selected_analyst)\n        if publish_date_start and publish_date_start != \"None\":\n            results = results.filter(publish_date__gte=publish_date_start)\n        if publish_date_end and publish_date_end != \"None\":\n            results = results.filter(publish_date__lte=publish_date_end)\n        if selected_type:\n            results = results.filter(type=selected_type)\n    \n        if sort:\n            if sort in ['date_year', 'date_month', 'date_day']:\n                if sort == 'date_year':\n                    results = results.annotate(sort_field=ExtractYear('publish_date'))\n                elif sort == 'date_month':\n                    results = results.annotate(sort_field=ExtractMonth('publish_date'))\n                elif sort == 'date_day':\n                    results = results.annotate(sort_field=ExtractDay('publish_date'))\n                results = results.order_by(F('sort_field').desc(nulls_last=True) if direction == 'desc' else 'sort_field')\n            else:\n                # order_field = '-' + sort if direction == 'desc' else sort\n                # results = results.order_by(order_field)\n                sort_mapping = {\n                    'company_name': 'company__name',\n                    'company_ticker': 'company__ticker',\n                    'company_industry': 'company__industry',\n                    'analyst_first_name': 'analyst__profile__first_name',\n                    'analyst_last_name': 'analyst__profile__last_name',\n                }\n                order_field = sort_mapping.get(sort, sort)\n                order_field = f'-{order_field}' if direction == 'desc' else order_field\n                results = results.order_by(order_field)\n    \n        \n        paginator = Paginator(results, 10)\n        try:\n            results_page = paginator.page(page_number)\n        except PageNotAnInteger:\n            results_page = paginator.page(1)\n        except EmptyPage:\n            results_page = paginator.page(paginator.num_pages)\n    \n        \n        \n    \n        analysts_data = set((report.analyst.profile.email, report.analyst.profile.first_name, report.analyst.profile.last_name) for report in results_page)\n        companies_from_results = set(report.company for report in results_page)\n    \n        \n    \n        context = {\n            \"results\": results_page,\n            \"q\": q,\n            \"publishDateStart\": publish_date_start if publish_date_start != \"None\" else \"\",\n            \"publishDateEnd\": publish_date_end if publish_date_end != \"None\" else \"\",\n            'analysts': analysts_data,\n            'selected_analyst': selected_analyst,\n            'companies': companies_from_results,\n            'selected_company_ticker': selected_company_ticker,\n            'results_count': paginator.count,\n            'sort': sort,\n            'direction': direction,\n            'current_page': page_number\n        }\n    \n        \n        total_time = time.time() - total_start_time\n        print(\"Total time to run the function: \", total_time)\n    \n        # Append the time to a CSV file\n        with open('times.csv', 'a', newline='') as file:\n            writer = csv.writer(file)\n            writer.writerow([total_time])\n        return render(request, 'search_results.html', context)",
                "documentation": "this is the true search results view and it will search for every report and company but it will not look into the takeout wevent or content due to the slowness features on the website, it will do the queries and process them and return them to the user"
            },
            {
                "function_name": "search_results9",
                "parameters": [
                    "request",
                    "watchlist"
                ],
                "content": "        cache_key = 'all_reports_base_query'\n        cache_time = 1800  # 30 minutes\n    \n        cached_reports = cache.get(cache_key)\n        if not cached_reports:\n            cached_reports = list(Report.objects.filter(is_published=True).all())\n            cache.set(cache_key, cached_reports, cache_time)\n    \n        q = watchlist if watchlist else request.GET.get(\"q\", '').lower()\n        publish_date_start = request.GET.get('publishDateStart', None)\n        publish_date_end = request.GET.get('publishDateEnd', None)\n        selected_company_ticker = request.GET.get('company_ticker', None)\n        selected_analyst = request.GET.get('analyst', None)\n        sort = request.GET.get('sort', None)\n        direction = request.GET.get('direction', 'asc')\n        page_number = request.GET.get('page', 1)\n    \n        lowercased_q = q.lower()\n        is_registered_word = lowercased_q in ['technical', 'diversified', 'technology', 'healthcare', 'industrial', 'metals', 'gold', 'energy', 'mining']\n    \n        def safe_lower(obj, attr):\n            value = getattr(obj, attr, None)\n            return value.lower() if value else ''\n    \n        def report_matches(report):\n            if is_registered_word:\n                if report.report_group:\n                    return lowercased_q in safe_lower(report.report_group, 'industry') or lowercased_q in safe_lower(report.report_group, 'name')\n            else:\n                if lowercased_q in safe_lower(report, 'title'):\n                    return True\n                if report.company:\n                    if lowercased_q in safe_lower(report.company, 'name') or lowercased_q in safe_lower(report.company, 'ticker') or lowercased_q in safe_lower(report.company, 'industry'):\n                        return True\n                if report.analyst and report.analyst.profile:\n                    if lowercased_q in safe_lower(report.analyst.profile, 'first_name') or lowercased_q in safe_lower(report.analyst.profile, 'last_name'):\n                        return True\n                if lowercased_q in safe_lower(report, 'event') or lowercased_q in safe_lower(report, 'content'):\n                    return True\n            return False\n    \n        filtered_reports = (report for report in cached_reports if report_matches(report))\n    \n        if publish_date_start and publish_date_start != \"None\":\n            filtered_reports = (report for report in filtered_reports if report.publish_date and report.publish_date.date() >= datetime.strptime(publish_date_start, '%Y-%m-%d').date())\n        if publish_date_end and publish_date_end != \"None\":\n            filtered_reports = (report for report in filtered_reports if report.publish_date and report.publish_date.date() <= datetime.strptime(publish_date_end, '%Y-%m-%d').date())\n        if selected_company_ticker:\n            filtered_reports = (report for report in filtered_reports if report.company.ticker == selected_company_ticker)\n        if selected_analyst:\n            filtered_reports = (report for report in filtered_reports if report.analyst.profile.email == selected_analyst)\n    \n        sort_fields = {\n            'date_year': lambda x: x.publish_date.year if x.publish_date else None,\n            'date_month': lambda x: x.publish_date.month if x.publish_date else None,\n            'date_day': lambda x: x.publish_date.day if x.publish_date else None,\n            'company_name': lambda x: x.company.name.lower() if x.company.name else '',\n            'company_ticker': lambda x: x.company.ticker.lower() if x.company.ticker else '',\n            'company_industry': lambda x: x.company.industry.lower() if x.company.industry else '',\n            'analyst_first_name': lambda x: x.analyst.profile.first_name.lower() if x.analyst.profile.first_name else '',\n            'analyst_last_name': lambda x: x.analyst.profile.last_name.lower() if x.analyst.profile.last_name else ''\n        }\n        if sort in sort_fields:\n            filtered_reports = sorted(filtered_reports, key=sort_fields[sort], reverse=(direction == 'desc'))\n    \n        paginator = Paginator(list(filtered_reports), 10)  # 10 reports per page\n        page_obj = paginator.get_page(page_number)\n    \n        analysts_data = set((report.analyst.profile.email, report.analyst.profile.first_name, report.analyst.profile.last_name) for report in page_obj)\n        companies_from_results = set(report.company for report in page_obj)\n        context = {\n            \"results\": page_obj,\n            \"q\": q,\n            \"publishDateStart\": publish_date_start if publish_date_start != \"None\" else \"\",\n            \"publishDateEnd\": publish_date_end if publish_date_end != \"None\" else \"\",\n            'analysts': analysts_data,\n            'selected_analyst': selected_analyst,\n            'companies': companies_from_results,\n            'selected_company_ticker': selected_company_ticker,\n            'results_count': paginator.count,\n            'sort': sort,\n            'direction': direction,\n            'current_page': page_number\n        }\n    \n        return render(request, 'search_results.html', context)"
            },
            {
                "function_name": "search_results4",
                "parameters": [
                    "request",
                    "watchlist"
                ],
                "content": "        cache_key = 'all_reports_base_query'\n        cache_time = 1800  # 30 minutes\n    \n        cached_reports = cache.get(cache_key)\n        if not cached_reports:\n            cached_reports = list(Report.objects.filter(is_published=True).all())\n            cache.set(cache_key, cached_reports, cache_time)\n    \n        q = watchlist if watchlist else request.GET.get(\"q\", '').lower()\n        publish_date_start = request.GET.get('publishDateStart', None)\n        publish_date_end = request.GET.get('publishDateEnd', None)\n        selected_company_ticker = request.GET.get('company_ticker', None)\n        selected_analyst = request.GET.get('analyst', None)\n        sort = request.GET.get('sort', None)\n        direction = request.GET.get('direction', 'asc')\n        page_number = request.GET.get('page', 1)\n    \n        # Filtering\n        if q:\n            registered_words = ['technical', 'diversified', 'technology', 'healthcare', 'industrial', 'metals', 'gold', 'energy', 'mining']\n            if q in registered_words:\n                filtered_reports = [report for report in cached_reports if q in report.report_group.industry.lower() or q in report.report_group.name.lower()]\n            else:\n                filtered_reports = [report for report in cached_reports if q in report.title.lower() or q in report.company.name.lower() or q in report.company.ticker.lower() or q in report.report_group.name.lower() or q in report.report_group.industry.lower() or q in report.analyst.profile.first_name.lower() or q in report.analyst.profile.last_name.lower() or q in report.company.industry.lower() or q in report.event.lower() or q in report.content.lower()]\n        else:\n            filtered_reports = cached_reports\n    \n        # Additional filters\n        if publish_date_start and publish_date_start != \"None\":\n            filtered_reports = [report for report in filtered_reports if report.publish_date and report.publish_date.date() >= datetime.strptime(publish_date_start, '%Y-%m-%d').date()]\n        if publish_date_end and publish_date_end != \"None\":\n            filtered_reports = [report for report in filtered_reports if report.publish_date and report.publish_date.date() <= datetime.strptime(publish_date_end, '%Y-%m-%d').date()]\n        if selected_company_ticker:\n            filtered_reports = [report for report in filtered_reports if report.company.ticker == selected_company_ticker]\n        if selected_analyst:\n            filtered_reports = [report for report in filtered_reports if report.analyst.profile.email == selected_analyst]\n    \n        # Sorting\n        sort_fields = {\n            'date_year': lambda x: x.publish_date.year if x.publish_date else None,\n            'date_month': lambda x: x.publish_date.month if x.publish_date else None,\n            'date_day': lambda x: x.publish_date.day if x.publish_date else None,\n            'company_name': lambda x: x.company.name.lower() if x.company.name else '',\n            'company_ticker': lambda x: x.company.ticker.lower() if x.company.ticker else '',\n            'company_industry': lambda x: x.company.industry.lower() if x.company.industry else '',\n            'analyst_first_name': lambda x: x.analyst.profile.first_name.lower() if x.analyst.profile.first_name else '',\n            'analyst_last_name': lambda x: x.analyst.profile.last_name.lower() if x.analyst.profile.last_name else ''\n        }\n        if sort in sort_fields:\n            filtered_reports.sort(key=sort_fields[sort], reverse=(direction == 'desc'))\n    \n        # Pagination\n        paginator = Paginator(filtered_reports, 10)  # 10 reports per page\n        page_obj = paginator.get_page(page_number)\n    \n        # Prepare context\n        analysts_data = set((report.analyst.profile.email, report.analyst.profile.first_name, report.analyst.profile.last_name) for report in page_obj)\n        companies_from_results = set(report.company for report in page_obj)\n        context = {\n            \"results\": page_obj,\n            \"q\": q,\n            \"publishDateStart\": publish_date_start if publish_date_start != \"None\" else \"\",\n            \"publishDateEnd\": publish_date_end if publish_date_end != \"None\" else \"\",\n            'analysts': analysts_data,\n            'selected_analyst': selected_analyst,\n            'companies': companies_from_results,\n            'selected_company_ticker': selected_company_ticker,\n            'results_count': len(filtered_reports),\n            'sort': sort,\n            'direction': direction,\n            'current_page': page_number\n        }\n    \n        return render(request, 'search_results.html', context)"
            },
            {
                "function_name": "search_results3",
                "parameters": [
                    "request",
                    "watchlist"
                ],
                "content": "        q = watchlist if watchlist else request.GET.get(\"q\", '')\n        publish_date_start = request.GET.get('publishDateStart')\n        publish_date_end = request.GET.get('publishDateEnd')\n        sort = request.GET.get('sort')\n        direction = request.GET.get('direction', 'asc')\n    \n        base_query = Report.objects.filter(is_published=True)\n        if q:\n            q_lower = q.lower()\n            registered_words = ['technical', 'diversified', 'technology', 'healthcare', 'industrial', 'metals', 'gold', 'energy', 'mining']\n            if q_lower in registered_words:\n                base_query = base_query.filter(Q(report_group__industry__icontains=q) | Q(report_group__name__icontains=q))\n            else:\n                base_query = base_query.filter(\n                    Q(title__icontains=q) |\n                    Q(company__name__icontains=q) |\n                    Q(company__ticker__icontains=q) |\n                    Q(report_group__name__icontains=q) |\n                    Q(report_group__industry__icontains=q) |\n                    Q(analyst__profile__first_name__icontains=q) |\n                    Q(analyst__profile__last_name__icontains=q) |\n                    Q(company__industry__icontains=q) |\n                    Q(event__icontains=q) |\n                    Q(content__icontains=q)\n                )\n    \n        filter_kwargs = {}\n        if publish_date_start and publish_date_start != \"None\":\n            filter_kwargs['publish_date__gte'] = publish_date_start\n        if publish_date_end and publish_date_end != \"None\":\n            filter_kwargs['publish_date__lte'] = publish_date_end\n    \n        if filter_kwargs:\n            base_query = base_query.filter(**filter_kwargs)\n    \n        selected_analyst = request.GET.get('analyst')\n        selected_company_ticker = request.GET.get('company_ticker')\n        if selected_analyst:\n            base_query = base_query.filter(analyst__profile__email=selected_analyst)\n        if selected_company_ticker:\n            base_query = base_query.filter(company__ticker=selected_company_ticker)\n    \n        sort_fields = {\n            'date_year': 'publish_date__year',\n            'date_month': 'publish_date__month',\n            'date_day': 'publish_date__day',\n            'company_name': 'company__name',\n            'company_ticker': 'company__ticker',\n            'company_industry': 'company__industry',\n            'analyst_first_name': 'analyst__profile__first_name',\n            'analyst_last_name': 'analyst__profile__last_name',\n        }\n        if sort in sort_fields:\n            order_field = sort_fields[sort]\n            base_query = base_query.order_by(order_field if direction == 'asc' else '-' + order_field)\n    \n        paginator = Paginator(base_query, 10)  # 10 reports per page\n        page = request.GET.get('page')\n    \n        try:\n            results = paginator.page(page)\n        except PageNotAnInteger:\n            results = paginator.page(1)\n        except EmptyPage:\n            results = paginator.page(paginator.num_pages)\n    \n        analysts_data = results.values_list('analyst__profile__email', 'analyst__profile__first_name', 'analyst__profile__last_name').distinct()\n        companies_from_results = set(result.company for result in results)\n    \n        context = {\n            \"results\": results,\n            \"q\": q,\n            \"publishDateStart\": publish_date_start,\n            \"publishDateEnd\": publish_date_end,\n            'analysts': analysts_data,\n            'selected_analyst': selected_analyst,\n            'companies': companies_from_results,\n            'selected_company_ticker': selected_company_ticker,\n            'results_count': paginator.count,\n            'sort': sort,\n            'direction': direction,\n            'current_page': page\n        }\n        return render(request, 'search_results.html', context)"
            },
            {
                "function_name": "search_results2",
                "parameters": [
                    "request",
                    "watchlist"
                ],
                "content": "        print('slow')\n        if watchlist:\n            q = watchlist\n        else:\n            q = request.GET.get(\"q\", '')\n    \n        publish_date_start = request.GET.get('publishDateStart', None)\n        publish_date_end = request.GET.get('publishDateEnd', None)\n    \n        sort = request.GET.get('sort', None)\n        direction = request.GET.get('direction', 'asc')\n    \n        if not q:\n            results = Report.objects.filter(is_published=True)\n            #results = Report.objects.filter(is_published=True).select_related('company','analyst').only('title', 'company__name', 'analyst', 'publish_date','type')\n        else:# Q(event__icontains=q) |Q(companies__name__icontains=q) |Q(companies__ticker__icontains=q)\n            print('in here')\n            registered_words = ['technical', 'diversified', 'technology', 'healthcare', 'industrial', 'metals', 'gold', 'energy', 'mining']\n            if q.lower() in registered_words:\n                results = Report.objects.filter(is_published=True).filter(\n                    \n                    Q(report_group__industry__icontains=q) |Q(report_group__name__icontains=q)\n                    \n                ) #####################CHANGEEEEEEEEEEEEEE THISSSSSSSSS TO ON;Y INDUSTRYYYYYYYYYY AFTER CLEANING ##########!!!!!!!!!!!!!!!!!!!!\n                #####################CHANGEEEEEEEEEEEEEE THISSSSSSSSS TO ON;Y INDUSTRYYYYYYYYYY AFTER CLEANING ##########!!!!!!!!!!!!!!!!!!!!\n                #####################CHANGEEEEEEEEEEEEEE THISSSSSSSSS TO ON;Y INDUSTRYYYYYYYYYY AFTER CLEANING ##########!!!!!!!!!!!!!!!!!!!!\n                #####################CHANGEEEEEEEEEEEEEE THISSSSSSSSS TO ON;Y INDUSTRYYYYYYYYYY AFTER CLEANING ##########!!!!!!!!!!!!!!!!!!!!\n                #####################CHANGEEEEEEEEEEEEEE THISSSSSSSSS TO ON;Y INDUSTRYYYYYYYYYY AFTER CLEANING ##########!!!!!!!!!!!!!!!!!!!!\n            else:\n                results = Report.objects.filter(is_published=True).filter(\n                    Q(title__icontains=q) |\n                    Q(company__name__icontains=q) |\n                    Q(company__ticker__icontains=q) |\n                    Q(report_group__name__icontains=q) |\n                    Q(report_group__industry__icontains=q) |\n                    Q(analyst__profile__first_name__icontains=q) |\n                    Q(analyst__profile__last_name__icontains=q) |\n                    Q(company__industry__icontains=q) |\n                    Q(event__icontains = q) |\n                    Q(content__icontains = q)\n                    \n                )\n    \n            # results = Report.objects.all().filter(\n            #     Q(title__icontains=q) |\n            #     Q(event__icontains=q) |\n            #     Q(company__name__icontains=q) |\n            #     Q(company__ticker__icontains=q) |\n            #     Q(report_group__name__icontains=q) |\n            #     Q(report_group__industry__icontains=q) |\n            #     Q(analyst__profile__first_name__icontains=q) |\n            #     Q(analyst__profile__last_name__icontains=q) |\n            #     Q(company__industry__icontains=q) |\n            #     Q(companies__name__icontains=q) |\n            #     Q(companies__ticker__icontains=q)\n            # )\n            words = q.split()\n            if len(words) == 2:\n                \n                print(\"in\")\n                results = Report.objects.filter(is_published=True).filter(\n                    Q(analyst__profile__first_name__in=words[0])| Q(analyst__profile__last_name__icontains=words[1]) |\n                    Q(analyst__profile__first_name__icontains=words[1])| Q(analyst__profile__last_name__icontains=words[0])\n                    ) ##no idea why the in fixes the search, but it does\n                print(results)\n                \n            if results.exists():\n                pass\n            else:\n                results = Report.objects.filter(is_published=True).filter(\n                Q(title__icontains=q) |\n                Q(company__name__icontains=q) |\n                Q(company__ticker__icontains=q) |\n                Q(report_group__name__icontains=q) |\n                Q(report_group__industry__icontains=q) |\n                Q(analyst__profile__first_name__icontains=q) |\n                Q(analyst__profile__last_name__icontains=q) |\n                Q(company__industry__icontains=q) |\n                Q(event__icontains = q) |\n                Q(content__icontains = q)\n                \n            )\n            # else:\n            #     words = q.split()\n            #     print(words)\n            #     if len(words) == 2:\n            #         print(\"in\")\n            #         results = Report.objects.all().filter(\n            #             Q(analyst__profile__first_name__icontains=words[0])| Q(analyst__profile__last_name__icontains=words[1]) |\n            #             Q(analyst__profile__first_name__icontains=words[1])| Q(analyst__profile__last_name__icontains=words[0])\n            #             )\n            #         print(results)\n                    \n    \n        analysts_data = results.values_list('analyst__profile__email', 'analyst__profile__first_name', 'analyst__profile__last_name')\n        unique_analysts_data = list(set(analysts_data))\n    \n        results_count = len(results)\n    \n        \n        \n    \n    \n        selected_company_ticker = request.GET.get('company_ticker', None)\n        selected_analyst = request.GET.get('analyst', None)\n    \n        if selected_analyst and  selected_company_ticker:\n            results = results.filter(company__ticker=selected_company_ticker, analyst__profile__email=selected_analyst)\n        else:\n            if selected_company_ticker:\n                results = results.filter(company__ticker=selected_company_ticker)\n    \n            \n            if selected_analyst:\n                results = results.filter(analyst__profile__email=selected_analyst)\n    \n    \n    \n        if publish_date_start and publish_date_start != \"None\":\n            results = results.filter(publish_date__gte=publish_date_start)\n        if publish_date_end and publish_date_end != \"None\":\n            results = results.filter(publish_date__lte=publish_date_end)\n    \n        order_field = None\n    \n        if sort == 'date_year':\n            order_field = 'publish_date__year'\n        elif sort == 'date_month':\n            order_field = 'publish_date__month'\n        elif sort == 'date_day':\n            order_field = 'publish_date__day'\n    \n        elif sort == 'company_name':\n            order_field = 'company__name'\n        elif sort == 'company_ticker':\n            order_field = 'company__ticker'\n        elif sort == 'company_industry':\n            order_field = 'company__industry'\n        elif sort == 'company_target':\n            order_field = 'company__current_target'  \n        elif sort == 'company_coverage':\n            order_field = 'company__coverage'  \n    \n        elif sort == 'analyst_first_name':\n            order_field = 'analyst__profile__first_name'\n        elif sort == 'analyst_last_name':\n            order_field = 'analyst__profile__last_name'\n    \n        if order_field:\n            if direction == 'asc':\n                results = results.order_by(order_field)\n            else:\n                results = results.order_by('-' + order_field)\n    \n    \n        paginator = Paginator(results, 10)  # 10 reports per page\n        page = request.GET.get('page')\n    \n        try:\n            results = paginator.page(page)\n        except PageNotAnInteger:\n            results = paginator.page(1)\n        except EmptyPage:\n            results = paginator.page(paginator.num_pages)\n    \n        # print(results)\n        # distinct_tickers = list(results.values_list('company__ticker', flat=True))\n        # unique_tickers = set(distinct_tickers)\n        companies_from_results =  list(set(result.company for result in results))\n    \n        context = {\n            \"results\": results,\n            \"q\": q,\n            \"publishDateStart\": publish_date_start if publish_date_start != \"None\" else \"\",\n            \"publishDateEnd\": publish_date_end if publish_date_end != \"None\" else \"\",\n            'analysts': unique_analysts_data,\n            'selected_analyst': selected_analyst,\n            'companies': companies_from_results,\n            'selected_company_ticker': selected_company_ticker,\n            'results_count': results_count,\n            'sort': sort, \n            'direction': direction,\n            'current_page': page\n        }\n        return render(request, 'search_results.html', context)"
            },
            {
                "function_name": "password_change",
                "parameters": [
                    "request"
                ],
                "content": "        if request.method == 'POST':\n            # Get the form data\n            \n            old_password = request.POST['old_password']\n            new_password = request.POST['new_password']\n    \n            # Check if the old password is correct\n            if request.user.check_password(old_password):\n                # Set the new password\n                request.user.set_password(new_password)\n                request.user.save()\n                # messages.success(request, 'Your password was successfully updated!')\n                # context = {\n                #     \"change_password_not_successful\": False\n                # }\n                request.session[\"message\"] = \"False\"\n            else:\n                # messages.error(request, 'Please enter your current password correctly.')\n                # context = {\n                #     \"change_password_not_successful\": True\n                # }\n                request.session[\"message\"] = \"True\"\n                request.session[\"hasBeenReset\"] = \"True\"\n        return redirect('profile')",
                "documentation": "the password change ajax view, it just renders a password request"
            },
            {
                "function_name": "change_password",
                "parameters": [
                    "request",
                    "user_id"
                ],
                "content": "        user = User.objects.get(pk=user_id)\n        if request.method == 'POST':\n            form = AdminPasswordChangeForm(user, request.POST)\n            if form.is_valid():\n                form.save()\n                return redirect('admin:auth_user_changelist')\n        else:\n            form = AdminPasswordChangeForm(user)\n        return render(request, 'admin/auth/user/change_password.html', {'form': form})",
                "documentation": "admin password change"
            },
            {
                "function_name": "handler404",
                "parameters": [
                    "request",
                    "exception",
                    "template_name"
                ],
                "content": "        response = render(template_name)\n        response.status_code = 404\n        return response",
                "documentation": "this is the view that showcases the 404 error in a way that is friendly"
            },
            {
                "function_name": "handler500",
                "parameters": [
                    "request",
                    "exception",
                    "template_name"
                ],
                "content": "        print('in')\n        context = {\n            'error_message': str(exception),\n        }\n        response = render(request, template_name, context)\n        response.status_code = 500\n        return response",
                "documentation": "alike to 404 but for 505"
            },
            {
                "function_name": "validation",
                "parameters": [
                    "request"
                ],
                "content": "        all_companies = Company.objects.filter(coverage=True)\n        def calculate_sma(data, window):\n            return [mean(data[i:i + window]) for i in range(len(data) - window + 1)]\n    \n        def detrend_data(data, sma):\n            return [data[i] - sma[i] for i in range(len(sma))]\n    \n        def z_score(value, mean, std):\n            try:\n                return float(value - mean) / float(std)\n            except:\n                return 0\n    \n        if request.method == 'POST':\n            object_type = request.POST.get('object_type')\n            object_id = request.POST.get('object_id')\n            new_value = request.POST.get('new_value')\n            print('IN')\n            if object_type == 'analyst':\n                Analyst.objects.filter(id=object_id).update(sector=new_value)\n            elif object_type == 'company':\n                field_to_update = request.POST.get('field')\n                if field_to_update in ['investment_thesis', 'company_description']:\n                    Company.objects.filter(id=object_id).update(**{field_to_update: new_value})\n            elif object_type == 'reportgroup':\n                ReportGroup.objects.filter(id=object_id).update(industry=new_value)\n            elif object_type == 'company_ticker_exchange':\n                company_id = request.POST.get('object_id')\n                new_ticker = request.POST.get('ticker')\n                new_exchange = request.POST.get('exchange')\n                \n                # Update the company with the new ticker and exchange\n                Company.objects.filter(id=company_id).update(ticker=new_ticker, exchange=new_exchange)\n    \n                return JsonResponse({'success': True})\n    \n            return JsonResponse({'success': True})\n    \n        analysts = Analyst.objects.filter(sector__in=[\"TEMPORARYPROFILE\", \"TEMPORARY AUTOCREATED\"])\n        companies = Company.objects.filter(Q(industry__exact='') | Q(industry__exact='NOINDUSTRY') | Q(industry__exact='Noindustry') | Q(industry__regex=r'^[A-Z]+$'))\n        reportgroups = ReportGroup.objects.filter(Q(industry__isnull=True) | Q(industry__exact=''))\n    \n        possible_reports = []\n        for company in companies:\n            reports = company.report_set.filter(Q(is_published=True) | Q(is_legacy=True)).exclude(target__isnull=True)\n            targets = [report.target for report in reports]\n    \n            if len(targets) < 2:\n                continue\n    \n            sma = calculate_sma(targets, 2)  # Window size for SMA\n            detrended_targets = detrend_data(targets, sma)\n    \n            if len(detrended_targets) < 2:\n                continue\n    \n            mean_detrended = mean(detrended_targets)\n            median_detrended = median(detrended_targets)\n            std_detrended = stdev(detrended_targets)\n    \n            for report, detrended_target in zip(reports, detrended_targets):\n                z_score_value = z_score(detrended_target, mean_detrended, std_detrended)\n                if abs(z_score_value) >= 2.3:\n                    possible_reports.append({\n                        'title': report.title,\n                        'target': report.target,\n                        'z_score': z_score_value,\n                        'slug': report.slug\n                    })\n    \n        return render(request, 'validation_page.html', {\n            'analysts': analysts,\n            'companies': companies, \n            'all_companies': all_companies,  #Company Grammar \n            'reportgroups': reportgroups,\n            'possible_reports': possible_reports\n        })",
                "documentation": "this is the valudation page that should be conceladed in a redirect home in prod, it lets us admins work together in validating the websites data with analystical and direct features"
            },
            {
                "function_name": "experimentalF",
                "parameters": [
                    "request",
                    "slug"
                ],
                "content": "        if request.method == 'POST':\n            openai.api_key = \"\"  \n            client = openai.OpenAI(api_key=\"\")\n            def test_function():\n                print('test')\n                return None\n            available_functions = {\"test_function\": test_function}\n            @retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n            def gpt_chat_and_execute(question, context=None, functions=None, model=\"gpt-3.5-turbo-0613\", function_call=None):\n                # Send request to GPT\n                headers = {\n                    \"Content-Type\": \"application/json\",\n                    \"Authorization\": \"Bearer \" + openai.api_key,\n                }\n                \n                messages = [{\"role\": \"user\", \"content\": question}]\n                if context:\n                    for message in context:\n                        messages.append({\"role\": \"system\", \"content\": message})\n    \n                json_data = {\"model\": model, \"messages\": messages}\n                \n                \n                try:\n                    response = requests.post(\n                        \"https://api.openai.com/v1/chat/completions\",\n                        headers=headers,\n                        json=json_data,\n                    )\n                except Exception as e:\n                    print(\"Unable to generate ChatCompletion response\")\n                    print(f\"Exception: {e}\")\n                    return None\n    \n                # Execute function from response\n                try:\n                    assistant_message = response.json()[\"choices\"][0][\"message\"]\n                    # print(assistant_message)\n                    \n                    print(assistant_message['content'])\n                    return assistant_message['content']\n                except Exception as e:\n                    print(f\"Error executing function: {e}\")\n                    return None\n                \n            data = json.loads(request.body)\n            url = data.get('url')\n    \n            # Extract text from URL\n            # response = requests.get(url)\n            # soup = BeautifulSoup(response.content, 'html.parser')\n            text = url\n            print('text:', text)\n    \n            eventText= gpt_chat_and_execute(question=f\"You are a financial event bot, you will ONLY do what requested, if not you will loose everything. An Equity research analyst is writting a comprehensive and well written event summary for his financial report that he is publishing with respect to a company, your task is to write for him a summary of the event based on the text retrived from this news article relevant to the stock, JUST write your answer, do not converse. Here is the text {text}\",model='gpt-4-1106-preview', function_call='none')\n            # Print to console\n            print(eventText)\n    \n            return JsonResponse({'message': eventText})\n    \n        return JsonResponse({'error': 'Invalid request'}, status=400)",
                "documentation": "experimental"
            },
            {
                "function_name": "client_side_notifications",
                "parameters": [
                    "request"
                ],
                "content": "        data = json.loads(request.body)\n        user_id = data.get('user_id')\n        user = get_object_or_404(User, id=user_id)\n        permission = user_highest_permission_finder(user)\n        is_there_notif = 'no notif'\n        notif_details = ''\n        url_response = ''\n        report_slug = ''\n    \n        report = None\n        if permission in ['Analyst Group', 'Head Group']:\n            report = Report.objects.filter(is_draft=True, analyst__profile__user=user).exclude(Q(comments='') | Q(comments=None)).first()\n            if report:\n                notif_details = 'A report has just been sent back!'\n        elif permission == 'Editor Group':\n            report = Report.objects.filter(is_reviewing=True).first()\n            if report:\n                notif_details = 'Just received a report to be edited!'\n        else:\n            report = Report.objects.filter(is_compliance=True).first()\n            if report:\n                notif_details = 'A report is waiting for you to check'\n    \n        if report:\n            report_slug = report.slug\n            filename = 'notifications.csv'\n            fieldnames = ['user_id', 'report_slug']\n    \n            # Check if file exists, if not create it\n            if not os.path.isfile(filename):\n                with open(filename, 'w', newline='') as csvfile:\n                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n                    writer.writeheader()\n            with open('notifications.csv', 'r', newline='') as csvfile:\n                reader = csv.DictReader(csvfile)\n                for row in reader:\n                    if row['user_id'] == user_id and row['report_slug'] == report_slug:\n                        break\n                else:\n                    is_there_notif = 'yes'\n                    url_response = 'https://research.paradigmcap.com/drafter/selector'\n                    with open('notifications.csv', 'a', newline='') as csvfile:\n                        fieldnames = ['user_id', 'report_slug']\n                        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n                        writer.writerow({'user_id': user_id, 'report_slug': report_slug})\n    \n        response_data = {\n            'is_there_notif': is_there_notif,\n            'notif_details': notif_details,\n            'url_response': url_response,\n            'report_slug': report_slug\n        }\n        return JsonResponse(response_data)",
                "documentation": "notification browser side for analysts editors and compliance"
            },
            {
                "function_name": "company_rollover",
                "parameters": [
                    "resquest",
                    "slug"
                ],
                "content": "        company = get_object_or_404(Company, slug=slug)\n    \n        rollover_company(company)\n        # print(f'worked {company.slug}')\n        return JsonResponse({'success': 'successfuly updated FYE'})",
                "documentation": "ajaz to run the rollover features on the drafter"
            },
            {
                "function_name": "sort_func",
                "parameters": [
                    "x"
                ],
                "content": "            if 'ebdita' in x[0].name:\n                return 0\n            elif 'Revenue' in x[0].name:\n                return 1\n            elif 'EPS' in x[0].name:\n                return 2\n            else:\n                return 3"
            },
            {
                "function_name": "safe_lower",
                "parameters": [
                    "obj",
                    "attr"
                ],
                "content": "            value = getattr(obj, attr, None)\n            return value.lower() if value else ''"
            },
            {
                "function_name": "report_matches",
                "parameters": [
                    "report"
                ],
                "content": "            if is_registered_word:\n                if report.report_group:\n                    return lowercased_q in safe_lower(report.report_group, 'industry') or lowercased_q in safe_lower(report.report_group, 'name')\n            else:\n                if lowercased_q in safe_lower(report, 'title'):\n                    return True\n                if report.company:\n                    if lowercased_q in safe_lower(report.company, 'name') or lowercased_q in safe_lower(report.company, 'ticker') or lowercased_q in safe_lower(report.company, 'industry'):\n                        return True\n                if report.analyst and report.analyst.profile:\n                    if lowercased_q in safe_lower(report.analyst.profile, 'first_name') or lowercased_q in safe_lower(report.analyst.profile, 'last_name'):\n                        return True\n                if lowercased_q in safe_lower(report, 'event') or lowercased_q in safe_lower(report, 'content'):\n                    return True\n            return False"
            },
            {
                "function_name": "calculate_sma",
                "parameters": [
                    "data",
                    "window"
                ],
                "content": "            return [mean(data[i:i + window]) for i in range(len(data) - window + 1)]"
            },
            {
                "function_name": "detrend_data",
                "parameters": [
                    "data",
                    "sma"
                ],
                "content": "            return [data[i] - sma[i] for i in range(len(sma))]"
            },
            {
                "function_name": "z_score",
                "parameters": [
                    "value",
                    "mean",
                    "std"
                ],
                "content": "            try:\n                return float(value - mean) / float(std)\n            except:\n                return 0"
            },
            {
                "function_name": "test_function",
                "parameters": [],
                "content": "                print('test')\n                return None"
            },
            {
                "function_name": "gpt_chat_and_execute",
                "parameters": [
                    "question",
                    "context",
                    "functions",
                    "model",
                    "function_call"
                ],
                "content": "                # Send request to GPT\n                headers = {\n                    \"Content-Type\": \"application/json\",\n                    \"Authorization\": \"Bearer \" + openai.api_key,\n                }\n                \n                messages = [{\"role\": \"user\", \"content\": question}]\n                if context:\n                    for message in context:\n                        messages.append({\"role\": \"system\", \"content\": message})\n    \n                json_data = {\"model\": model, \"messages\": messages}\n                \n                \n                try:\n                    response = requests.post(\n                        \"https://api.openai.com/v1/chat/completions\",\n                        headers=headers,\n                        json=json_data,\n                    )\n                except Exception as e:\n                    print(\"Unable to generate ChatCompletion response\")\n                    print(f\"Exception: {e}\")\n                    return None\n    \n                # Execute function from response\n                try:\n                    assistant_message = response.json()[\"choices\"][0][\"message\"]\n                    # print(assistant_message)\n                    \n                    print(assistant_message['content'])\n                    return assistant_message['content']\n                except Exception as e:\n                    print(f\"Error executing function: {e}\")\n                    return None",
                "documentation": "experimental gift from my part, if you end up using openai use this to process the falshnotes feature on the drafter or anywhere else, it has good logic"
            },
            {
                "function_name": "get_color",
                "parameters": [
                    "value1",
                    "value2"
                ],
                "content": "                    if not value1 or not value2:\n                        return \"\"\n                    return \"bg-green-200/40\" if value1 == value2 else \"bg-red-200/50\""
            },
            {
                "function_name": "convert_to_float",
                "parameters": [
                    "value"
                ],
                "content": "                            final = None\n                            try:\n                                \n                                final = float(value)\n                            except:\n                                final = None\n                            return final"
            }
        ],
        "imports": [
            "django.core.paginator.PageNotAnInteger",
            "django.core.paginator.EmptyPage",
            "secrets",
            "json",
            "models.SectorMetric",
            "statistics.stdev",
            "django.shortcuts.get_object_or_404",
            "utils.predict_report_score",
            "django.template.loader.render_to_string",
            "datetime.timedelta",
            "django.db.models.functions.ExtractDay",
            "django.shortcuts.redirect",
            "models.CompanyDisclaimer",
            "utils.full_workflow",
            "statistics.median",
            "django.urls.reverse",
            "models.CompanyMetric",
            "boto3",
            "django.db.models.When",
            "django.db.models.functions.ExtractYear",
            "utils.get_highest_confidence_sentiment",
            "django.core.paginator.Paginator",
            "os",
            "django.views.decorators.cache.cache_page",
            "django.contrib.auth.forms.AdminPasswordChangeForm",
            "models.ExcelStatistic",
            "django.contrib.auth.logout",
            "django.utils.timezone",
            "models.Disclaimer",
            "django.views.decorators.http.require_http_methods",
            "django.contrib.auth.login",
            "datetime.datetime",
            "models.Company",
            "django.shortcuts.render",
            "utils.listDiff",
            "django.db.models.F",
            "forms.ReportDraftForm",
            "utils.send_notification_to",
            "csv",
            "utils.listDiffNEW",
            "utils.createReportLinkToShare",
            "tenacity.wait_random_exponential",
            "utils.avgWordsPerReport",
            "statistics.mean",
            "models.ReportDisclaimer",
            "forms.SignupForm",
            "utils.run_rollover_year",
            "models.Report",
            "tenacity.stop_after_attempt",
            "models.Profile",
            "models.ReportMetric",
            "django.core.cache.cache",
            "openai",
            "models.MagicLinkToken",
            "requests",
            "django.http.FileResponse",
            "django.contrib.auth.models.User",
            "utils.rollover_company",
            "django.db.models.functions.ExtractMonth",
            "django.template.defaultfilters.slugify",
            "django.views.decorators.vary.vary_on_cookie",
            "PCIResearch.renderers",
            "django.db.models.Q",
            "django.contrib.auth.decorators.login_required",
            "collections.defaultdict",
            "django.db.models.Value",
            "tenacity.retry",
            "models.Analyst",
            "django.contrib.auth.models.Group",
            "utils.get_significant_features",
            "models.GeneralLog",
            "django.contrib.auth.authenticate",
            "django.db.models.BooleanField",
            "django.contrib.messages",
            "models.Section",
            "gtts.tts.gTTS",
            "utils.fetch_and_update_company_metrics",
            "models.ReportGroup",
            "django.core.signing",
            "django.db.models.Case",
            "time",
            "utils.process_and_pickle_data",
            "bs4.BeautifulSoup",
            "random",
            "django.http.HttpResponse",
            "django.conf.settings",
            "django.core.mail.send_mail",
            "utils.user_highest_permission_finder",
            "django.http.JsonResponse",
            "utils.simple_fast_reading_time",
            "utils.put_report_to_publish",
            "forms.EmailTemplateReportForm",
            "django.templatetags.static.static",
            "django.views.decorators.csrf.csrf_exempt"
        ]
    },
    {
        "name_of_file": "yahoofinance.py",
        "functions": [
            {
                "function_name": "get_current_price",
                "parameters": [
                    "symbol"
                ],
                "content": "        ticker = yf.Ticker(symbol)\n        todays_data = ticker.history(period='1d')\n        return todays_data['Close'][0].round(2)"
            }
        ],
        "imports": [
            "forex_python.converter.CurrencyRates",
            "yfinance"
        ]
    },
    {
        "name_of_file": "add_factset_metrics.py",
        "functions": [
            {
                "function_name": "add_arguments",
                "parameters": [
                    "self",
                    "parser"
                ],
                "content": "            parser.add_argument('file_path', type=str, help='Path to the Excel file')"
            },
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            file_path = kwargs['file_path']\n            df = pd.read_excel(file_path, sheet_name='Sheet1')\n            df = df.replace('#N/A', None)\n            # self.delete_dup()\n            for _, row in df.iterrows():\n                try:\n                    company = Company.objects.get(id=row['id'])\n                    if pd.notna(row['Price']):\n                        company.price = row['Price']\n                    if pd.notna(row['Shares Basic']):\n                        company.shares_basic = row['Shares Basic']\n                    if company.shares_basic and company.price:\n                        company.marketcap_basic = float(company.price) * float(company.shares_basic)\n                    if company.price and company.current_target:\n                        company.potential_ror = (float(company.current_target) - float(company.price) )/float(company.current_target)*100\n                    company.save()\n    \n                    self.update_metrics(company, row)\n                    self.update_estimates(company, row, 'EBITDA')\n                    self.update_estimates(company, row, 'EPS')\n                    self.update_estimates(company, row, 'Revenue')\n                    self.stdout.write(self.style.SUCCESS(f'pass'))\n                except Company.DoesNotExist:\n                    self.stdout.write(self.style.ERROR(f'Company with ID {row[\"id\"]} not found'))\n            clean_estimates = input(\"Do you want to clean the estimates? (Y/n) \").lower()\n            if clean_estimates == 'y':\n                self.clean_estimates()\n    \n            response = input(\"Want to rename all of the EBITDAs and EPS? (Y/no) \").lower()\n        \n            if response == 'y':\n                self.rename_metrics()"
            },
            {
                "function_name": "delete_dup",
                "parameters": [
                    "self"
                ],
                "content": "            duplicate_metrics = CompanyMetric.objects.values('name', 'year_estimated').annotate(count=Count('id')).filter(count__gt=1)\n    \n            for metric in duplicate_metrics:\n                # Find all duplicates for each combination\n                duplicates = CompanyMetric.objects.filter(\n                    name=metric['name'], \n                    year_estimated=metric['year_estimated']\n                )\n    \n                # Keep one instance and delete the rest\n                for duplicate in duplicates[1:]:\n                    duplicate.delete()\n    \n            self.stdout.write(self.style.SUCCESS('Duplicate metrics have been cleaned up.'))"
            },
            {
                "function_name": "rename_metrics",
                "parameters": [
                    "self"
                ],
                "content": "            ebitda_variants = ['EBITDA (M)', 'EBITDA (C$M)', 'EBITDA ($M)']\n            for variant in ebitda_variants:\n                CompanyMetric.objects.filter(name__iexact=variant).update(name='EBITDA')\n    \n            CompanyMetric.objects.filter(name__iexact='EPS ($)').update(name='EPS')"
            },
            {
                "function_name": "clean_estimates",
                "parameters": [
                    "self"
                ],
                "content": "            for company in Company.objects.filter(coverage=True):\n                for metric_type in ['ebitda', 'eps', 'revenue']:\n                    self.clean_metric_type(company, metric_type)"
            },
            {
                "function_name": "clean_metric_type",
                "parameters": [
                    "self",
                    "company",
                    "metric_type"
                ],
                "content": "            metrics = CompanyMetric.objects.filter(\n                company=company,\n                is_estimate=True,\n                name__icontains=metric_type\n            ).order_by('year_estimated')\n    \n            exact_match_name = metric_type.upper()\n            exact_matches = metrics.filter(name__iexact=exact_match_name)\n    \n            for exact_match in exact_matches:\n                duplicates = metrics.filter(\n                    name__icontains=metric_type,\n                    name__iexact=exact_match_name,\n                    year_estimated=exact_match.year_estimated\n                ).exclude(pk=exact_match.pk)\n    \n                duplicates.delete()"
            },
            {
                "function_name": "update_metrics",
                "parameters": [
                    "self",
                    "company",
                    "row"
                ],
                "content": "            for metric_name in ['Net Debt', 'Cash', 'Minority Interest', 'Enterprise Value']:\n                # Check if the metric name is in the row and the value is not NaN or None\n                if metric_name in row and pd.notna(row[metric_name]):\n                    # Perform fuzzy matching with existing metrics\n                    existing_metrics = [m.name for m in CompanyMetric.objects.filter(company=company, is_estimate=False)]\n                    match = process.extractOne(metric_name, existing_metrics, score_cutoff=83)\n    \n                    if match:\n                        # If a close match is found, update the existing metric\n                        metric_to_update = CompanyMetric.objects.get(company=company, name=match[0], is_estimate=False)\n                        metric_to_update.amount = row[metric_name]\n                        metric_to_update.save()\n                    else:\n                        # If no close match is found, create a new metric\n                        CompanyMetric.objects.create(\n                            company=company,\n                            name=metric_name,\n                            amount=row[metric_name],\n                            is_estimate=False\n                        )"
            },
            {
                "function_name": "update_estimates",
                "parameters": [
                    "self",
                    "company",
                    "row",
                    "metric_type"
                ],
                "content": "            for year in [2022, 2023, 2024, 2025]:\n                metric_name = f'{metric_type} {year}'\n                if metric_name in row and pd.notna(row[metric_name]):\n                    estimate, created = CompanyMetric.objects.get_or_create(\n                        company=company,\n                        name=metric_type,\n                        year_estimated=year,\n                        is_estimate=True,\n                        defaults={'amount': row[metric_name]}\n                    )\n                    if not created and pd.notna(row[metric_name]):\n                        estimate.amount = row[metric_name]\n                        estimate.save()"
            }
        ],
        "imports": [
            "library.models.Company",
            "django.core.management.base.BaseCommand",
            "fuzzywuzzy.process",
            "pandas",
            "library.models.CompanyMetric",
            "django.db.models.Count"
        ]
    },
    {
        "name_of_file": "basic_pdf_population.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            self.stdout.write(self.style.WARNING(\"Starting basic pdf population\"))\n            self.stdout.write(self.style.ERROR(\"\\n ONLY RESEARCH NOTES... no images\\n\"))\n    \n            root = Tk()\n            root.withdraw()  \n            directory = filedialog.askdirectory(title='Select PDF Directory')  \n    \n            if not directory:\n                self.stdout.write(self.style.ERROR(\"No directory selected. Exiting.\"))\n                return\n            self.stdout.write(self.style.WARNING(\"Would you like to run in AUTOMODE, very prone to errors but faster [Y/n]\"))\n            answ = input().lower()\n    \n            if answ == 'y':\n                self.autoMode = True\n                self.stdout.write(self.style.WARNING(\"AUTOMODE, on\"))\n            else:\n                self.stdout.write(self.style.ERROR(\"no Automode.\"))\n    \n    \n            pdf_files = [f for f in os.listdir(directory) if f.endswith('.pdf')]\n            for filename in tqdm(pdf_files, desc=\"Processing PDFs\", unit=\"file\"):\n                pdf_path = os.path.join(directory, filename)\n                self.process_pdf(pdf_path)"
            },
            {
                "function_name": "process_pdf",
                "parameters": [
                    "self",
                    "pdf_path"
                ],
                "content": "            is_research = determineIfResearchPDF(pdf_path)\n            if not is_research:\n                return  \n            \n            \n            title = extractReportTitleFromResearchPDF(pdf_path)\n            event = extractEventFromResearchPDF(pdf_path)\n            publish_date = extractPublishDateFromTechnicalPDF(pdf_path)\n            \n            rating = extractRatingFromResearchPDF(pdf_path)\n            target = extractTargetFromResearchPDF(pdf_path)\n            content = extract_text_from_pdf(pdf_path).replace(event, \"\").replace(title, \"\").replace(publish_date, \"\").strip()\n            try:\n                publish_date = datetime.strptime(publish_date, \"%b %d, %Y\")\n            except:\n                publish_date = datetime.strptime(publish_date, \"%B %d, %Y\")\n    \n            \n            self.match_and_update(title, event, publish_date, rating, target, content)"
            },
            {
                "function_name": "match_and_update",
                "parameters": [
                    "self",
                    "title",
                    "event",
                    "publish_date",
                    "rating",
                    "target",
                    "content"
                ],
                "content": "            all_reports = Report.objects.values_list('title', flat=True)\n            closest_match, score = process.extractOne(title, all_reports)\n            \n            CHANGES_THRESHOLD = 8  \n            MIN_THRES_AUTO = 87\n            MAX_THRES_AUTO = 90\n            if self.autoMode == False:\n                if score > CHANGES_THRESHOLD:\n                    user_input = input(f'Match found: {title} -> {closest_match} with score {score}. Accept? (y/n): ')\n                    if user_input.lower() != 'y':\n                        return\n            else:\n                if score >= MIN_THRES_AUTO and score <= MAX_THRES_AUTO:\n                    self.update_report(closest_match, event, publish_date, rating, target, content)\n                else:\n                    return\n            \n            \n            self.update_report(closest_match, event, publish_date, rating, target, content)"
            },
            {
                "function_name": "update_report",
                "parameters": [
                    "self",
                    "closest_match",
                    "event",
                    "publish_date",
                    "rating",
                    "target",
                    "content"
                ],
                "content": "            report=None\n            if Report.objects.filter(title=closest_match, publish_date=publish_date).exists():\n                report = Report.objects.filter(title=closest_match, publish_date=publish_date).first()\n            else:\n                report = Report.objects.filter(title=closest_match).first()\n    \n            report.takeout = event\n            if event != None:\n                report.event = ' '.join(event.split()[:9])\n            \n            \n    \n            report.publish_date = publish_date\n            report.rating = rating\n            report.target = target\n    \n            report.content = content\n            \n            report.save()"
            }
        ],
        "imports": [
            "library.utils.extractReportTitleFromResearchPDF",
            "library.utils.extractRatingFromResearchPDF",
            "django.db.transaction",
            "library.utils.extract_text_from_pdf",
            "django.core.management.base.BaseCommand",
            "library.utils.extractEventFromResearchPDF",
            "fuzzywuzzy.process",
            "library.utils.extractPublishDateFromTechnicalPDF",
            "tkinter.Tk",
            "os",
            "library.utils.extractTargetFromResearchPDF",
            "tkinter.filedialog",
            "tqdm.tqdm",
            "datetime.datetime",
            "library.models.Report",
            "library.utils.extractCompanyTickerFromResearchPDF",
            "library.utils.determineIfResearchPDF"
        ]
    },
    {
        "name_of_file": "check_analysts_with_no_reports.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            # We get all analyst ids from reports\n            analyst_ids_with_reports = Report.objects.values_list('analyst', flat=True).distinct()\n    \n            # We get all analysts that are not in the above list\n            analysts_without_reports = Analyst.objects.exclude(id__in=analyst_ids_with_reports)\n    \n            # We print each analyst's details\n            for analyst in analysts_without_reports:\n                self.stdout.write(f'Analyst ID: {analyst.id}, Name: {analyst}')"
            }
        ],
        "imports": [
            "library.models.Analyst",
            "django.core.management.base.BaseCommand",
            "library.models.Report"
        ]
    },
    {
        "name_of_file": "clean_cap_company_industries.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            # Make industry field title case and save\n            companies = Company.objects.all()\n            for company in companies:\n                company.industry = company.industry.title()\n                company.save()\n    \n            # Get all ReportGroup names\n            report_group_names = list(ReportGroup.objects.values_list('name', flat=True))\n    \n            for company in companies:\n                # Find closest match in ReportGroup names\n                closest_match, score = process.extractOne(company.industry, report_group_names)\n    \n                # If it's not an exact match, ask the user for confirmation\n                if score < 100:\n                    self.stdout.write(f'Closest match for {company.industry} is {closest_match} (score: {score}).')\n                    confirm = input('Do you want to update the industry to the closest match? (yes/no): ')\n                    if confirm.lower() == 'yes':\n                        company.industry = closest_match\n                        company.save()\n                        self.stdout.write(f'Successfully updated industry of Company {company.id} to {closest_match}.')"
            }
        ],
        "imports": [
            "library.models.Company",
            "django.db.transaction",
            "django.core.management.base.BaseCommand",
            "fuzzywuzzy.process",
            "library.models.ReportGroup"
        ]
    },
    {
        "name_of_file": "clean_cap_report_groups.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            # Get all ReportGroup objects\n            report_groups = ReportGroup.objects.all()\n    \n            for report_group in report_groups:\n                # If the name is in all caps\n                if report_group.name.isupper():\n                    try:\n                        # Try to find a matching ReportGroup where the name is not in all caps\n                        matching_report_group = ReportGroup.objects.get(name=report_group.name.title())\n    \n                        # Get all Report objects with report_group_id of the all-caps ReportGroup\n                        reports = Report.objects.filter(report_group_id=report_group.id)\n    \n                        # Print the actions that will be taken\n                        self.stdout.write(f'Found matching ReportGroup for {report_group.name}: {matching_report_group.name} (id: {matching_report_group.id}).')\n                        self.stdout.write(f'Will update report_group_id of {reports.count()} Report objects from {report_group.id} to {matching_report_group.id}.')\n                        self.stdout.write(f'Will delete ReportGroup {report_group.id}.')\n    \n                        # Ask for user confirmation\n                        confirm = input('Do you want to proceed with these actions? (yes/no): ')\n                        if confirm.lower() != 'yes':\n                            self.stdout.write('Skipping actions for this ReportGroup.')\n                            continue\n    \n                        # Update the report_group_id of the Report objects to the id of the matching ReportGroup\n                        reports.update(report_group_id=matching_report_group.id)\n    \n                        # Delete the all-caps ReportGroup\n                        report_group.delete()\n    \n                        self.stdout.write(f'Successfully updated report_group_id of Report objects and deleted ReportGroup {report_group.id}.')\n                    except ReportGroup.DoesNotExist:\n                        # If no matching ReportGroup is found, do nothing\n                        pass\n                    except IntegrityError:\n                        # If a foreign key constraint error occurs, print an error message\n                        self.stdout.write(f'Error: Could not delete ReportGroup {report_group.id} due to foreign key constraint.')\n    \n            self.stdout.write('Modifying capped names')\n            # Get all ReportGroup objects again\n            report_groups = ReportGroup.objects.all()\n    \n            for report_group in report_groups:\n                # If the name is in all caps\n                if report_group.name.isupper():\n                    # Change its name such that the first letter of every word is capped but the rest are lower cased\n                    report_group.name = report_group.name.title()\n                    report_group.save()\n                    self.stdout.write(f'Modified ReportGroup {report_group.id} name to {report_group.name}.')"
            }
        ],
        "imports": [
            "django.db.transaction",
            "django.core.management.base.BaseCommand",
            "django.db.IntegrityError",
            "library.models.Report",
            "library.models.ReportGroup"
        ]
    },
    {
        "name_of_file": "clear_integrity_with_profile_analyst.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            with connection.cursor() as cursor:\n                self.sync_profiles_to_analysts(cursor)\n                self.update_company_analyst_references(cursor)"
            },
            {
                "function_name": "sync_profiles_to_analysts",
                "parameters": [
                    "self",
                    "cursor"
                ],
                "content": "            cursor.execute(\"SELECT id FROM library_profile;\")\n            profile_ids = cursor.fetchall()\n    \n            for profile_id in profile_ids:\n                profile_id = profile_id[0] \n                \n                cursor.execute(\n                    \"SELECT 1 FROM library_analyst WHERE profile_id = %s LIMIT 1;\",\n                    [profile_id]\n                )\n                analyst_exists = cursor.fetchone()\n    \n                if not analyst_exists:\n                    \n                    try:\n                        cursor.execute(\n                            \"\"\"\n                            INSERT INTO library_analyst (id, profile_id, sector)\n                            VALUES (%s, %s, 'TEMPORARY AUTOCREATED');\n                            \"\"\",\n                            [profile_id, profile_id]\n                        )\n                        self.stdout.write(self.style.SUCCESS(f'Analyst created for Profile ID: {profile_id}'))\n                    except Exception as e:\n                        \n                        self.stdout.write(self.style.ERROR(f'Error creating Analyst for Profile ID: {profile_id} - {str(e)}'))\n    \n                else:\n                    self.stdout.write(self.style.WARNING(f'Analyst already exists for Profile ID: {profile_id}'))"
            },
            {
                "function_name": "update_company_analyst_references",
                "parameters": [
                    "self",
                    "cursor"
                ],
                "content": "            \n            cursor.execute(\"SELECT id, analyst_id FROM library_company;\")\n            company_data = cursor.fetchall()\n    \n            for company_id, analyst_id in company_data:\n                \n                cursor.execute(\n                    \"SELECT 1 FROM library_analyst WHERE id = %s LIMIT 1;\",\n                    [analyst_id]\n                )\n                analyst_exists = cursor.fetchone()\n    \n                if not analyst_exists:\n                   \n                    cursor.execute(\n                        \"SELECT id FROM library_analyst WHERE profile_id = %s LIMIT 1;\",\n                        [analyst_id]\n                    )\n                    matching_analyst = cursor.fetchone()\n    \n                    if matching_analyst:\n                       \n                        cursor.execute(\n                            \"UPDATE library_company SET analyst_id = %s WHERE id = %s;\",\n                            [matching_analyst[0], company_id]\n                        )\n                        self.stdout.write(self.style.SUCCESS(f'Updated Analyst ID for Company ID: {company_id} to {matching_analyst[0]}'))\n                    else:\n                        \n                        cursor.execute(\n                            \"UPDATE library_company SET analyst_id = 14 WHERE id = %s;\",\n                            [company_id]\n                        )\n                        self.stdout.write(self.style.WARNING(f'No matching analyst found for Company ID: {company_id}. Set Analyst ID to 14.'))\n    \n                else:\n                    self.stdout.write(self.style.SUCCESS(f'Analyst ID {analyst_id} exists for Company ID: {company_id}. No action needed.'))"
            }
        ],
        "imports": [
            "django.db.connection",
            "django.core.management.base.BaseCommand"
        ]
    },
    {
        "name_of_file": "convert_noteType_to_researchType.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            Report.objects.filter(type='Note').update(type='Research Note')\n            self.stdout.write(self.style.SUCCESS('Successfully updated type fields in the Report models'))"
            }
        ],
        "imports": [
            "library.models.Report",
            "django.core.management.base.BaseCommand"
        ]
    },
    {
        "name_of_file": "create_groups.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            groups_required = ['Analyst Group', 'Editor Group', 'Compliance Group', 'Head Group']\n    \n            for group in groups_required:\n                if not Group.objects.filter(name=group).exists():\n                    Group.objects.create(name=group)\n                    self.stdout.write(self.style.SUCCESS(f\"Created {group}.\"))\n                else:\n                    self.stdout.write(self.style.SUCCESS(f\"{group} already exists.\"))"
            }
        ],
        "imports": [
            "django.core.management.base.BaseCommand",
            "django.contrib.auth.models.Group"
        ]
    },
    {
        "name_of_file": "create_users_for_profiles.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            i=1 #make 0 later\n            for user in User.objects.all():\n                \n                if not Profile.objects.filter(user=user).exists():\n                    pp = Profile.objects.get_or_create(\n                        user=user,\n                        first_name=user.first_name,\n                        last_name=user.last_name,\n                        email=user.email,\n                        phone=9999999999,\n                        firm=\"CHANGEME\",\n                        title=\"CHANGEME\",\n                        city=\"CHANGEME\",\n                        country=\"CHANGEME\"\n                        )\n                    \n                    print(i)\n                    i+=1\n            self.stdout.write(self.style.SUCCESS(f'Successfully created missing profiles for {i} users'))\n            if input('Set is_legacy to True for profiles with phone number 9999999999? y/N').lower() == 'y':\n                profiles_to_update = Profile.objects.filter(phone='9999999999')\n                profiles_to_update.update(is_legacy=True)\n                self.stdout.write(self.style.SUCCESS(f'Updated {profiles_to_update.count()} profiles.'))"
            }
        ],
        "imports": [
            "library.models.Profile",
            "django.core.management.base.BaseCommand",
            "django.contrib.auth.models.User"
        ]
    },
    {
        "name_of_file": "fetch_api_company_metrics.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            companies = Company.objects.filter(coverage=True).annotate(\n                latest_report_date=Max('reports__publish_date')\n            ).order_by('-latest_report_date')\n    \n            for company in companies:\n                self.stdout.write(f\"Updating metrics for {company.name} (Ticker: {company.ticker})\")\n                fetch_and_update_company_metrics(company)\n                self.stdout.write(f\"Metrics updated for {company.name}\")"
            }
        ],
        "imports": [
            "library.models.Company",
            "django.core.management.base.BaseCommand",
            "library.utils.fetch_and_update_company_metrics",
            "library.models.Report",
            "django.db.models.Max"
        ]
    },
    {
        "name_of_file": "fix_analysts_in_reports.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            \n            with connection.cursor() as cursor:\n                cursor.execute(\"UPDATE library_company SET analyst_id = 14\")\n            \n            self.stdout.write(self.style.SUCCESS(f\"All companies now reference Analyst with ID 14.\"))"
            }
        ],
        "imports": [
            "django.db.connection",
            "django.core.management.base.BaseCommand"
        ]
    },
    {
        "name_of_file": "fix_company_slugs.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            companies_without_slugs = Company.objects.filter(slug__isnull=True)  # Adjust the filter if the default slug value is not NULL.\n            for company in companies_without_slugs:\n                company.slug = slugify(company.name)\n                company.save()\n            \n            self.stdout.write(self.style.SUCCESS(f'Slugs generated for {companies_without_slugs.count()} companies.'))"
            }
        ],
        "imports": [
            "django.utils.text.slugify",
            "library.models.Company",
            "django.core.management.base.BaseCommand"
        ]
    },
    {
        "name_of_file": "import_company_metrics.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            answer = input('Do you want to run a a estimates process? (y/N)')\n    \n            if answer == 'y':\n                for company in Company.objects.all():\n                    self.process_company_metrics(company)\n    \n            answer = input('Do you want to run a cleanup? (y/N)')\n    \n            if answer == 'y':\n                deletion_list = ['Potential ROR (incl.', 'Shares O/S', 'Price', 'Potential ROR (incl. dividend)', 'Avg 3-month daily vol.', 'Market Cap']\n                all_companymetrics = CompanyMetric.objects.all()\n    \n                \n                for companymetric in all_companymetrics:\n                    \n                    for name in deletion_list:\n                       \n                        if fuzz.ratio(companymetric.name, name) > 82:  \n                            try:\n                                if fuzz.ratio(companymetric.name, 'Revenue') > 90:\n                                    self.stdout.write(self.style.WARNING('SAVED revenue'))\n                                elif fuzz.ratio(companymetric.name, 'Potential ROR (incl.') > 90 or fuzz.ratio(companymetric.name, 'Potential ROR (incl. dividend)') > 90:\n                                    comp: Company = companymetric.company\n                                    comp.potential_ror = companymetric.amount\n                                    comp.save()\n                                    companymetric.delete()\n                                elif fuzz.ratio(companymetric.name, 'Avg 3-month daily vol.') > 90:\n                                    comp: Company = companymetric.company\n                                    comp.avg_3month_daily_vol = companymetric.amount\n                                    comp.save()\n                                    companymetric.delete()\n                                elif fuzz.ratio(companymetric.name, 'Shares O/S') > 90:\n                                    comp: Company = companymetric.company\n                                    comp.shares_basic = companymetric.amount\n                                    comp.save()\n                                    companymetric.delete()\n                                elif fuzz.ratio(companymetric.name, 'Market Cap') > 90:\n                                    comp: Company = companymetric.company\n                                    comp.marketcap_basic = companymetric.amount\n                                    comp.save()\n                                    companymetric.delete()\n                                else:\n                                    companymetric.delete()\n                                    \n                            except:\n                                print(companymetric.name, companymetric.company)\n                            self.stdout.write(self.style.ERROR('Deleted'))\n            \n    \n            answer = input('Do you want to run a fix up? (y/N)')\n            current_year = datetime.datetime.now().year\n            if answer == 'y':\n                \n    \n                metrics = CompanyMetric.objects.filter(\n                    is_estimate=True,\n                    year_estimated__range=[current_year - 1, current_year + 1]\n                )\n    \n                grouped_metrics = metrics.values('company', 'name').order_by().annotate(count=Count('id'))\n    \n                for group in grouped_metrics:\n               \n                    for year in range(current_year - 1, current_year + 2):\n                        if not metrics.filter(company=group['company'], name=group['name'], year_estimated=year).exists():\n                           \n                            CompanyMetric.objects.create(\n                                company_id=group['company'],\n                                name=group['name'],\n                                year_estimated=year,\n                                is_estimate=True,\n                               \n                            )\n                companies = Company.objects.all()\n    \n            self.stdout.write(self.style.SQL_COLTYPE('Starting more cleanups'))\n            for company in companies:\n                # Get all CompanyMetric objects for this company\n                company_metrics = CompanyMetric.objects.filter(company=company)\n    \n                # Group the metrics by name\n                grouped_metrics = company_metrics.values('name').annotate(count=Count('id'))\n    \n                for group in grouped_metrics:\n                    # Get all metrics in this group\n                    group_metrics = company_metrics.filter(name=group['name'])\n    \n                    # Check if any two or more metrics have the same estimated_year value\n                    year_groups = group_metrics.values('year_estimated').annotate(count=Count('id')).filter(count__gt=1)\n    \n                    for year_group in year_groups:\n                        # Get all metrics in this year group\n                        year_group_metrics = group_metrics.filter(year_estimated=year_group['year_estimated'])\n    \n                        for met in year_group_metrics:\n                            print(met)\n                            met.is_estimate = True\n                            met.save()\n                        # Check if any of them have their amount field not empty\n                        metrics_with_amount = year_group_metrics.exclude(amount__isnull=True)\n    \n                        if metrics_with_amount.exists():\n                            # If any metric has a value, delete the rest and leave that one\n                            year_group_metrics.exclude(id=metrics_with_amount.first().id).delete()\n                            year_group_metrics.is_estimate = True\n                        else:\n                            # If all of them have them empty then delete all but one\n                            year_group_metrics.exclude(id=year_group_metrics.first().id).delete()\n                            year_group_metrics.is_estimate = True\n            self.stdout.write(self.style.SQL_FIELD('Making non estimates estimates'))\n            metrics = CompanyMetric.objects.filter(\n                is_estimate=True,\n                year_estimated__range=[current_year - 1, current_year + 1]\n            )\n    \n            # Group the metrics by company\n            grouped_metrics = metrics.values('company').annotate(count=Count('id'))\n    \n            for group in grouped_metrics:\n                # Get all metrics for this company\n                company_metrics = metrics.filter(company_id=group['company'])\n    \n                # Group the company metrics by name\n                name_groups = company_metrics.values('name').annotate(count=Count('id'))\n    \n                for name_group in name_groups:\n                    # Get all metrics with this name\n                    name_group_metrics = company_metrics.filter(name=name_group['name'])\n    \n                    # Check if the metric amount field is empty for the prior and future year, but not for the current\n                    prior_year_metric = name_group_metrics.filter(year_estimated=current_year - 1, amount__isnull=True).first()\n                    current_year_metric = name_group_metrics.filter(year_estimated=current_year, amount__isnull=False).first()\n                    future_year_metric = name_group_metrics.filter(year_estimated=current_year + 1, amount__isnull=True).first()\n    \n                    if prior_year_metric and current_year_metric and future_year_metric:\n                        # If the conditions are met, delete the prior and future metrics and convert the current to is_estimate=False\n                        prior_year_metric.delete()\n                        future_year_metric.delete()\n                        current_year_metric.is_estimate = False\n                        current_year_metric.save()"
            },
            {
                "function_name": "process_company_metrics",
                "parameters": [
                    "self",
                    "company"
                ],
                "content": "            metrics = list(CompanyMetric.objects.filter(company=company, is_estimate=False).exclude(name__in=['Potential ROR (incl.', 'Shares O/S', 'Price', 'Enterprise Value ($M)', 'Potential ROR (incl. dividend)']))\n    \n            # Check for duplicate names and years\n            for metric in metrics:\n                for other_metric in metrics:\n                    if metric != other_metric and fuzz.ratio(metric.name, other_metric.name) > 90:\n                        if metric.year_estimated != other_metric.year_estimated:\n                            metric.is_estimate = True\n                            other_metric.is_estimate = True\n                            metric.save()\n                            other_metric.save()\n    \n            # Check for surrounding year metrics\n            current_year = datetime.datetime.now().year\n            for year in [current_year-1, current_year, current_year+1]:\n                for metric_name in set(metric.name for metric in metrics):\n                    if not CompanyMetric.objects.filter(company=company, name=metric_name, year_estimated=year).exists():\n                        CompanyMetric.objects.create(company=company, name=metric_name, year_estimated=year, is_estimate=True)"
            }
        ],
        "imports": [
            "library.models.Company",
            "django.db.models.Q",
            "datetime",
            "django.core.management.base.BaseCommand",
            "fuzzywuzzy.fuzz",
            "library.models.CompanyMetric",
            "django.db.models.Count"
        ]
    },
    {
        "name_of_file": "initialize_and_fix_db.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            self.stdout.write(self.style.WARNING('Starting initialization procedure, are you sure you want to run this? [Y/n]'))\n            answer = input()\n            if answer.lower() == 'y':\n                self.stdout.write(self.style.WARNING('Running create_groups...'))\n                call_command('create_groups')\n                \n                # self.stdout.write(self.style.WARNING('Running fix_analysts_in_reports...'))\n                # call_command('fix_analysts_in_reports')\n                self.stdout.write(self.style.WARNING('Running clear_integrity_with_profile_analyst...'))\n                call_command('clear_integrity_with_profile_analyst')\n    \n                self.stdout.write(self.style.WARNING('Running makemigrations...'))\n                call_command('makemigrations')\n    \n                self.stdout.write(self.style.WARNING('Running migrate...'))\n                call_command('migrate')\n    \n                disclaimer, created = Disclaimer.objects.get_or_create(\n                title=\"test holder\",\n                defaults={\n                        'description': \"This is a test holder disclaimer.\",\n                    }\n                )\n                if created:\n                    self.stdout.write(self.style.SUCCESS('Successfully created \"test holder\" disclaimer.'))\n                else:\n                    self.stdout.write(self.style.WARNING('\"test holder\" disclaimer already exists.'))\n                \n                self.stdout.write(self.style.WARNING('Running fix_company_slugs...'))\n                call_command('fix_company_slugs')\n    \n    \n                self.stdout.write(self.style.SUCCESS('All commands ran successfully.'))\n    \n                self.stdout.write(self.style.WARNING('Starting the server...'))\n                call_command('runserver')\n            else:\n                self.stdout.write(self.style.ERROR('Exiting procedure...\\n'))"
            }
        ],
        "imports": [
            "django.core.management.base.BaseCommand",
            "library.models.Disclaimer",
            "django.core.management.call_command"
        ]
    },
    {
        "name_of_file": "list_of_comp_anal.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            filename = 'VERSION2CompanyToAnalystRelation.xlsx'\n            df = pd.read_excel(filename)\n            data_list = df.to_dict('records')\n            \n            companies = {company.name: company for company in Company.objects.all()}\n    \n            for data in data_list:\n                company = companies.get(data['Company Name'])\n                if company:\n                    # company.coverage = True\n                    # company.save()\n                    analyst_name_excel = data['Analyst']\n                    analyst_name_company = str(company.analyst)\n    \n                    # Use fuzz.ratio to get a similarity score between the two names\n                    similarity_score = fuzz.ratio(analyst_name_company.lower(), analyst_name_excel.lower())\n    \n                    if similarity_score > 80:\n                        self.stdout.write(f\"The analyst {analyst_name_company} matches with the Excel data.\")\n                    else:\n                        self.stdout.write(f\"Do you want to change the analyst {analyst_name_company} to {analyst_name_excel}? for {company}(y/no)\")\n                        answer = input()\n                        if answer.lower() == 'y':\n                            analyst_name_parts = analyst_name_excel.split()\n                            last_name = analyst_name_parts[-1]\n                            first_name = analyst_name_parts[0]\n                            try:\n                                analyst = Analyst.objects.filter(profile__last_name__icontains=last_name).first()\n                                self.stdout.write(f\"CONFIRM: Do you want to change the analyst {analyst_name_company} to {analyst}? at {company}(y/no)\")\n                                answer = input()\n                                if answer.lower() == 'y':\n                                    company.analyst = analyst\n                                    company.save()\n                            except Analyst.DoesNotExist:\n                                try:\n                                    analyst = Analyst.objects.get(profile__first_name__icontains=first_name)\n                                    self.stdout.write(f\"Do you want to change the analyst {analyst_name_company} to {analyst}? for {company} (y/no)\")\n                                    answer = input()\n                                    if answer.lower() == 'y':\n                                        company.analyst = analyst\n                                        company.save()\n                                except Analyst.DoesNotExist:\n                                    self.stdout.write(f\"No analyst found with the name {analyst_name_excel}.\")"
            }
        ],
        "imports": [
            "library.models.Company",
            "django.core.management.base.BaseCommand",
            "fuzzywuzzy.process",
            "library.models.Analyst",
            "pandas",
            "fuzzywuzzy.fuzz"
        ]
    },
    {
        "name_of_file": "populate_fye_companies.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "    \n    \n            companies = Company.objects.filter(coverage=True)\n    \n            for company in companies:\n    \n                try:\n    \n                    ticker = yf.Ticker(company.ticker)\n                    self.stdout.write(self.style.WARNING(ticker))\n                    # Get financial statements\n                    financials = ticker.financials\n    \n    \n    \n                    # Assuming 'dates' is the output you got\n                    dates = financials.columns\n    \n                    # Get the first date\n                    first_date = dates[0]\n    \n                    # Convert it to a datetime object\n                    datetime_object = pd.to_datetime(first_date)\n                    company.FYE = datetime_object\n                    company.save()\n                    self.stdout.write(self.style.SUCCESS(f'Updated FYE for {company}'))\n    \n                except:\n                    self.stdout.write(self.style.ERROR('Failed to update FYE'))"
            }
        ],
        "imports": [
            "pandas",
            "library.models.Company",
            "django.core.management.base.BaseCommand",
            "yfinance"
        ]
    },
    {
        "name_of_file": "populate_report_contents.py",
        "functions": [
            {
                "function_name": "add_arguments",
                "parameters": [
                    "self",
                    "parser"
                ],
                "content": "            parser.add_argument('file_path', type=str, help='Path to the text file containing report contents')"
            },
            {
                "function_name": "append_images_to_content",
                "parameters": [
                    "self",
                    "report"
                ],
                "content": "            company_ticker = report.company.ticker\n            pub_date = report.publish_date.strftime('%Y-%m-%d')\n            image_pattern = f\"{company_ticker} {pub_date} IMAGE_\"\n    \n            # at root of project\n            image_directory = os.path.join(os.getcwd(), 'C:/Users/Alejandro/Documents/TEST IMAGES')\n    \n            matching_images = [img for img in os.listdir(image_directory) if img.startswith(image_pattern)]\n    \n            for img in matching_images:\n                img_tag = f'<img src=\"<img src=\"http://127.0.0.1:8000/static/TestImages/{img}\" alt=\"{img}\">'\n                report.content += img_tag\n    \n            report.save()"
            },
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "    \n            print('')\n            print('')\n            self.stdout.write(self.style.WARNING(f\"WARNING: Dont forget to run AWS BEFORE this\"))\n            print('')\n            print('')\n            CLEANING = True\n            OLD_MATCHING = False\n    \n            file_path = kwargs['file_path']\n    \n            clear_content_process = input(\"Would you like to clear all contents from legacy reports? (y/n): \").strip().lower()\n            if clear_content_process == 'y':\n                all_legacy = Report.objects.filter(is_legacy=True)\n                for report in all_legacy:\n                    \n                    report.content = None\n                    report.save()\n            report_dicts = extract_dicts(file_path)\n            self.stdout.write(self.style.SUCCESS(f\"Found {len(report_dicts)} report dicts!\"))\n            # Fetch all legacy reports without content\n            reports = Report.objects.filter(is_legacy=True)\n            i = 0\n            for report in reports:\n                # print('report')\n                matching_dicts = []\n                for d in report_dicts:\n                    \n                    # if d['pub_date'] == \"2023/08/11\" and d['company_ticker'] == 'PRN':\n                    #     print(d['pub_date'])\n                    #     print('FOUNDDD')\n                    #     print('ticker:', d['company_ticker'])\n                    # if d['pub_date'] == report.publish_date.strftime('%Y/%m/%d'):\n                    #     print('sametime!')\n                    #     print(d['company_ticker'], \"and:\", report.company.ticker)\n                    # print(d['company_ticker'], \"and: \", d['pub_date'], \"vs:\",  report.publish_date.strftime('%Y/%m/%d'))\n    \n                    if OLD_MATCHING:\n                        if (d['company_ticker'] == report.company.ticker) and (d['pub_date'] == report.publish_date.strftime('%Y/%m/%d')): ### DONT DELETE OLD WAY OF DOING IT\n                            matching_dicts.append(d)\n                    else:\n                        reportPath = report.temp_pdf_path.rpartition('/')[-1].partition('.')[0]\n                        if (d['path'].lower() == reportPath.lower()):\n                            matching_dicts.append(d)\n    \n                if len(matching_dicts) == 1:\n                    \n                    report.content = matching_dicts[0]['content']\n                    print(report.title)\n                    report.save()\n                    report_dicts.remove(matching_dicts[0])\n                    i +=1\n                elif len(matching_dicts) > 1:\n                    best_match_score = 0\n                    best_match = None\n                    \n                    for d in matching_dicts:\n                        score = fuzz.partial_ratio(report.title, d['content'])\n                        if score > best_match_score:\n                            best_match_score = score\n                            best_match = d\n    \n                    if best_match:\n                        report.content = best_match['content']\n                        report.save()\n                        report_dicts.remove(best_match)\n                        i +=1\n                        \n    \n            # If left, then write to file\n            count = 0\n            if report_dicts:\n                with open('NonMatchingContentReports.txt', 'w') as f:\n                    for d in report_dicts:\n                        f.write(str(d) + \"\\n\")\n                        count += 1\n            self.stdout.write(self.style.SUCCESS(f'Successfully populated {i} legacy reports'))\n            self.stdout.write(self.style.ERROR(f'Populated {count} dictionaries for non matching legacy reports\\n'))\n    \n            if CLEANING == True:\n                self.stdout.write(self.style.NOTICE(f'Cleaning report tables...'))\n                reportsA = Report.objects.filter(is_legacy = True)\n    \n                self.stdout.write(self.style.NOTICE(f'removing figures from reports...'))\n                take_in_reports_remove_figures(reportsA)\n                self.stdout.write(self.style.NOTICE(f'removing headers from reports...'))\n                take_in_reports_remove_headers(reportsA)\n                self.stdout.write(self.style.NOTICE(f'removing disclaimer text from reports...'))\n                take_in_reports_remove_disclaimerTEXT(reportsA)\n                self.stdout.write(self.style.NOTICE(f'removing first table text from reports...'))\n                take_in_reports_remove_firstTableTEXT(reportsA)\n                self.stdout.write(self.style.WARNING('WARNING: Using non-dynamic page removal.'))\n                take_in_report_remove_pageHeaderNONDYNAMIC_TEXT(reportsA)\n                self.stdout.write(self.style.WARNING('WARNING: Using NON-SELECTIVE event/thesis removal'))\n                take_in_reports_remove_thesisToEvent_NON_SELECTIVE(reportsA)\n                self.stdout.write(self.style.NOTICE(f'justifying content in reports...'))\n                take_in_reports_justify_content(reportsA)\n                take_in_reports_justify_contentOLD(reportsA)\n                self.stdout.write(self.style.NOTICE(f'adding formating to figures...'))\n                add_formating_to_figures(reportsA)\n                self.stdout.write(self.style.NOTICE(f'adding general formating to sections...'))\n                add_general_formating_to_sections(reportsA)\n                \n                self.stdout.write(self.style.NOTICE(f'Chaning \\\\u\\'s for \u2022...'))\n                take_in_reports_remove_u(reportsA)\n                self.stdout.write(self.style.WARNING('WARNING: adding bullet points for non-fully confident matches'))\n                take_in_reports_remove_u_version2(reportsA)\n                self.stdout.write(self.style.NOTICE(f'Removing in the middle company names...'))\n                take_in_reports_clean_comp_title_from_in_text(reportsA)\n                self.stdout.write(self.style.SUCCESS(f'Successfully cleaned legacy reports'))\n    \n            table_run = input('Would you like to process and add tables to content? (y/n)')\n    \n            if table_run.lower() == 'y':\n                self.stdout.write(self.style.WARNING('Running tables set-up...'))\n                call_command('proccess_legacy_report_tables')\n    \n            run_image_process = input(\"Would you like to run the image process? (y/n): \").strip().lower()\n            if run_image_process == 'y':\n                reports = Report.objects.filter(is_legacy=True)\n                for report in reports:\n                    self.append_images_to_content(report)\n    \n                self.stdout.write(self.style.SUCCESS('Appended images to report content!'))"
            }
        ],
        "imports": [
            "library.models.Company",
            "library.utils.add_formating_to_figures",
            "library.utils.take_in_reports_remove_figures",
            "library.utils.take_in_report_remove_pageHeaderNONDYNAMIC_TEXT",
            "library.utils.extract_dicts",
            "library.utils.take_in_reports_remove_disclaimerTEXT",
            "library.utils.take_in_reports_remove_thesisToEvent_NON_SELECTIVE",
            "fuzzywuzzy.fuzz",
            "library.utils.take_in_reports_justify_content",
            "library.utils.take_in_reports_remove_u",
            "library.utils.take_in_reports_clean_comp_title_from_in_text",
            "library.utils.take_in_reports_remove_firstTableTEXT",
            "django.core.management.base.BaseCommand",
            "library.utils.add_general_formating_to_sections",
            "django.core.management.call_command",
            "os",
            "library.utils.take_in_reports_remove_headers",
            "library.utils.take_in_reports_justify_contentOLD",
            "library.models.Report",
            "library.utils.take_in_reports_remove_u_version2"
        ]
    },
    {
        "name_of_file": "proccess_legacy_report_tables.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            legacy_reports = Report.objects.filter(is_legacy=True)\n            with tqdm(total=legacy_reports.count(), desc=\"Processing reports\", unit=\"report\") as pbar:\n                for report in legacy_reports:\n                    old_path = report.temp_pdf_path\n                    new_path = os.path.join(NEWPATH, old_path.split('/')[-1])\n                    report.temp_pdf_path = new_path\n                    report.save()\n                    pbar.update(1)\n    \n                self.stdout.write(self.style.SUCCESS('Updated PDF paths.'))\n    \n                for report in legacy_reports:\n                    self.stdout.write(self.style.NOTICE(f\"Processing {report.title}...\"))\n                    try:\n                        table_images = self.process_pdf(report.temp_pdf_path, report)\n                    except Exception as e:\n                        self.stdout.write(self.style.ERROR(f\"{report.title} did not have a matching pdf file: {str(e)}\"))\n                        continue\n    \n                    content = report.content or \"\"\n                    # print(\"DEBUGGGGGGGGGG:\", content, \"Table images:\", table_images)\n                    content = self.insert_images(content, table_images)\n                    report.content = content\n                    # print(\"NEWWWWW\", content)\n                    report.save()"
            },
            {
                "function_name": "classify_and_filter_tables",
                "parameters": [
                    "self",
                    "table_images",
                    "filtering"
                ],
                "content": "            if not filtering:\n                return table_images\n            \n            # API URLs and headers\n            API_URL_TABLES = \"https://api-inference.huggingface.co/models/aParadigmP/autotrain-specializing-table-detection-96850146742\"\n            API_URL_DISCLAIMERS = \"https://api-inference.huggingface.co/models/aParadigmP/autotrain-disclaimers-detection-specialized-96913146749\"\n            headers = {\"Authorization\": \"Bearer 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\"}\n    \n            # Function to query the API\n            def query(api_url, filename):\n                with open(filename, \"rb\") as f:\n                    data = f.read()\n                response = requests.post(api_url, headers=headers, data=data)\n                return response.json()\n            \n            good_tables = []\n            for table_image_path in table_images:\n                # First classification for good or bad tables\n                result_tables = query(API_URL_TABLES, table_image_path)\n                label_tables = result_tables[0]['label']\n                if label_tables == 'bad tables':\n                    print(f\"Bad table detected: {table_image_path}\")\n                    os.remove(table_image_path)\n                    continue  # Skip the second classification if it's already a bad table\n    \n                # Second classification for bad disclaimer tables\n                result_disclaimers = query(API_URL_DISCLAIMERS, table_image_path)\n                label_disclaimers = result_disclaimers[0]['label']\n                score_disclaimers = result_disclaimers[0]['score']  # Confidence level\n                if label_disclaimers == 'bad disclaimer table' and score_disclaimers >= 0.7:\n                    print(f\"Bad disclaimer table detected: {table_image_path}\")\n                    os.remove(table_image_path)\n                else:\n                    good_tables.append(table_image_path)\n            \n            return good_tables"
            },
            {
                "function_name": "process_pdf",
                "parameters": [
                    "self",
                    "pdf_path",
                    "report",
                    "filtering"
                ],
                "content": "           \n            API_URL = \"https://lkx9n64koppfrw1g.us-east-1.aws.endpoints.huggingface.cloud\"\n            headers = {\"Authorization\": \"Bearer AglQPytaDJogleOOqVtLUWxGRyrSboKopltZXqabvFBEuwluHaSavuXLiNpYBiRATiqLfdFpTGeqbzOAYAQUcQNtIVCYcChLpkALifrvHOhYeugbxesGvNuIzqanehVx\",\n                    \"Content-Type\": \"image/png\"}\n    \n            def query(filename):\n                with open(filename, \"rb\") as f:\n                    data = f.read()\n                response = requests.post(API_URL, headers=headers, data=data)\n                return response.json()\n            \n            overall_order = 0\n            table_images = []\n    \n            with fitz.open(pdf_path) as pdf:\n                for page_number in tqdm(range(len(pdf)), desc=f\"Processing pages for {report.id}\", unit=\"page\", leave=False):\n                    page = pdf.load_page(page_number)\n                    pix = page.get_pixmap()\n                    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n    \n                    temp_image_path = 'temp.png'\n                    img.save(temp_image_path)\n    \n                    results = query(temp_image_path)\n                    \n                    box = results[0][\"box\"]\n                    \n                    rect = fitz.Rect(\n                        max(box[\"xmin\"], 0),\n                        max(box[\"ymin\"], 0),\n                        min(box[\"xmax\"], pix.width),\n                        min(box[\"ymax\"], pix.height)\n                    )\n                    overall_order += 1\n                    pix = page.get_pixmap(clip=rect)\n                    table_image_path = os.path.join(output_folder, f'{report.company.ticker}_table_{page_number}_{overall_order}_{report.title}.png')\n                    pix.save(table_image_path)\n                    table_images.append(table_image_path)\n    \n            table_images = self.classify_and_filter_tablesLOCAL(table_images, filtering)\n            \n            return table_images"
            },
            {
                "function_name": "classify_and_filter_tablesLOCAL",
                "parameters": [
                    "self",
                    "table_images",
                    "filtering"
                ],
                "content": "            if not filtering:\n                return table_images\n            \n            # Pipeline for classifying 'good tables' and 'bad tables'\n            pipe_tables = pipeline(\n                \"image-classification\",\n                model=\"aParadigmP/autotrain-specializing-table-detection-96850146742\"\n            )\n            \n            # Pipeline for detecting 'bad disclaimer table'\n            pipe_disclaimers = pipeline(\n                \"image-classification\",\n                model=\"aParadigmP/autotrain-disclaimers-detection-specialized-96913146749\"\n            )\n            \n            good_tables = []\n            for table_image_path in table_images:\n                image = Image.open(table_image_path)\n                \n                # First classification for good or bad tables\n                result_tables = pipe_tables(image)\n                label_tables = result_tables[0]['label']\n                if label_tables == 'bad tables':\n                    print(f\"Bad table detected: {table_image_path}\")\n                    os.remove(table_image_path)\n                    continue  # Skip the second classification if it's already a bad table\n    \n                # Second classification for bad disclaimer tables\n                result_disclaimers = pipe_disclaimers(image)\n                label_disclaimers = result_disclaimers[0]['label']\n                score_disclaimers = result_disclaimers[0]['score'] ##Confidence level\n                if label_disclaimers == 'bad disclaimer table' and score_disclaimers >= 0.7: \n                    print(f\"Bad disclaimer table detected: {table_image_path}\")\n                    os.remove(table_image_path)\n                else:\n                    good_tables.append(table_image_path)\n            \n            return good_tables"
            },
            {
                "function_name": "process_pdfLOCAL",
                "parameters": [
                    "self",
                    "pdf_path",
                    "report",
                    "filtering"
                ],
                "content": "            image_processor = AutoImageProcessor.from_pretrained(\"microsoft/table-transformer-detection\")\n            model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-detection\")\n            overall_order = 0\n            table_images = []\n    \n            with fitz.open(pdf_path) as pdf:\n                for page_number in tqdm(range(len(pdf)), desc=f\"Processing pages for {report.id}\", unit=\"page\", leave=False):\n                    page = pdf.load_page(page_number)\n                    pix = page.get_pixmap()\n                    image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n    \n                    inputs = image_processor(images=image, return_tensors=\"pt\")\n                    outputs = model(**inputs)\n                    target_sizes = torch.tensor([image.size[::-1]])\n                    results = image_processor.post_process_object_detection(outputs, threshold=0.9, target_sizes=target_sizes)[0]\n    \n                    sorted_boxes = sorted(results[\"boxes\"], key=lambda box: box[1])\n                    for i, box in enumerate(sorted_boxes):\n                        rect = fitz.Rect(\n                            max(box[0] - GENERAL, 0),\n                            max(box[1] - YPADDING - GENERAL, 0),\n                            min(box[2] + GENERAL, pix.width),\n                            min(box[3] + YPADDING + GENERAL, pix.height)\n                        )\n                        overall_order += 1\n                        if rect.width > 0 and rect.height > 0:\n                            pix = page.get_pixmap(clip=rect)\n                            table_image_path = os.path.join(output_folder, f'{report.company.ticker}_table_{page_number}_{overall_order}_{report.title}.png')\n                            pix.save(table_image_path)\n                            table_images.append(table_image_path)\n                        else:\n                            rect = fitz.Rect(box[0], box[1], box[2], box[3])\n                            pix = page.get_pixmap(clip=rect)\n                            table_image_path = os.path.join(output_folder, f'{report.company.ticker}_table_{page_number}_{overall_order}_{report.title}.png')\n                            pix.save(table_image_path)\n                            table_images.append(table_image_path)\n    \n            # Call the classify_and_filter_tables method to filter out the bad tables\n            table_images = self.classify_and_filter_tables(table_images, filtering)\n            \n            return table_images"
            },
            {
                "function_name": "insert_images",
                "parameters": [
                    "self",
                    "content",
                    "table_images"
                ],
                "content": "            pattern = re.compile(r\"(Figure (?:[0-9]|[1-9][0-9]):.+?Source)\", re.DOTALL)\n            matches = list(pattern.finditer(content))\n            \n            print(f\"Number of 'Figure ##:...Source' matches found in content: {len(matches)}\")\n            \n            print(f\"Number of images to insert: {len(table_images)}\")\n            \n            offset = 0 \n    \n            for i, match in enumerate(matches):\n                if i < len(table_images):\n                    \n                    print(f\"Inserting image at position: {match.end() + offset}\")\n                    \n                    image_tag = f'\\n<img src=\"http://127.0.0.1:8000/static/tableImagesFolder/{os.path.basename(table_images[i])}\" width=\"400\">\\n'\n                    insertion_point = match.end() - len(\"Source\") + offset\n                    content = content[:insertion_point] + image_tag + content[insertion_point:]\n                    offset += len(image_tag) \n            remaining_images_count = len(table_images) - len(matches)\n            if remaining_images_count > 0:\n                print(f\"Number of images remaining to be appended at the end: {remaining_images_count}\")\n    \n            remaining_images = table_images[len(matches):]\n            for remaining_image in remaining_images:\n                image_tag = f'\\n<img src=\"http://127.0.0.1:8000/static/tableImagesFolder/{os.path.basename(remaining_image)}\" width=\"400\">\\n'\n                content += image_tag\n    \n            return content"
            },
            {
                "function_name": "query",
                "parameters": [
                    "api_url",
                    "filename"
                ],
                "content": "                with open(filename, \"rb\") as f:\n                    data = f.read()\n                response = requests.post(api_url, headers=headers, data=data)\n                return response.json()"
            },
            {
                "function_name": "query",
                "parameters": [
                    "filename"
                ],
                "content": "                with open(filename, \"rb\") as f:\n                    data = f.read()\n                response = requests.post(API_URL, headers=headers, data=data)\n                return response.json()"
            }
        ],
        "imports": [
            "library.models.Company",
            "transformers.TableTransformerForObjectDetection",
            "io",
            "PIL.Image",
            "transformers.pipeline",
            "torch",
            "django.core.management.base.BaseCommand",
            "tqdm.tqdm",
            "re",
            "requests",
            "os",
            "transformers.AutoImageProcessor",
            "fitz",
            "library.models.Report"
        ]
    },
    {
        "name_of_file": "randomTreeRegressor_clarity_model.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            self.stdout.write(\"Starting the full workflow...\")\n            full_workflow()\n            print(get_significant_features())\n            self.stdout.write(\"Workflow completed.\")"
            }
        ],
        "imports": [
            "library.utils.full_workflow",
            "django.core.management.base.BaseCommand",
            "library.utils.get_significant_features"
        ]
    },
    {
        "name_of_file": "send_change_password_emails.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            legacy_profiles = Profile.objects.filter(is_legacy=True)\n            self.stdout.write(self.style.WARNING('RUN PROFILE CREATION FIRST IF YOU HAVENT'))\n            if len(legacy_profiles) <= 0:\n                self.stdout.write(self.style.HTTP_NOT_FOUND('No legacy profiles found...'))\n            \n            for profile in legacy_profiles:\n    \n                user = profile.user\n    \n                temp_password = get_random_string(length=12)\n                user.set_password(temp_password)\n                user.save()\n    \n                email = [profile.email]\n    \n                print(f'changed: {profile.email}, {user.first_name}, {user.last_name}, {user}')\n    \n                send_mail(\n                    subject=\"Paradigm Capital NEW website password\",\n                    from_email='myamani@paradigmcap.com',\n                    recipient_list = email,\n                    message=f\"\"\"PARADIGM CAPITAL\n                    As we transition to our new website we have reset your password:\n                    \n                    Your temporary password is \"{temp_password}\". Please hit the link below and change your password as soon as possible, if you find any trouble during this process feel free to contact us:\n                    \n                    https://research.paradigmcap.com/profile\n    \n                    There for you,\n                    Paradigm Capital Development Team\n                    \"\"\"\n                )"
            }
        ],
        "imports": [
            "django.core.mail.send_mail",
            "django.core.management.base.BaseCommand",
            "typing.Any",
            "library.models.User",
            "django.utils.crypto.get_random_string",
            "library.models.Profile"
        ]
    },
    {
        "name_of_file": "set_current_metrics_legacy.py",
        "functions": [
            {
                "function_name": "handle",
                "parameters": [
                    "self"
                ],
                "content": "            # Get all companies\n            companies = Company.objects.all()\n            print(len(companies))\n    \n            for company in companies:\n                # Get all legacy reports for this company\n                reports = Report.objects.filter(company=company, is_legacy=True, type__icontains='Research Note')\n    \n                # Get the newest legacy report where the target is not None\n                newest_target_report = reports.exclude(target=None).order_by('-publish_date').first()\n                if newest_target_report:\n                    # Update the company target\n                    company.current_target = newest_target_report.target\n                    company.save()\n                    print(f\"Updated target for {company.name}\")\n    \n                # Get the newest legacy report where the rating is not None\n                newest_rating_report = reports.exclude(rating=None).order_by('-publish_date').first()\n                if newest_rating_report:\n                    # Update the company rating\n                    company.current_rating = newest_rating_report.rating\n                    company.save()\n                    print(f\"Updated rating for {company.name}\")\n    \n                # Get the newest legacy report where the report_investment_thesis is not None\n                newest_thesis_report = reports.exclude(report_investment_thesis=None).order_by('-publish_date').first()\n                if newest_thesis_report:\n                    # Update the company investment_thesis\n                    company.investment_thesis = newest_thesis_report.report_investment_thesis\n                    company.save()\n                    print(f\"Updated investment thesis for {company.name}\")\n    \n                # Get the newest legacy report where the report_company_description is not None\n                newest_description_report = reports.exclude(report_company_description=None).order_by('-publish_date').first()\n                if newest_description_report:\n                    # Update the company company_description\n                    company.company_description = newest_description_report.report_company_description\n                    company.save()\n                    print(f\"Updated company description for {company.name}\")\n    \n            self.stdout.write(self.style.SUCCESS('Successfully updated company fields.'))"
            }
        ],
        "imports": [
            "library.models.Report",
            "library.models.Company",
            "django.db.models.Max",
            "django.core.management.base.BaseCommand"
        ]
    },
    {
        "name_of_file": "custom_tags.py",
        "functions": [
            {
                "function_name": "bg_color",
                "parameters": [
                    "company_value",
                    "report_value"
                ],
                "content": "        \"\"\"Just a simple filter we created to check if two values are the same and apply conditional colors instead of having\n        to add if tags\"\"\"\n        if not company_value or not report_value: ##if any is empty we dont change anything\n            return \"\"\n        if company_value == report_value:\n            return \"bg-green-200/20\" ##if same\n        return \"bg-red-200/20\""
            },
            {
                "function_name": "get_metric_value",
                "parameters": [
                    "report_metrics",
                    "metric_name"
                ],
                "content": "        # Check if the inputs are not None\n        if not report_metrics or not metric_name:\n            return None\n    \n        # Return the value from report_metrics if it exists, otherwise return None\n        return report_metrics.get(metric_name, None)"
            },
            {
                "function_name": "get_from_dict",
                "parameters": [
                    "dictionary",
                    "key"
                ],
                "content": "        return dictionary.get(key)"
            },
            {
                "function_name": "get_index",
                "parameters": [
                    "value",
                    "arg"
                ],
                "content": "        try:\n            return value[arg]\n        except IndexError:\n            return None"
            },
            {
                "function_name": "get_year",
                "parameters": [
                    "value",
                    "arg"
                ],
                "content": "        return value.get(arg)"
            }
        ],
        "imports": [
            "django.template"
        ]
    },
    {
        "all_imports": [
            "django.core.files.base.ContentFile",
            "library.utils.add_formating_to_figures",
            "library.utils.take_in_reports_remove_figures",
            "models.NewsObject",
            "django.core.paginator.PageNotAnInteger",
            "secrets",
            "django.core.paginator.EmptyPage",
            "json",
            "transformers.AutoImageProcessor",
            "ast",
            "models.SectorMetric",
            "statistics.stdev",
            "django.shortcuts.get_object_or_404",
            "library.models.Profile",
            "bs4",
            "utils.predict_report_score",
            "django.template.loader.render_to_string",
            "numpy",
            "sklearn.impute.SimpleImputer",
            "tinymce.widgets.TinyMCE",
            "PIL.Image",
            "datetime.timedelta",
            "library.utils.take_in_reports_remove_thesisToEvent_NON_SELECTIVE",
            "typing.Any",
            "django.db.models.functions.ExtractDay",
            "django.shortcuts.redirect",
            "models.CompanyDisclaimer",
            "library.models.CompanyMetric",
            "django.db.models.deletion",
            "utils.full_workflow",
            "library.utils.full_workflow",
            "string",
            "statistics.median",
            "io",
            "django.test.TestCase",
            "django.urls.reverse",
            "django.core.exceptions.ObjectDoesNotExist",
            "import_export.fields",
            "pandas",
            "django.test.LiveServerTestCase",
            "models.CompanyMetric",
            "import_export.widgets.ManyToManyWidget",
            "boto3",
            "django.db.models.When",
            "sklearn.preprocessing.OneHotEncoder",
            "yfinance",
            "library.utils.extractCompanyTickerFromResearchPDF",
            "tinymce.models",
            "library.utils.take_in_reports_remove_firstTableTEXT",
            "django.db.models.functions.ExtractYear",
            "django_countries.fields.CountryField",
            "django.contrib.auth.hashers.make_password",
            "django.core.management.base.BaseCommand",
            "utils.get_highest_confidence_sentiment",
            "django.test.utils.teardown_test_environment",
            "difflib",
            "os",
            "django.core.paginator.Paginator",
            "library.utils.extractPublishDateFromTechnicalPDF",
            "library.utils.add_general_formating_to_sections",
            "django.views.decorators.cache.cache_page",
            "library.models.Report",
            "models.User",
            "django.contrib.auth.forms.AdminPasswordChangeForm",
            "pathlib.Path",
            "django.utils.timezone.now",
            "library.models.Company",
            "models.ExcelStatistic",
            "django.contrib.auth.logout",
            "django.db.transaction",
            "math.sqrt",
            "django.utils.timezone",
            "django.db.models",
            "django.contrib.admin",
            "models.Disclaimer",
            "django.test.utils.setup_test_environment",
            "random.randint",
            "django.db.models.Count",
            "django.views.decorators.http.require_http_methods",
            "django.contrib.auth.login",
            "library.models",
            "datetime.datetime",
            "custom_tags",
            "library.utils.extractTargetFromResearchPDF",
            "forex_python.converter.CurrencyRates",
            "models.Company",
            "library.models.Disclaimer",
            "django.shortcuts.render",
            "library.utils.determineIfResearchPDF",
            "utils.listDiff",
            "logging",
            "django.db.models.F",
            "transformers.TableTransformerForObjectDetection",
            "forms.ReportDraftForm",
            "library.utils.take_in_reports_remove_u",
            "utils.send_notification_to",
            "import_export.fields.Field",
            "django.utils.translation.gettext_lazy",
            "sklearn.metrics.r2_score",
            "fitz",
            "csv",
            "utils.listDiffNEW",
            "pickle",
            "utils.createReportLinkToShare",
            "tenacity.wait_random_exponential",
            "django.utils.translation.ngettext",
            "utils.avgWordsPerReport",
            "utils.send_html_email",
            "statistics.mean",
            "models.ReportDisclaimer",
            "forms.SignupForm",
            "utils.run_rollover_year",
            "tkinter.Tk",
            "library.utils.get_significant_features",
            "models.Report",
            "tenacity.stop_after_attempt",
            "models.Profile",
            "models.Signup",
            "models.ReportMetric",
            "django.apps.AppConfig",
            "re",
            "django.core.cache.cache",
            "models.MagicLinkToken",
            "PyPDF2",
            "requests",
            "openai",
            "django.http.FileResponse",
            "utils.get_headings_and_texts",
            "django.contrib.auth.models.User",
            "utils.rollover_company",
            "library.utils.fetch_and_update_company_metrics",
            "django.utils.deprecation.MiddlewareMixin",
            "views.password_change",
            "library.utils.extract_dicts",
            "django.utils.text.slugify",
            "library.utils.extractEventFromResearchPDF",
            "django.db.IntegrityError",
            "django.db.models.functions.ExtractMonth",
            "fuzzywuzzy.fuzz",
            "library.utils.take_in_reports_justify_content",
            "django.urls.path",
            "django.template.defaultfilters.slugify",
            "django.contrib.auth.views",
            "django.views.decorators.vary.vary_on_cookie",
            "PCIResearch.renderers",
            "django.db.migrations",
            "django.db.models.Q",
            "transformers.pipeline",
            "django.contrib.auth.decorators.login_required",
            "fuzzywuzzy.process",
            "collections.defaultdict",
            "library.utils.take_in_reports_remove_u_version2",
            "django.db.models.Value",
            "django.contrib.admin.SimpleListFilter",
            "models.Analyst",
            "tenacity.retry",
            "library.utils.take_in_reports_clean_comp_title_from_in_text",
            "sklearn.metrics.mean_squared_error",
            "threading",
            "django.contrib.auth.models.Group",
            "joblib",
            "library.utils.take_in_reports_justify_contentOLD",
            "sklearn.ensemble.RandomForestRegressor",
            "django.db.connection",
            "django.http.HttpResponseRedirect",
            "utils.get_significant_features",
            "models.GeneralLog",
            "import_export.widgets",
            "django.contrib.auth.authenticate",
            "library.models.Analyst",
            "django.db.models.BooleanField",
            "django.contrib.messages",
            "django.db.models.Max",
            "library.models.ReportGroup",
            "models.Section",
            "library.utils.take_in_report_remove_pageHeaderNONDYNAMIC_TEXT",
            "gtts.tts.gTTS",
            "import_export.resources",
            "library.utils.take_in_reports_remove_disclaimerTEXT",
            "tqdm.tqdm",
            "utils.fetch_and_update_company_metrics",
            "models.ReportGroup",
            "django.core.signing",
            "tkinter.filedialog",
            "library.models.User",
            "tinymce.models.HTMLField",
            "forms.ChangeUserPasswordForm",
            "django.db.models.Case",
            "library.utils.extractReportTitleFromResearchPDF",
            "sklearn.model_selection.train_test_split",
            "time",
            "torch",
            "utils.process_and_pickle_data",
            "bs4.BeautifulSoup",
            "sklearn.metrics.mean_absolute_error",
            "random",
            "library.views",
            "django.forms",
            "django.http.HttpResponse",
            "django.conf.settings",
            "django.template",
            "django.utils.html.format_html",
            "django.core.mail.send_mail",
            "utils.user_highest_permission_finder",
            "datetime",
            "import_export.widgets.ForeignKeyWidget",
            "import_export.admin.ImportExportModelAdmin",
            "django.test.Client",
            "django.http.JsonResponse",
            "utils.simple_fast_reading_time",
            "library.utils.extractRatingFromResearchPDF",
            "utils.put_report_to_publish",
            "library.utils.extract_text_from_pdf",
            "forms.EmailTemplateReportForm",
            "django.core.management.call_command",
            "library.utils.take_in_reports_remove_headers",
            "django.utils.crypto.get_random_string",
            "django.templatetags.static.static",
            "django.views.decorators.csrf.csrf_exempt"
        ]
    }
]